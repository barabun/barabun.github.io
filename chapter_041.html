<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html>
<html epub:prefix="z3998: http://www.daisy.org/z3998/2012/vocab/structure/#" lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
 <head>
  <link href="style.css" rel="stylesheet" type="text/css"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   27Multithreaded Programming with C++
  </title>
 </head>
 <body>
  <div class="navigation">
   <a class="nav-button" href="chapter_040.html">
    ← Previous
   </a>
   <a class="nav-button" href="index.html">
    Table of Contents
   </a>
   <a class="nav-button" href="chapter_042.html">
    Next →
   </a>
  </div>
  <div class="chapter-content">
   <section aria-labelledby="c27_1" class="calibre2" epub:type="chapter" role="doc-chapter">
    <header class="calibre10">
     <h1 class="calibre16" id="c27_1">
      <span aria-label="985" class="calibre17" epub:type="pagebreak" id="Page_985" role="doc-pagebreak">
      </span>
      <span class="calibre" id="c27">
      </span>
      <span class="calibre">
       27
      </span>
      <br class="calibre12"/>
      <span class="calibre">
       Multithreaded Programming with C++
      </span>
     </h1>
    </header>
    <section aria-label="chapter opening" class="calibre2">
     <span class="calibre" id="c27-sec-0001">
     </span>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature1">
        <h3 class="calibre30">
         WHAT'S IN THIS CHAPTER?
        </h3>
        <ul class="check2" id="c27-list-0001">
         <li class="calibre9" id="c27-li-0001">
          What multithreaded programming is
         </li>
         <li class="calibre9" id="c27-li-0002">
          How to launch multiple threads
         </li>
         <li class="calibre9" id="c27-li-0003">
          How to (sort of) cancel threads
         </li>
         <li class="calibre9" id="c27-li-0004">
          How to retrieve results from threads
         </li>
         <li class="calibre9" id="c27-li-0005">
          What deadlocks and race conditions are, and how to use mutual exclusion to prevent them
         </li>
         <li class="calibre9" id="c27-li-0006">
          How to use atomic types and atomic operations
         </li>
         <li class="calibre9" id="c27-li-0007">
          What condition variables are
         </li>
         <li class="calibre9" id="c27-li-0008">
          How to use semaphores, latches, and barriers
         </li>
         <li class="calibre9" id="c27-li-0009">
          How to use futures and promises for inter-thread communication
         </li>
         <li class="calibre9" id="c27-li-0010">
          What thread pools are
         </li>
         <li class="calibre9" id="c27-li-0011">
          What resumable functions, or coroutines, are
         </li>
        </ul>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature1">
        <span class="calibre" id="c27-fea-0001">
        </span>
        <h3 class="calibre30" id="head-2-267">
         WILEY.COM DOWNLOADS FOR THIS CHAPTER
        </h3>
        <span class="calibre" id="c27-sec-0003">
        </span>
        <p class="calibre25" id="c27-para-0004">
         Please note that all the code examples for this chapter are available as part of this chapter's code download on the book's website at
         <code class="calibre21">
          <a class="calibre5" href="http://www.wiley.com/go/proc++6e">
           www.wiley.com/go/proc++6e
          </a>
         </code>
         on the Download Code tab.
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <p class="calibre13" id="c27-para-0005">
      <span aria-label="986" class="calibre20" epub:type="pagebreak" id="Page_986" role="doc-pagebreak">
      </span>
      Multithreaded programming is important on computer systems with multiple processor units. It allows you to write a program to use all those processor units in parallel. There are multiple ways for a system to have multiple processor units. The system can have multiple discrete processor chips, each one an independent central processing unit (CPU). Or, the system can have a single discrete processor chip that internally consists of multiple independent CPUs, also called
      <i class="calibre18">
       cores
      </i>
      . These kinds of processors are called
      <i class="calibre18">
       multicore processors
      </i>
      . A system can also have a combination of both. Systems with multiple processor units have existed for a long time; however, they were rarely used in consumer systems. Today, all CPU vendors are selling multicore processors, which are being used in everything from servers to consumer computers to smartphones. Because of this proliferation of multicore processors, it is important to know how to write multithreaded applications. A professional C++ programmer needs to know how to write correct multithreaded code to take full advantage of all the available processor units. Writing multithreaded applications used to rely on platform- and operating system–specific APIs. This made it difficult to write platform-independent multithreaded code. C++11 addressed this problem by including a standard threading library.
     </p>
     <p class="calibre13" id="c27-para-0006">
      Multithreaded programming is a complicated subject. This chapter introduces multithreaded programming using the standard threading library, but it cannot go into all of the details due to space constraints. Entire books have been written about developing multithreaded programs. If you are interested in more details, consult one of the references in the multithreading section of
      <a class="calibre5" href="b02.xhtml">
       Appendix B
      </a>
      , “Annotated Bibliography.”
     </p>
     <p class="calibre13" id="c27-para-0007">
      There are also third-party C++ libraries that try to make multithreaded programming more platform independent, such as
      <code class="calibre21">
       pthreads
      </code>
      and the
      <code class="calibre21">
       boost::thread
      </code>
      library. However, because these libraries are not part of the C++ standard, they are not discussed in this book.
     </p>
    </section>
    <section aria-labelledby="head-2-268" class="calibre2">
     <span class="calibre" id="c27-sec-0004">
     </span>
     <h2 class="calibre6" id="head-2-268">
      INTRODUCTION
     </h2>
     <p class="calibre13">
      There are three major styles of executing multiple tasks:
     </p>
     <ul class="check" id="c27-list-0002">
      <li class="calibre9" id="c27-li-0012">
       <b class="calibre14">
        Sequential execution:
       </b>
       Each task is executed one after the other.
      </li>
      <li class="calibre9" id="c27-li-0013">
       <b class="calibre14">
        Concurrent execution:
       </b>
       Multiple tasks can be executing seemingly at the same time, but this can be because the operating system is giving a task a tiny amount of time, known as a
       <i class="calibre18">
        time slice
       </i>
       , to do some work, then giving another task a time slice to do its work, and so on. This task switching keeps ongoing until tasks are finished.
      </li>
      <li class="calibre9" id="c27-li-0014">
       <b class="calibre14">
        Parallel execution:
       </b>
       Multiple tasks are truly executing at the same time for example, on multiple processor units.
      </li>
     </ul>
     <p class="calibre13" id="c27-para-0009">
      Multithreaded programming allows you to execute multiple tasks concurrently (perhaps even in parallel). As a result, you can take advantage of the multiple processor units inside virtually all systems today. Two decades ago, the processor market was racing for the highest frequency, which is perfect for single-threaded applications. Around 2005, this race stopped due to a combination of power and heat management problems. Since then, the processor market is racing toward the most cores on a single processor chip. Quad- and octa-core processors are common, but processors with up to 128 and more cores are available.
     </p>
     <p class="calibre13" id="c27-para-0010">
      Similarly, if you look at the processors on graphics cards, called graphical processing units (GPUs), you'll see that they are massively parallel processors. Today, high-end graphics cards have more than 16,000 cores, a number that keeps increasing rapidly! These graphics cards are used not only for
      <span aria-label="987" class="calibre20" epub:type="pagebreak" id="Page_987" role="doc-pagebreak">
      </span>
      gaming, but also to perform computationally intensive tasks, such as artificial intelligence, machine learning, image and video manipulation, protein folding (useful for discovering new drugs), processing signals as part of the Search for Extraterrestrial Intelligence (SETI) project, and so on.
     </p>
     <p class="calibre13" id="c27-para-0011">
      C++98/03 did not have support for multithreaded programming, and you had to resort to third-party libraries or to the multithreading APIs of your target operating system. Since C++11 introduced a standard multithreading library, it became easier to write cross-platform multithreaded applications. However, the current C++ standard targets only CPUs and not GPUs. This might change in the future.
     </p>
     <p class="calibre13" id="c27-para-0012">
      There are two reasons to start writing multithreaded code. First, if you have a computational problem and you manage to separate it into small pieces that can be run in parallel independently from each other, you can expect a huge performance boost when running it on multiple processor units. Second, you can modularize computations along orthogonal axes. For example, you can do long computations in a worker thread instead of blocking the UI thread, so the user interface remains responsive while a long computation occurs in the background.
     </p>
     <p class="calibre13" id="c27-para-0013">
      <a class="calibre5" href="#c27-fig-0001" id="R_c27-fig-0001">
       Figure 27.1
      </a>
      shows a situation that is perfectly suited for running in parallel. An example could be the processing of pixels of an image by an algorithm that does not require information about neighboring pixels. The algorithm could split the image into four parts. On a single-core processor, each part would be processed sequentially; on a dual-core processor, two parts would be processed in parallel; and on a quad-core processor, four parts would be processed in parallel, resulting in an almost linear scaling of the performance with the number of cores.
     </p>
     <figure class="calibre36">
      <img alt="A diagram illustrates the difference in processing times among single-core, dual-core, and quad-core processors. In the single-core section, core 1 completes process part 1, process part 2, process part 3, and process part 4 sequentially over time." class="center" src="images/c27f001.png"/>
      <figcaption class="calibre37">
       <p class="calibre13">
        <span class="figurelabel">
         <a class="calibre5" href="#R_c27-fig-0001" id="c27-fig-0001" role="doc-backlink">
          <b class="calibre14">
           FIGURE 27.1
          </b>
         </a>
        </span>
       </p>
      </figcaption>
     </figure>
     <p class="calibre13">
      Of course, it's not always possible to split the problem into parts that can be executed independently of each other in parallel. However, it can often be made parallel, at least partially, resulting in a performance increase. A difficult part of multithreaded programming is making your algorithm parallel, which is highly dependent on the type of the algorithm. Other difficulties are race conditions, deadlocks, tearing, and false sharing. These are discussed in the following sections. Options for making code thread-safe include:
     </p>
     <ul class="check" id="c27-list-0003">
      <li class="calibre9" id="c27-li-0015">
       <b class="calibre14">
        Immutable data:
       </b>
       Constant data is inherently safe to be accessed by multiple threads.
      </li>
      <li class="calibre9" id="c27-li-0016">
       <span aria-label="988" class="calibre20" epub:type="pagebreak" id="Page_988" role="doc-pagebreak">
       </span>
       <b class="calibre14">
        Atomic operations:
       </b>
       These are low-level types that automatically provide thread-safe operations.
      </li>
      <li class="calibre9" id="c27-li-0017">
       <b class="calibre14">
        Mutual exclusion and other synchronization mechanisms:
       </b>
       These are used to coordinate access to shared data from multiple threads.
      </li>
      <li class="calibre9" id="c27-li-0018">
       <b class="calibre14">
        Thread-local storage:
       </b>
       Variables that are marked as
       <code class="calibre21">
        thread_local
       </code>
       are local to a thread; other threads don't have access to them (at least not by default), so they are generally thread-safe.
      </li>
     </ul>
     <p class="calibre13">
      All these topics are touched upon in this chapter.
     </p>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature">
        <p class="calibre25" id="c27-para-0016">
         <b class="calibre14">
          NOTE
         </b>
         <i class="calibre18">
          To prevent multithreading problems, try to design your programs so that multiple threads need not read and write to shared memory. Or, use a synchronization mechanism (as described in the section “
          <a class="calibre5" href="#c27-sec-0031">
           Mutual Exclusion
          </a>
          ”) or atomic operations (as described in the section “
          <a class="calibre5" href="#c27-sec-0024">
           Atomic Operations Library
          </a>
          ”)
         </i>
         .
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0006">
      </span>
      <h3 class="calibre27" id="head-3-492">
       Race Conditions
      </h3>
      <p class="calibre13" id="c27-para-0017">
       <i class="calibre18">
        Race conditions
       </i>
       can occur when multiple threads want to access any kind of shared resources. Race conditions in the context of memory shared by multiple threads are called
       <i class="calibre18">
        data races
       </i>
       . A data race can occur when multiple threads access the same variable, and at least one of those threads writes to it. For example, suppose you have a shared variable and one thread increments this value while another thread decrements it. Incrementing and decrementing the value means that the current value needs to be retrieved from memory, incremented or decremented, and stored back in memory. Most processors have
       <code class="calibre21">
        INC
       </code>
       and
       <code class="calibre21">
        DEC
       </code>
       instructions to do these operations. On modern x86 processors, these instructions are not atomic, meaning that other instructions can be executed in the middle of the operation, which might cause the code to retrieve a wrong value.
      </p>
      <p class="calibre13" id="c27-para-0018">
       The following table shows the result when the increment is finished before the decrement starts and assumes that the initial value is 1:
      </p>
      <table border="1" class="calibre31">
       <thead class="calibre32">
        <tr class="calibre33">
         <th class="left" scope="col">
          THREAD 1 (INCREMENT)
         </th>
         <th class="left" scope="col">
          THREAD 2 (DECREMENT)
         </th>
        </tr>
       </thead>
       <tbody class="calibre34">
        <tr class="calibre33">
         <td class="bgcolor">
          load value (value = 1)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          increment value (value = 2)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          store value (value = 2)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          load value (value = 2)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          decrement value (value = 1)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          store value (value = 1)
         </td>
        </tr>
       </tbody>
      </table>
      <p class="calibre13" id="c27-para-0020">
       The final value stored in memory is 1. When the decrement thread is finished before the increment thread starts, the final value is also 1, as shown in the following table:
      </p>
      <p class="calibre13">
       <span aria-label="989" class="calibre20" epub:type="pagebreak" id="Page_989" role="doc-pagebreak">
       </span>
      </p>
      <table border="1" class="calibre31">
       <thead class="calibre32">
        <tr class="calibre33">
         <th class="left" scope="col">
          THREAD 1 (INCREMENT)
         </th>
         <th class="left" scope="col">
          THREAD 2 (DECREMENT)
         </th>
        </tr>
       </thead>
       <tbody class="calibre34">
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          load value (value = 1)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          decrement value (value = 0)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          store value (value = 0)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          load value (value = 0)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          increment value (value = 1)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          store value (value = 1)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
       </tbody>
      </table>
      <p class="calibre13" id="c27-para-0022">
       However, when the instructions are interleaved, the result is different, as shown in the following table:
      </p>
      <table border="1" class="calibre31">
       <thead class="calibre32">
        <tr class="calibre33">
         <th class="left" scope="col">
          THREAD 1 (INCREMENT)
         </th>
         <th class="left" scope="col">
          THREAD 2 (DECREMENT)
         </th>
        </tr>
       </thead>
       <tbody class="calibre34">
        <tr class="calibre33">
         <td class="bgcolor">
          load value (value = 1)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          increment value (value = 2)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          load value (value = 1)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          decrement value (value = 0)
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          store value (value = 2)
         </td>
         <td class="bgcolor">
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
         </td>
         <td class="bgcolor">
          store value (value = 0)
         </td>
        </tr>
       </tbody>
      </table>
      <p class="calibre13" id="c27-para-0024">
       The final result in this case is 0. In other words, the effect of the increment operation is lost. This is a data race.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0007">
      </span>
      <h3 class="calibre27" id="head-3-493">
       Tearing
      </h3>
      <p class="calibre13" id="c27-para-0025">
       <i class="calibre18">
        Tearing
       </i>
       is a specific case or consequence of a data race. There are two kinds of tearing:
       <i class="calibre18">
        torn read
       </i>
       and
       <i class="calibre18">
        torn write
       </i>
       . If a thread has written part of your data to memory, while another part hasn't been written yet, any other thread reading that data at that exact moment sees inconsistent data: a torn read. If two threads are writing to the data at the same time, one thread might have written part of the data, while another thread might have written another part of the data. The final result will be inconsistent: a torn write.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0008">
      </span>
      <h3 class="calibre27" id="head-3-494">
       Deadlocks
      </h3>
      <p class="calibre13" id="c27-para-0026">
       If you opt to solve a race condition by using a synchronization mechanism, such as mutual exclusion, you might run into another common problem with multithreaded programming:
       <i class="calibre18">
        deadlocks
       </i>
       . Two threads are deadlocked if they are both waiting for the other thread to do something. This can be extended to more than two threads. For example, if two threads want to acquire access to a shared resource, they need to ask for permission to access this resource. If one of the threads currently holds the permission to access the resource, but is blocked indefinitely for some other reason, then the other thread will block indefinitely as well when trying to acquire permission for the same resource.
       <span aria-label="990" class="calibre20" epub:type="pagebreak" id="Page_990" role="doc-pagebreak">
       </span>
       One mechanism to acquire permission for a shared resource is called a mutual exclusion object, or mutex for short, discussed in detail later in this chapter. For example, suppose you have two threads and two resources protected with two mutexes, A and B. Both threads acquire permission for both resources, but they acquire the permission in different order. The following table shows this situation in pseudo-code:
      </p>
      <table border="1" class="calibre31">
       <thead class="calibre32">
        <tr class="calibre33">
         <th class="left" scope="col">
          THREAD 1
         </th>
         <th class="left" scope="col">
          THREAD 2
         </th>
        </tr>
       </thead>
       <tbody class="calibre34">
        <tr class="calibre33">
         <td class="bgcolor">
          Acquire A
          <br class="calibre12"/>
          Acquire B
          <br class="calibre12"/>
          // … computeRelease BRelease A
         </td>
         <td class="bgcolor">
          Acquire B
          <br class="calibre12"/>
          Acquire A
          <br class="calibre12"/>
          // … compute
          <br class="calibre12"/>
          Release A
          <br class="calibre12"/>
          Release B
         </td>
        </tr>
       </tbody>
      </table>
      <p class="calibre13">
       Now, imagine that the code in the two threads is executed in the following order:
      </p>
      <ul class="check" id="c27-list-0004">
       <li class="calibre9" id="c27-li-0019">
        <b class="calibre14">
         Thread 1:
        </b>
        Acquire A (succeeds)
       </li>
       <li class="calibre9" id="c27-li-0020">
        <b class="calibre14">
         Thread 2:
        </b>
        Acquire B (succeeds)
       </li>
       <li class="calibre9" id="c27-li-0021">
        <b class="calibre14">
         Thread 1:
        </b>
        Acquire B (waits/blocks, because B is held by thread 2)
       </li>
       <li class="calibre9" id="c27-li-0022">
        <b class="calibre14">
         Thread 2:
        </b>
        Acquire A (waits/blocks, because A is held by thread 1)
       </li>
      </ul>
      <p class="calibre13" id="c27-para-0037">
       Both threads are now waiting indefinitely in a deadlock situation.
       <a class="calibre5" href="#c27-fig-0002" id="R_c27-fig-0002">
        Figure 27.2
       </a>
       shows a graphical representation of the deadlock. Thread 1 has acquired permission for resource A and is waiting to acquire permission for resource B. Thread 2 has acquired permission for resource B and is waiting to acquire permission for resource A. In this graphical representation, you see a cycle that depicts the deadlock. Both threads will wait indefinitely.
      </p>
      <figure class="calibre36">
       <img alt="A diagram illustrates resource B at the top, thread 1 and thread 2 in the middle, and resource A at the bottom. All are represented in rectangular boxes. Arrows indicate that both thread 1 and thread 2 require resources from resource A and resource B." class="center" src="images/c27f002.png"/>
       <figcaption class="calibre37">
        <p class="calibre13">
         <span class="figurelabel">
          <a class="calibre5" href="#R_c27-fig-0002" id="c27-fig-0002" role="doc-backlink">
           <b class="calibre14">
            FIGURE 27.2
           </b>
          </a>
         </span>
        </p>
       </figcaption>
      </figure>
      <p class="calibre13" id="c27-para-0038">
       It's best to always acquire permissions in the same order to avoid these kinds of deadlocks. You could also include mechanisms in your program to break these deadlocks. One possible solution is to try for a certain time to acquire permission for a resource. If the permission cannot be obtained within a certain time interval, the thread can stop waiting and possibly release other permissions it is currently holding. The thread can then sleep for a little bit and try again later to acquire all the resources it needs. This mechanism gives other threads the opportunity to acquire necessary permissions and continue their execution. Whether this mechanism works or not depends heavily on your specific deadlock case.
      </p>
      <p class="calibre13" id="c27-para-0039">
       The previous paragraph describes workarounds to avoid deadlocks. These exact workarounds are implemented in the Standard Library by
       <code class="calibre21">
        std::lock
       </code>
       (), described later in the section “
       <a class="calibre5" href="#c27-sec-0031">
        Mutual Exclusion
       </a>
       .” This function obtains permission for several resources with one call, without the risk of deadlocks. You should use
       <code class="calibre21">
        std::lock()
       </code>
       instead of reinventing the same workarounds. However, it's even better not to get into such a situation in the first place by avoiding having to take multiple locks at once. Ideally, try to avoid patterns that require locking at all.
      </p>
     </section>
     <span aria-label="991" class="calibre20" epub:type="pagebreak" id="Page_991" role="doc-pagebreak">
     </span>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0009">
      </span>
      <h3 class="calibre27" id="head-3-495">
       False Sharing
      </h3>
      <p class="calibre13" id="c27-para-0040">
       Most caches work with
       <i class="calibre18">
        cache lines
       </i>
       . For modern CPUs, cache lines are usually 64 bytes. If something needs to be written to a cache line, the entire line needs to be locked. This can bring a serious performance penalty for multithreaded code if your data structure is not properly designed. For example, if two threads are using two different pieces of data, but that data shares a cache line, then when one thread writes something, the other thread is blocked because the entire cache line is locked.
       <a class="calibre5" href="#c27-fig-0003" id="R_c27-fig-0003">
        Figure 27.3
       </a>
       graphically shows the situation where two threads clearly write to two different blocks of memory while sharing a cache line.
      </p>
      <figure class="calibre36">
       <img alt="A diagram illustrates the interaction between two C P U cores. C P U Core 0 and C P U Core 1 and memory. Each core has a thread connected to a cache line, both leading to a memory section with shaded squares indicating accessed data." class="center" src="images/c27f003.png"/>
       <figcaption class="calibre37">
        <p class="calibre13">
         <span class="figurelabel">
          <a class="calibre5" href="#R_c27-fig-0003" id="c27-fig-0003" role="doc-backlink">
           <b class="calibre14">
            FIGURE 27.3
           </b>
          </a>
         </span>
        </p>
       </figcaption>
      </figure>
      <p class="calibre13" id="c27-para-0041">
       You can optimize your data structures by using explicit memory alignments to make sure data that is worked on by multiple threads does not share any cache lines. To do this in a portable manner, a constant called
       <code class="calibre21">
        hardware_destructive_interference:size
       </code>
       , defined in
       <code class="calibre21">
        &lt;new&gt;
       </code>
       , can be used, which returns you the minimum recommended offset between two concurrently accessed objects to avoid cache line sharing. You can use that value in combination with the
       <code class="calibre21">
        alignas
       </code>
       keyword to properly align your data.
      </p>
     </section>
    </section>
    <section aria-labelledby="head-2-269" class="calibre2">
     <span class="calibre" id="c27-sec-0010">
     </span>
     <h2 class="calibre6" id="head-2-269">
      THREADS
     </h2>
     <p class="calibre13" id="c27-para-0042">
      The C++ threading library, defined in
      <code class="calibre21">
       &lt;thread&gt;
      </code>
      , makes it easy to launch new threads. You can specify what needs to be executed in the new thread in several ways. You can let the new thread execute a global function, the
      <code class="calibre21">
       operator()
      </code>
      of a function object, a lambda expression, or even a member function of an instance of some class. The following sections give small examples of all these techniques.
     </p>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0011">
      </span>
      <h3 class="calibre27" id="head-3-496">
       Thread with Function Pointer
      </h3>
      <p class="calibre13" id="c27-para-0043">
       Functions such as
       <code class="calibre21">
        CreateThread()
       </code>
       ,
       <code class="calibre21">
        _beginthread()
       </code>
       , and so on, on Windows, and
       <code class="calibre21">
        pthread_create()
       </code>
       with the
       <code class="calibre21">
        pthreads
       </code>
       library, require that the thread function has only one parameter. On the other hand, a function that you want to use with the standard C++
       <code class="calibre21">
        std::thread
       </code>
       class can have as many parameters as you want.
      </p>
      <p class="calibre13">
       Suppose you have a
       <code class="calibre21">
        counter()
       </code>
       function accepting two integers: the first representing an ID and the second representing the number of iterations that the function should loop. The body of the function is a single loop that loops the given number of iterations. On each iteration, a message is printed to standard output.
      </p>
      <pre class="calibre26" id="c27-code-0001"><code class="calibre21">void counter(int id, int numIterations)</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { 0 }; i &lt; numIterations; ++i) {</code>
<code class="calibre21">        println("Counter {} has value {}", id, i);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       <span aria-label="992" class="calibre20" epub:type="pagebreak" id="Page_992" role="doc-pagebreak">
       </span>
       You can launch multiple threads executing this function using
       <code class="calibre21">
        std::thread
       </code>
       . You can create a thread
       <code class="calibre21">
        t1
       </code>
       , executing
       <code class="calibre21">
        counter()
       </code>
       with arguments 1 and 6 as follows:
      </p>
      <pre class="calibre26" id="c27-code-0002"><code class="calibre21">thread t1 { counter, 1, 6 };</code></pre>
      <p class="calibre13" id="c27-para-0046">
       The constructor of the
       <code class="calibre21">
        thread
       </code>
       class is a variadic template, which means that it accepts any number of arguments. Variadic templates are discussed in detail in
       <a class="calibre5" href="c26.xhtml">
        Chapter 26
       </a>
       , “Advanced Templates.” The first argument is a callable object (such as a function pointer—in this example, a pointer to the function
       <code class="calibre21">
        counter()
       </code>
       ) to execute in the new thread. Any subsequent arguments are passed to this callable when execution of the thread starts.
      </p>
      <p class="calibre13" id="c27-para-0047">
       A
       <code class="calibre21">
        thread
       </code>
       object is said to be
       <i class="calibre18">
        joinable
       </i>
       if it represents or represented an active thread in the system. Even when the thread has finished executing, a
       <code class="calibre21">
        thread
       </code>
       object remains in the joinable state. A default-constructed
       <code class="calibre21">
        thread
       </code>
       object is
       <i class="calibre18">
        unjoinable
       </i>
       . Before a joinable
       <code class="calibre21">
        thread
       </code>
       object is destroyed, you need to make sure to call either
       <code class="calibre21">
        join()
       </code>
       or
       <code class="calibre21">
        detach()
       </code>
       on it. A call to
       <code class="calibre21">
        join()
       </code>
       is a blocking call: it waits until the thread has finished its work. A call to
       <code class="calibre21">
        detach()
       </code>
       detaches a
       <code class="calibre21">
        thread
       </code>
       object from its underlying OS thread, in which case the OS thread keeps running independently. Both member functions cause the thread to become unjoinable. If a
       <code class="calibre21">
        thread
       </code>
       object that is still joinable is destroyed, the destructor calls
       <code class="calibre21">
        std::terminate()
       </code>
       , which abruptly terminates all threads and the application itself. The reason for this behavior is that destroying a thread without joining it is almost certainly a bug, and terminating the program is the best available way for the library to indicate the problem.
      </p>
      <p class="calibre13">
       The following code launches two threads executing the
       <code class="calibre21">
        counter()
       </code>
       function. After launching the threads,
       <code class="calibre21">
       </code>
       <code class="calibre21">
        join()
       </code>
       is called on both threads.
      </p>
      <pre class="calibre26" id="c27-code-0003"><code class="calibre21">thread t1 { counter, 1, 6 };</code>
<code class="calibre21">thread t2 { counter, 2, 4 };</code>
<code class="calibre21">t1.join();</code>
<code class="calibre21">t2.join();</code></pre>
      <p class="calibre13">
       A possible output of this example looks as follows:
      </p>
      <pre class="calibre26" id="c27-code-0004"><code class="calibre21">Counter 2 has value 0</code>
<code class="calibre21">Counter 1 has value 0</code>
<code class="calibre21">Counter 1 has value 1</code>
<code class="calibre21">Counter 1 has value 2</code>
<code class="calibre21">Counter 1 has value 3</code>
<code class="calibre21">Counter 1 has value 4</code>
<code class="calibre21">Counter 1 has value 5</code>
<code class="calibre21">Counter 2 has value 1</code>
<code class="calibre21">Counter 2 has value 2</code>
<code class="calibre21">Counter 2 has value 3</code></pre>
      <p class="calibre13" id="c27-para-0050">
       The output on your system will be different, and it will most likely be different every time you run it. This is because two threads are executing the
       <code class="calibre21">
        counter()
       </code>
       function at the same time, so the output depends on the number of processing cores in your machine and on the thread scheduling of the operating system.
      </p>
      <p class="calibre13">
       Calling
       <code class="calibre21">
        print()
       </code>
       or
       <code class="calibre21">
        println()
       </code>
       from different threads is thread-safe and doesn't cause any data races. However, if you change the single
       <code class="calibre21">
        println()
       </code>
       statement in
       <code class="calibre21">
        counter()
       </code>
       to the following:
      </p>
      <pre class="calibre26" id="c27-code-0005"><code class="calibre21">print("Counter {} has value {}", id, i);</code>
<code class="calibre21">println("");</code></pre>
      <p class="calibre13">
       <span aria-label="993" class="calibre20" epub:type="pagebreak" id="Page_993" role="doc-pagebreak">
       </span>
       Or:
      </p>
      <pre class="calibre26" id="c27-code-0006"><code class="calibre21">cout &lt;&lt; format("Counter {} has value {}", id, i) &lt;&lt; endl;</code></pre>
      <p class="calibre13">
       Or:
      </p>
      <pre class="calibre26" id="c27-code-0007"><code class="calibre21">cout &lt;&lt; format("Counter {} has value {}", id, i);</code>
<code class="calibre21">cout &lt;&lt; endl;</code></pre>
      <p class="calibre13">
       Then, even though there are still no data races, output from different threads can be interleaved! This means that the output can be mixed together as follows:
      </p>
      <pre class="calibre26" id="c27-code-0008"><code class="calibre21">Counter 1 has value 0Counter 2 has value 0</code>
<code class="calibre21"> </code>
<code class="calibre21">Counter 2 has value 1</code>
<code class="calibre21">Counter 2 has value 2Counter 1 has value 1</code>
<code class="calibre21">…</code></pre>
      <p class="calibre13">
       This can be fixed using synchronization mechanisms, which are discussed later in this chapter.
      </p>
      <section class="calibre2">
       <aside class="calibre23">
        <div class="top">
         <hr class="calibre24"/>
        </div>
        <section class="feature">
         <p class="calibre25" id="c27-para-0056">
          <b class="calibre14">
           NOTE
          </b>
          <i class="calibre18">
           Thread function arguments are always copied into some internal storage for the thread. Use
          </i>
          <code class="calibre21">
           std::ref()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            or
           </i>
          </i>
          <code class="calibre21">
           std::cref()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            from
           </i>
          </i>
          <code class="calibre21">
           &lt;functional&gt;
          </code>
          <i class="calibre18">
           <i class="calibre18">
            to pass them by reference
           </i>
           .
          </i>
         </p>
         <div class="top">
          <hr class="calibre24"/>
         </div>
        </section>
       </aside>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0013">
      </span>
      <h3 class="calibre27" id="head-3-497">
       Thread with Function Object
      </h3>
      <p class="calibre13">
       Instead of using function pointers, you can also use a function object to execute in a thread. With the function pointer technique of the previous section, the only way to pass information to the thread is by passing arguments to the function. With function objects, you can add data members to your function object class, which you can initialize and use however you want. The following example first defines a class called
       <code class="calibre21">
        Counter
       </code>
       , which has two data members: an ID and the number of iterations for the loop. Both variables are initialized with the constructor. To make the
       <code class="calibre21">
        Counter
       </code>
       class a function object, you need to implement
       <code class="calibre21">
        operator()
       </code>
       , as discussed in
       <a class="calibre5" href="c19.xhtml">
        Chapter 19
       </a>
       , “Function Pointers, Function Objects, and Lambda Expressions.” The implementation of
       <code class="calibre21">
        operator()
       </code>
       is the same as the
       <code class="calibre21">
        counter()
       </code>
       function from the previous section. Here is the code:
      </p>
      <pre class="calibre26" id="c27-code-0009"><code class="calibre21">class Counter</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Counter(int id, int numIterations)</code>
<code class="calibre21">            : m_id { id }, m_numIterations { numIterations } { }</code>
<code class="calibre21"> </code>
<code class="calibre21">        void operator()() const</code>
<code class="calibre21">        {</code>
<code class="calibre21">            for (int i { 0 }; i &lt; m_numIterations; ++i) {</code>
<code class="calibre21">                println("Counter {} has value {}", m_id, i);</code>
<code class="calibre21">            }</code>
<code class="calibre21">        }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_id { 0 };</code>
<code class="calibre21">        int m_numIterations { 0 };</code>
<code class="calibre21">};</code></pre>
      <p class="calibre13">
       <span aria-label="994" class="calibre20" epub:type="pagebreak" id="Page_994" role="doc-pagebreak">
       </span>
       Two techniques for initializing threads with a function object are demonstrated in the following code snippet. The first technique uses the uniform initialization syntax. You create an instance of
       <code class="calibre21">
        Counter
       </code>
       with its constructor arguments and give it to the
       <code class="calibre21">
        thread
       </code>
       constructor between curly braces. The second technique defines a named instance of
       <code class="calibre21">
        Counter
       </code>
       and gives this named instance to the constructor of the
       <code class="calibre21">
        thread
       </code>
       class.
      </p>
      <pre class="calibre26" id="c27-code-0010"><code class="calibre21"><span class="color">// Using uniform initialization syntax.</span></code>
<code class="calibre21">thread t1 { Counter { 1, 20 } };</code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Using named variable.</span></code>
<code class="calibre21">Counter c { 2, 12 };</code>
<code class="calibre21">thread t2 { c };</code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Wait for threads to finish.</span></code>
<code class="calibre21">t1.join();</code>
<code class="calibre21">t2.join();</code></pre>
      <section class="calibre2">
       <aside class="calibre23">
        <div class="top">
         <hr class="calibre24"/>
        </div>
        <section class="feature">
         <p class="calibre25" id="c27-para-0060">
          <b class="calibre14">
           NOTE
          </b>
          <i class="calibre18">
           Function objects are always copied into some internal storage for the thread. If you want to execute
          </i>
          <code class="calibre21">
           operator()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            on a specific instance of your function object instead of on a copy, you should use one of the
           </i>
          </i>
          <code class="calibre21">
           std::ref()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            or
           </i>
          </i>
          <code class="calibre21">
           std::cref()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            helper functions from
           </i>
          </i>
          <code class="calibre21">
           &lt;functional&gt;
          </code>
          <i class="calibre18">
           <i class="calibre18">
            to pass your instance by reference, for example:
           </i>
          </i>
         </p>
         <pre class="calibre26" id="c27-code-0011"><code class="calibre21">Counter c { 2, 12 };</code>
<code class="calibre21">thread t2 { ref(c) };</code></pre>
         <p class="calibre25" id="c27-para-0062">
          <i class="calibre18">
           However, since
          </i>
          <code class="calibre21">
           t2
          </code>
          <i class="calibre18">
           <i class="calibre18">
            now has a reference to
           </i>
          </i>
          <code class="calibre21">
           c
          </code>
          <i class="calibre18">
           , it will be a data race (and thus undefined behavior) to read or write the contents of
          </i>
          <code class="calibre21">
           c
          </code>
          <i class="calibre18">
           <i class="calibre18">
            from the main thread before
           </i>
          </i>
          <code class="calibre21">
           t2
          </code>
          <i class="calibre18">
           <i class="calibre18">
            has finished and been joined
           </i>
           .
          </i>
         </p>
         <div class="top">
          <hr class="calibre24"/>
         </div>
        </section>
       </aside>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0016">
      </span>
      <h3 class="calibre27" id="head-3-498">
       Thread with Lambda
      </h3>
      <p class="calibre13">
       Lambda expressions fit nicely with the standard C++ threading library. Here is an example that launches a thread to execute a given lambda expression:
      </p>
      <pre class="calibre26" id="c27-code-0012"><code class="calibre21">int id { 1 };</code>
<code class="calibre21">int numIterations { 5 };</code>
<code class="calibre21">thread t1 { [id, numIterations] {</code>
<code class="calibre21">    for (int i { 0 }; i &lt; numIterations; ++i) {</code>
<code class="calibre21">        println("Counter {} has value {}", id, i);</code>
<code class="calibre21">    }</code>
<code class="calibre21">} };</code>
<code class="calibre21">t1.join();</code></pre>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0017">
      </span>
      <h3 class="calibre27" id="head-3-499">
       Thread with Member Function Pointer
      </h3>
      <p class="calibre13">
       You can specify a member function of a class to be executed in a thread. The following example defines a basic
       <code class="calibre21">
        Request
       </code>
       class with a
       <code class="calibre21">
        process()
       </code>
       member function. The
       <code class="calibre21">
        main()
       </code>
       function creates an
       <span aria-label="995" class="calibre20" epub:type="pagebreak" id="Page_995" role="doc-pagebreak">
       </span>
       instance of the
       <code class="calibre21">
        Request
       </code>
       class and launches a new thread, which executes the
       <code class="calibre21">
        process()
       </code>
       member function of the
       <code class="calibre21">
        Request
       </code>
       instance
       <code class="calibre21">
        req
       </code>
       .
      </p>
      <pre class="calibre26" id="c27-code-0013"><code class="calibre21">class Request</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Request(int id) : m_id { id } { }</code>
<code class="calibre21">        void process() { println("Processing request {}", m_id); }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_id { 0 };</code>
<code class="calibre21">};</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    Request req { 100 };</code>
<code class="calibre21">    thread t { &amp;Request::process, &amp;req };</code>
<code class="calibre21">    t.join();</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13" id="c27-para-0065">
       With this technique, you are executing a member function on a specific object in a separate thread. If other threads are accessing the same object, you need to make sure this happens in a thread-safe way to avoid data races. Mutual exclusion, discussed later in this chapter, can be used as a synchronization mechanism to make it thread-safe.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0018">
      </span>
      <h3 class="calibre27" id="head-3-500">
       Thread-Local Storage
      </h3>
      <p class="calibre13">
       The C++ standard supports
       <i class="calibre18">
        thread-local storage
       </i>
       . With a keyword called
       <code class="calibre21">
        thread_local
       </code>
       , you can mark any variable as thread-local, which means that each thread will have its own unique copy of the variable, and it will last for the entire duration of the thread. For each thread, the variable is initialized exactly once. For example, the following code defines two global variables,
       <code class="calibre21">
        k
       </code>
       and
       <code class="calibre21">
        n
       </code>
       . Every thread shares one—and only one—copy of
       <code class="calibre21">
        k
       </code>
       , while each thread has its own unique copy of
       <code class="calibre21">
        n
       </code>
       .
      </p>
      <pre class="calibre26" id="c27-code-0014"><code class="calibre21">int k;</code>
<code class="calibre21">thread_local int n;</code></pre>
      <p class="calibre13">
       The following code snippet verifies this.
       <code class="calibre21">
        threadFunction()
       </code>
       prints the current values for
       <code class="calibre21">
        k
       </code>
       and
       <code class="calibre21">
        n
       </code>
       , and then increments them both. The
       <code class="calibre21">
        main()
       </code>
       function launches a first thread, waits for it to finish, and then launches a second thread.
      </p>
      <pre class="calibre26" id="c27-code-0015"><code class="calibre21">void threadFunction(int id)</code>
<code class="calibre21">{</code>
<code class="calibre21">    println("Thread {}: k={}, n={}", id, k, n);</code>
<code class="calibre21">    ++n;</code>
<code class="calibre21">    ++k;</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    thread t1 { threadFunction, 1 }; t1.join();</code>
<code class="calibre21">    thread t2 { threadFunction, 2 }; t2.join();</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       <span aria-label="996" class="calibre20" epub:type="pagebreak" id="Page_996" role="doc-pagebreak">
       </span>
       From the following output, it's clear that there is only a single instance of
       <code class="calibre21">
        k
       </code>
       shared across all threads, while each thread has its own copy of
       <code class="calibre21">
        n
       </code>
       .
      </p>
      <pre class="calibre26" id="c27-code-0016"><code class="calibre21">Thread 1: k=0, n=0</code>
<code class="calibre21">Thread 2: k=1, n=0</code></pre>
      <p class="calibre13">
       The previous paragraphs show how
       <code class="calibre21">
        thread_local
       </code>
       works for global variables. It also works for
       <code class="calibre21">
        static
       </code>
       data members of classes and
       <code class="calibre21">
        static
       </code>
       local variables of functions. Inside a function, and only inside a function, declaring a variable as
       <code class="calibre21">
        thread_local
       </code>
       implies
       <code class="calibre21">
        static
       </code>
       , but it's recommended to be explicit about this. Here are some examples:
      </p>
      <pre class="calibre26" id="c27-code-0017"><code class="calibre21">static thread_local int x1;     <span class="color">// OK, internal linkage (See <a class="calibre5" href="c11.xhtml">Chapter 11</a>)</span></code>
<code class="calibre21">thread_local int x2;            <span class="color">// OK, external linkage (See <a class="calibre5" href="c11.xhtml">Chapter 11</a>)</span></code>
<code class="calibre21"> </code>
<code class="calibre21">class Foo</code>
<code class="calibre21">{</code>
<code class="calibre21">    static thread_local int x3; <span class="color">// OK</span></code>
<code class="calibre21">    thread_local int x4;        <span class="color">// Error!</span></code>
<code class="calibre21">};</code>
<code class="calibre21"> </code>
<code class="calibre21">void f()</code>
<code class="calibre21">{</code>
<code class="calibre21">    static thread_local int x5; <span class="color">// OK</span></code>
<code class="calibre21">    thread_local int x6;        <span class="color">// OK, implicitly static!</span></code>
<code class="calibre21">}</code></pre>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0019">
      </span>
      <h3 class="calibre27" id="head-3-501">
       Canceling Threads
      </h3>
      <p class="calibre13" id="c27-para-0070">
       The C++ standard does not include any mechanism for canceling a running
       <code class="calibre21">
        thread
       </code>
       from another thread. One (partial) solution is to use the
       <code class="calibre21">
        jthread
       </code>
       class, discussed in the next section. If that's not an option, then the best way to achieve this is to provide some communication mechanism that the two threads agree upon. The simplest mechanism is to have a shared variable, which the target thread checks periodically to determine if it should terminate. Other threads can set this shared variable to indirectly instruct the thread to shut down. You have to be careful here, because this shared variable is being accessed by multiple threads, of which at least one is writing to the shared variable. To make this thread safe, it's recommended to use atomic variables or condition variables, both discussed later in this chapter.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0020">
      </span>
      <h3 class="calibre27" id="head-3-502">
       Automatically Joining Threads
      </h3>
      <p class="calibre13">
       As discussed earlier, if a
       <code class="calibre21">
        thread
       </code>
       instance is destroyed that is still joinable, the C++ runtime calls
       <code class="calibre21">
        std::terminate()
       </code>
       to terminate the application.
       <code class="calibre21">
        &lt;thread&gt;
       </code>
       also defines
       <code class="calibre21">
        std::jthread
       </code>
       , which is virtually identical to
       <code class="calibre21">
        thread
       </code>
       , except:
      </p>
      <ul class="check" id="c27-list-0005">
       <li class="calibre9" id="c27-li-0023">
        It automatically joins in its destructor.
       </li>
       <li class="calibre9" id="c27-li-0024">
        It supports cooperative cancellation.
       </li>
      </ul>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0021">
       </span>
       <h4 class="calibre29" id="head-4-380">
        Cooperative Cancellation
       </h4>
       <p class="calibre13">
        The cancellation support of
        <code class="calibre21">
         jthread
        </code>
        is called
        <i class="calibre18">
         cooperative cancellation
        </i>
        because a thread that supports cancellation needs to periodically check if it needs to cancel itself. Before an example can be given, two important classes need to be introduced, both defined in
        <code class="calibre21">
         &lt;stop_token&gt;
        </code>
        :
        <span aria-label="997" class="calibre20" epub:type="pagebreak" id="Page_997" role="doc-pagebreak">
        </span>
       </p>
       <ul class="check" id="c27-list-0006">
        <li class="calibre9" id="c27-li-0025">
         <b class="calibre14">
          <code class="calibre21">
           std::stop_token
          </code>
          :
         </b>
         Supports actively checking for a cancellation request. A cancellable thread needs to periodically call
         <code class="calibre21">
          stop_requested()
         </code>
         on a
         <code class="calibre21">
          stop_token
         </code>
         to find out if it needs to stop its work. A
         <code class="calibre21">
          stop_token
         </code>
         can be used with a
         <code class="calibre21">
          condition_variable_any
         </code>
         so a thread can wake up when it needs to stop.
        </li>
        <li class="calibre9" id="c27-li-0026">
         <b class="calibre14">
          <code class="calibre21">
           std::stop_source
          </code>
          :
         </b>
         Used to request a thread to cancel its execution. This is done by calling the
         <code class="calibre21">
          request_stop()
         </code>
         member function on a
         <code class="calibre21">
          stop_source
         </code>
         . If a
         <code class="calibre21">
          stop_source
         </code>
         is used to request a cancellation, that stop request is visible to all associated
         <code class="calibre21">
          stop_source
         </code>
         s and
         <code class="calibre21">
          stop_token
         </code>
         s. The
         <code class="calibre21">
          stop_requested()
         </code>
         member function can be used to check whether a stop has already been requested.
        </li>
       </ul>
       <p class="calibre13" id="c27-para-0073">
        If you have a
        <code class="calibre21">
         jthread
        </code>
        instance, you can get access to its
        <code class="calibre21">
         stop_token
        </code>
        and
        <code class="calibre21">
         stop_source
        </code>
        by using the
        <code class="calibre21">
         get_stop_token()
        </code>
        and
        <code class="calibre21">
         get_stop_source()
        </code>
        member functions. Additionally, the callable passed to a constructor of
        <code class="calibre21">
         jthread
        </code>
        can have a
        <code class="calibre21">
         stop_token
        </code>
        as its first parameter.
       </p>
       <p class="calibre13">
        Let's look at an example. The following code defines a
        <code class="calibre21">
         threadFunction()
        </code>
        callable that accepts a
        <code class="calibre21">
         stop_token
        </code>
        as its first parameter. Because this is cooperative cancellation, the body of this thread function uses that
        <code class="calibre21">
         stop_token
        </code>
        to check whether it needs to cancel itself. This code uses
        <code class="calibre21">
         std::this_thread::sleep_for()
        </code>
        to introduce a small delay in each loop. The argument to
        <code class="calibre21">
         sleep_for()
        </code>
        is an
        <code class="calibre21">
         std::chrono::duration
        </code>
        ; see
        <a class="calibre5" href="c22.xhtml">
         Chapter 22
        </a>
        , “Date and Time Utilities.”
       </p>
       <pre class="calibre26" id="c27-code-0018"><code class="calibre21">void threadFunction(stop_token token, int id)</code>
<code class="calibre21">{</code>
<code class="calibre21">    <b class="calibre14">while (!token.stop_requested()) {</b></code>
<code class="calibre21">        println("Thread {} doing some work.", id);</code>
<code class="calibre21">        this_thread::sleep_for(500ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">    println("Stop requested for thread {}.", id);</code>
<code class="calibre21">}</code></pre>
       <p class="calibre13">
        The following
        <code class="calibre21">
         main()
        </code>
        function creates two
        <code class="calibre21">
         jthread
        </code>
        instances to execute
        <code class="calibre21">
         threadFunction()
        </code>
        , sleeps for two seconds, writes a message that it's ending, and asks both threads to stop:
       </p>
       <pre class="calibre26" id="c27-code-0019"><code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    jthread job1 { threadFunction, 1 };</code>
<code class="calibre21">    jthread job2 { threadFunction, 2 };</code>
<code class="calibre21"> </code>
<code class="calibre21">    this_thread::sleep_for(2s);</code>
<code class="calibre21">    println("main() is ending.");</code>
<code class="calibre21"> </code>
<code class="calibre21">    job1.request_stop();</code>
<code class="calibre21">    job2.request_stop();</code>
<code class="calibre21">}</code></pre>
       <p class="calibre13">
        The following is a possible output of this program:
       </p>
       <pre class="calibre26" id="c27-code-0020"><code class="calibre21">Thread 2 doing some work.</code>
<code class="calibre21">Thread 1 doing some work.</code>
<code class="calibre21">Thread 2 doing some work.</code>
<code class="calibre21">Thread 1 doing some work.</code>
<code class="calibre21">Thread 2 doing some work.</code>
<code class="calibre21">Thread 1 doing some work.</code>
<code class="calibre21">Thread 2 doing some work.</code>
<span aria-label="998" class="calibre20" epub:type="pagebreak" id="Page_998" role="doc-pagebreak"></span><code class="calibre21">Thread 1 doing some work.</code>
<code class="calibre21">main() is ending.</code>
<code class="calibre21">Stop requested for thread 2.</code>
<code class="calibre21">Stop requested for thread 1.</code></pre>
       <p class="calibre13" id="c27-para-0077">
        The destructor of
        <code class="calibre21">
         jthread
        </code>
        automatically requests its thread to stop executing before joining it, so the previous
        <code class="calibre21">
         main()
        </code>
        function can be simplified slightly by omitting the two calls to
        <code class="calibre21">
         request_stop()
        </code>
        .
       </p>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0022">
      </span>
      <h3 class="calibre27" id="head-3-503">
       Retrieving Results from Threads
      </h3>
      <p class="calibre13">
       As you saw in the previous examples, launching a new thread is pretty easy. However, in most cases you are probably interested in results produced by the thread. For example, if your thread performs some mathematical calculations, you really would like to get the results out of the thread once the thread is finished. One way is to pass a pointer or reference to a result variable to the thread in which the thread stores the results. Another technique is to store the results inside class data members of a function object, which you can retrieve later once the thread has finished executing. This works only if you use
       <code class="calibre21">
        std::ref()
       </code>
       to pass your function object by reference to the
       <code class="calibre21">
        jthread
       </code>
       constructor. Here is an example:
      </p>
      <pre class="calibre26" id="c27-code-0021"><code class="calibre21">class Calculator</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Calculator(int a, int b) : m_a { a }, m_b { b } {}</code>
<code class="calibre21">        void operator()() { result = m_a * m_b; }</code>
<code class="calibre21">        int getResult() const { return result; }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_a { 0 };</code>
<code class="calibre21">        int m_b { 0 };</code>
<code class="calibre21">        int result { 0 };</code>
<code class="calibre21">};</code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    Calculator calculator { 21, 2 };</code>
<code class="calibre21">    jthread job { ref(calculator) };</code>
<code class="calibre21">    job.join();</code>
<code class="calibre21">    println("21*2 = {}", calculator.getResult());</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       This correctly outputs:
      </p>
      <pre class="calibre26" id="c27-code-0022"><code class="calibre21">21*2 = 42</code></pre>
      <p class="calibre13">
       If you don't use
       <code class="calibre21">
        ref()
       </code>
       and initialize
       <code class="calibre21">
        job
       </code>
       as follows, then the output will be
       <code class="calibre21">
        21*2 = 0
       </code>
       :
      </p>
      <pre class="calibre26" id="c27-code-0023"><code class="calibre21">jthread job { calculator };</code></pre>
      <p class="calibre13" id="c27-para-0081">
       However, there is another easier mechanism to obtain a result from threads:
       <i class="calibre18">
        futures
       </i>
       . Futures also make it easier to handle errors that occur inside your threads. They are discussed later in this chapter.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0023">
      </span>
      <h3 class="calibre27" id="head-3-504">
       Copying and Rethrowing Exceptions
      </h3>
      <p class="calibre13" id="c27-para-0082">
       The whole exception mechanism in C++ works perfectly fine, as long as it stays within one single thread. Every thread can throw its own exceptions, but they need to be caught within their own thread. If a thread throws an exception and it is not caught inside the thread, the C++ runtime calls
       <span aria-label="999" class="calibre20" epub:type="pagebreak" id="Page_999" role="doc-pagebreak">
       </span>
       <code class="calibre21">
        std::terminate()
       </code>
       , which terminates the whole application. Exceptions thrown in one thread cannot be caught in another thread. This introduces quite a few problems when you would like to use exception handling in combination with multithreaded programming.
      </p>
      <p class="calibre13">
       Without the standard threading library, it's difficult if not impossible to gracefully handle exceptions across threads. The standard threading library solves this issue with the following exception-related functions. These functions work not only with
       <code class="calibre21">
        std::exception
       </code>
       s, but also with other kinds of exceptions,
       <code class="calibre21">
        int
       </code>
       s,
       <code class="calibre21">
        string
       </code>
       s, custom exceptions, and so on:
      </p>
      <ul class="check" id="c27-list-0007">
       <li class="calibre9" id="c27-li-0027">
        <code class="calibre21">
         exception_ptr current_exception() noexcept;
        </code>
        <p class="listpara" id="c27-para-0085">
         Intended to be called from inside a catch block. Returns an
         <code class="calibre21">
          exception_ptr
         </code>
         object that refers to the exception currently being handled, or a copy of the currently handled exception. A null
         <code class="calibre21">
          exception_ptr
         </code>
         object is returned if no exception is being handled. This referenced exception object is reference counted, similar to
         <code class="calibre21">
          std::shared_ptr
         </code>
         , and remains valid for as long as there is an object of type
         <code class="calibre21">
          exception_ptr
         </code>
         that is referencing it.
        </p>
       </li>
       <li class="calibre9" id="c27-li-0028">
        <code class="calibre21">
         [[noreturn]] void rethrow_exception(exception_ptr p);
        </code>
        <p class="listpara" id="c27-para-0087">
         Rethrows the exception referenced by the
         <code class="calibre21">
          exception_ptr
         </code>
         parameter (which must not be null). Rethrowing the referenced exception does not have to be done in the same thread that generated the referenced exception in the first place, which makes this feature perfectly suited for handling exceptions across different threads. The
         <code class="calibre21">
          [[noreturn]]
         </code>
         attribute makes it clear that this function never returns normally.
        </p>
       </li>
       <li class="calibre9" id="c27-li-0029">
        <code class="calibre21">
         template&lt;class E&gt; exception_ptr make_exception_ptr(E e) noexcept;
        </code>
        <p class="listpara" id="c27-para-0089">
         Creates an
         <code class="calibre21">
          exception_ptr
         </code>
         object that refers to a copy of the given exception object. This is basically a shorthand notation for the following code:
        </p>
       </li>
      </ul>
      <pre class="calibre26" id="c27-code-0024"><code class="calibre21">try { throw e; }</code>
<code class="calibre21">catch(…) { return current_exception(); }</code></pre>
      <p class="calibre13">
       Let's see how handling exceptions across different threads can be implemented using these functions. The following code defines a function that does some work and throws an exception. This function will ultimately be running in a separate thread.
      </p>
      <pre class="calibre26" id="c27-code-0025"><code class="calibre21">void doSomeWork()</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 5; ++i) { println("{}", i); }</code>
<code class="calibre21">    println("Thread throwing a runtime_error exception…");</code>
<code class="calibre21">    throw runtime_error { "Exception from thread" };</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       The following
       <code class="calibre21">
        threadFunc()
       </code>
       function wraps the call to the preceding function in a
       <code class="calibre21">
        try/catch
       </code>
       block, catching all exceptions that
       <code class="calibre21">
        doSomeWork()
       </code>
       might throw. A single argument is supplied to
       <code class="calibre21">
        threadFunc()
       </code>
       , which is of type
       <code class="calibre21">
        exception_ptr&amp;
       </code>
       . Once an exception is caught, the function
       <code class="calibre21">
        current_exception()
       </code>
       is used to get a reference to the exception being handled, which is then assigned to the
       <code class="calibre21">
        exception_ptr
       </code>
       parameter. After that, the thread exits normally.
      </p>
      <pre class="calibre26" id="c27-code-0026"><code class="calibre21">void threadFunc(exception_ptr&amp; err)</code>
<code class="calibre21">{</code>
<code class="calibre21">    try {</code>
<span aria-label="1000" class="calibre20" epub:type="pagebreak" id="Page_1000" role="doc-pagebreak"></span><code class="calibre21">        doSomeWork();</code>
<code class="calibre21">    } catch (…) {</code>
<code class="calibre21">        println("Thread caught exception, returning exception…");</code>
<code class="calibre21">        err = current_exception();</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       The following
       <code class="calibre21">
        doWorkInThread()
       </code>
       function is called from within the main thread. Its responsibility is to create a new thread and start executing
       <code class="calibre21">
        threadFunc()
       </code>
       in it. A reference to an object of type
       <code class="calibre21">
        exception_ptr
       </code>
       is given as an argument to
       <code class="calibre21">
        threadFunc()
       </code>
       . Once the thread is created, the
       <code class="calibre21">
        doWorkInThread()
       </code>
       function waits for the thread to finish by using the
       <code class="calibre21">
        join()
       </code>
       member function, after which the error object is examined. Because
       <code class="calibre21">
        exception_ptr
       </code>
       is of type
       <code class="calibre21">
        NullablePointer
       </code>
       , you can easily check it using an
       <code class="calibre21">
        if
       </code>
       statement. If it's a non-null value, the exception is rethrown in the current thread, which is the main thread in this example. Because you are rethrowing the exception in the main thread, the exception has been transferred from one thread to another thread.
      </p>
      <pre class="calibre26" id="c27-code-0027"><code class="calibre21">void doWorkInThread()</code>
<code class="calibre21">{</code>
<code class="calibre21">    exception_ptr error;</code>
<code class="calibre21">    <span class="color">// Launch thread.</span></code>
<code class="calibre21">    jthread t { threadFunc, ref(error) };</code>
<code class="calibre21">    <span class="color">// Wait for thread to finish.</span></code>
<code class="calibre21">    t.join();</code>
<code class="calibre21">    <span class="color">// See if thread has thrown any exception.</span></code>
<code class="calibre21">    if (error) {</code>
<code class="calibre21">        println("Main thread received exception, rethrowing it…");</code>
<code class="calibre21">        rethrow_exception(error);</code>
<code class="calibre21">    } else {</code>
<code class="calibre21">        println("Main thread did not receive any exception.");</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       The
       <code class="calibre21">
        main()
       </code>
       function is pretty straightforward. It calls
       <code class="calibre21">
        doWorkInThread()
       </code>
       and wraps the call in a
       <code class="calibre21">
        try/catch
       </code>
       block to catch exceptions thrown by the thread spawned by
       <code class="calibre21">
        doWorkInThread()
       </code>
       .
      </p>
      <pre class="calibre26" id="c27-code-0028"><code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    try {</code>
<code class="calibre21">        doWorkInThread();</code>
<code class="calibre21">    } catch (const exception&amp; e) {</code>
<code class="calibre21">        println("Main function caught: '{}'", e.what());</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       The output is as follows:
      </p>
      <pre class="calibre26" id="c27-code-0029"><code class="calibre21">0</code>
<code class="calibre21">1</code>
<code class="calibre21">2</code>
<code class="calibre21">3</code>
<code class="calibre21">4</code>
<code class="calibre21">Thread throwing a runtime_error exception…</code>
<code class="calibre21">Thread caught exception, returning exception…</code>
<code class="calibre21">Main thread received exception, rethrowing it…</code>
<code class="calibre21">Main function caught: 'Exception from thread'</code></pre>
      <p class="calibre13" id="c27-para-0095">
       <span aria-label="1001" class="calibre20" epub:type="pagebreak" id="Page_1001" role="doc-pagebreak">
       </span>
       To keep the examples in this chapter compact and to the point, their
       <code class="calibre21">
        main()
       </code>
       functions usually use
       <code class="calibre21">
        join()
       </code>
       , either explicitly or implicitly with
       <code class="calibre21">
        jthread
       </code>
       , to block the main thread and to wait until threads have finished. Of course, in real-world applications you do not want to block your main thread. For example, in a GUI application, blocking your main thread means that the UI becomes unresponsive. In that case, you can use a messaging paradigm to communicate between threads. For example, the earlier
       <code class="calibre21">
        threadFunc()
       </code>
       function could send a message to the UI thread with as argument a copy of the result of
       <code class="calibre21">
        current_exception()
       </code>
       .
      </p>
     </section>
    </section>
    <section aria-labelledby="head-2-270" class="calibre2">
     <span class="calibre" id="c27-sec-0024">
     </span>
     <h2 class="calibre6" id="head-2-270">
      ATOMIC OPERATIONS LIBRARY
     </h2>
     <p class="calibre13">
      <i class="calibre18">
       Atomic types
      </i>
      allow
      <i class="calibre18">
       atomic access
      </i>
      , which means that concurrent reading and writing without additional synchronization is allowed. Without atomic operations, incrementing a variable is not thread-safe because the compiler first loads the value from memory into a register, increments it, and then stores the result back in memory. Another thread might touch the same memory during this increment operation, which is a data race. For example, the following code is not thread-safe and contains a data race. This type of data race is discussed in the beginning of this chapter.
     </p>
     <pre class="calibre26" id="c27-code-0030"><code class="calibre21">int counter { 0 };   <span class="color">// Global variable</span></code>
<code class="calibre21">…</code>
<code class="calibre21">++counter;           <span class="color">// Executed in multiple threads</span></code></pre>
     <p class="calibre13">
      You can use the
      <code class="calibre21">
       std::atomic
      </code>
      class template, defined in
      <code class="calibre21">
       &lt;atomic&gt;
      </code>
      , to make this thread-safe without explicitly using any synchronization mechanism. Here is the same code using an atomic integer:
     </p>
     <pre class="calibre26" id="c27-code-0031"><code class="calibre21">atomic&lt;int&gt; counter { 0 } ;  <span class="color">// Global variable</span></code>
<code class="calibre21">…</code>
<code class="calibre21">++counter;                   <span class="color">// Executed in multiple threads</span></code></pre>
     <p class="calibre13" id="c27-para-0098">
      <code class="calibre21">
       &lt;atomic&gt;
      </code>
      also defines named integral atomic types for all primitive types. The following table lists just a few:
     </p>
     <table border="1" class="calibre31">
      <thead class="calibre32">
       <tr class="calibre33">
        <th class="left" scope="col">
         NAMED ATOMIC TYPE
        </th>
        <th class="left" scope="col">
         EQUIVALENT STD::ATOMIC TYPE
        </th>
       </tr>
      </thead>
      <tbody class="calibre34">
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_bool
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;bool&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_char
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;char&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_uchar
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;unsigned char&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_int
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;int&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_uint
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;unsigned int&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_long
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;long&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_ulong
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;unsigned long&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_llong
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;long long&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_ullong
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;unsigned long long&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_wchar_t
         </span>
        </td>
        <td class="bgcolor">
         <span class="calibre21">
          atomic&lt;wchar_t&gt;
         </span>
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          atomic_flag
         </span>
        </td>
        <td class="bgcolor">
         (none)
        </td>
       </tr>
      </tbody>
     </table>
     <p class="calibre13" id="c27-para-0100">
      <span aria-label="1002" class="calibre20" epub:type="pagebreak" id="Page_1002" role="doc-pagebreak">
      </span>
      You can use atomic types without explicitly using any synchronization mechanism. However, underneath, operations on atomics of a certain type might use a synchronization mechanism such as a mutex. This might happen, for example, when the hardware you are targeting lacks the necessary instructions to perform an operation atomically. You can use the
      <code class="calibre21">
       is_lock_free()
      </code>
      member function on an atomic type to query whether it supports lock-free operations, that is, whether all of its operations run without any explicit synchronization mechanism underneath. There is also a
      <code class="calibre21">
       static
      </code>
      constant called
      <code class="calibre21">
       atomic&lt;T&gt;::is_always_lock_free
      </code>
      , which is
      <code class="calibre21">
       true
      </code>
      if the
      <code class="calibre21">
       atomic&lt;T&gt;
      </code>
      is always lock free, and
      <code class="calibre21">
       false
      </code>
      otherwise.
     </p>
     <p class="calibre13">
      The
      <code class="calibre21">
       std::atomic
      </code>
      class template can be used with all kinds of types, not only integral types. For example, you can create an
      <code class="calibre21">
       atomic&lt;double&gt;
      </code>
      , or an
      <code class="calibre21">
       atomic&lt;MyType&gt;
      </code>
      , but only if
      <code class="calibre21">
       MyType
      </code>
      is trivially copyable. Depending on the size of the specified type, underneath these might require explicit synchronization mechanisms. In the following example, both
      <code class="calibre21">
       Foo
      </code>
      and
      <code class="calibre21">
       Bar
      </code>
      are trivially copyable, that is,
      <code class="calibre21">
       std::is_trivially_copyable_v
      </code>
      is
      <code class="calibre21">
       true
      </code>
      for both. However, due to the size of
      <code class="calibre21">
       Foo
      </code>
      ,
      <code class="calibre21">
       atomic&lt;Foo&gt;
      </code>
      is not lock-free, while
      <code class="calibre21">
       atomic&lt;Bar&gt;
      </code>
      is.
     </p>
     <pre class="calibre26" id="c27-code-0032"><code class="calibre21">struct Foo { int m_array[123]; };</code>
<code class="calibre21">struct Bar { int m_int; };</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    atomic&lt;Foo&gt; f;</code>
<code class="calibre21">    println("{} {}", is_trivially_copyable_v&lt;Foo&gt;, f.is_lock_free()); <span class="color">// true false</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    atomic&lt;Bar&gt; b;</code>
<code class="calibre21">    println("{} {}", is_trivially_copyable_v&lt;Bar&gt;, b.is_lock_free()); <span class="color">// true true</span></code>
<code class="calibre21">}</code></pre>
     <p class="calibre13">
      When accessing a piece of data from multiple threads, atomics also solve issues with memory ordering, compiler optimizations, and so on. Basically, it's virtually never safe to read and write to the same piece of data from multiple threads without using atomics or explicit synchronization mechanisms!
     </p>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature">
        <p class="calibre25" id="c27-para-0103">
         <b class="calibre14">
          NOTE
         </b>
         <i class="calibre18">
          Memory ordering is the order in which memory is accessed. In the absence of any atomics and other synchronization mechanisms, compilers and hardware are allowed to reorder memory accesses as long as this does not affect the outcome. This is known as the as-if rule, but can cause problems in multithreaded environments.
         </i>
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <p class="calibre13" id="c27-para-0104">
      <code class="calibre21">
       atomic_flag
      </code>
      is an atomic Boolean, always lock-free, guaranteed by the C++ standard. It differs from
      <code class="calibre21">
       atomic&lt;bool&gt;
      </code>
      in that it does not provide an assignment operator; instead, it provides named member functions
      <code class="calibre21">
       clear()
      </code>
      ,
      <code class="calibre21">
       test()
      </code>
      , and
      <code class="calibre21">
       test_and_set()
      </code>
      . An example of using
      <code class="calibre21">
       atomic_flag
      </code>
      is given in the mutual exclusion section for the implementation of a spinlock later in this chapter.
     </p>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0026">
      </span>
      <h3 class="calibre27" id="head-3-505">
       Atomic Operations
      </h3>
      <p class="calibre13" id="c27-para-0105">
       The C++ standard defines a number of special operations on
       <code class="calibre21">
        atomic&lt;T&gt;
       </code>
       . This section describes a few of those operations. For a full list, consult a Standard Library Reference (see
       <a class="calibre5" href="b02.xhtml">
        Appendix B
       </a>
       ).
      </p>
      <p class="calibre13">
       <span aria-label="1003" class="calibre20" epub:type="pagebreak" id="Page_1003" role="doc-pagebreak">
       </span>
       Our first example of an atomic operation is the following:
      </p>
      <pre class="calibre26" id="c27-code-0033"><code class="calibre21">bool atomic&lt;T&gt;::compare_exchange_strong(T&amp; expected, T desired);</code></pre>
      <p class="calibre13">
       The logic implemented atomically by this operation is as follows, in pseudo-code:
      </p>
      <pre class="calibre26" id="c27-code-0034"><code class="calibre21">if (*this == expected) {</code>
<code class="calibre21">    *this = desired;</code>
<code class="calibre21">    return true;</code>
<code class="calibre21">} else {</code>
<code class="calibre21">    expected = *this;</code>
<code class="calibre21">    return false;</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       Although this logic might seem fairly strange on first sight, this operation is a key building block for doing any complicated operation on atomics. Here is an example that atomically multiplies an
       <code class="calibre21">
        atomic&lt;int&gt;
       </code>
       with a given number:
      </p>
      <pre class="calibre26" id="c27-code-0035"><code class="calibre21">void atomicallyMultiply(atomic&lt;int&gt;&amp; a, int n)</code>
<code class="calibre21">{</code>
<code class="calibre21">    int expected { a.load() };</code>
<code class="calibre21">    int desired { n * expected };</code>
<code class="calibre21">    while (!a.compare_exchange_strong(expected, desired)) {</code>
<code class="calibre21">        desired = n * expected;</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    atomic&lt;int&gt; value { 10 };</code>
<code class="calibre21">    println("Value = {}", value.load());</code>
<code class="calibre21">    atomicallyMultiply(value, 3);</code>
<code class="calibre21">    println("Result = {}", value.load());</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       A second example is
       <code class="calibre21">
        atomic&lt;T&gt;::fetch_add()
       </code>
       . It fetches the current value of the atomic type, adds the given increment to the atomic value, and returns the original non-incremented value. Here is an example:
      </p>
      <pre class="calibre26" id="c27-code-0036"><code class="calibre21">atomic&lt;int&gt; value { 10 };</code>
<code class="calibre21">println("Value = {}", value.load());</code>
<code class="calibre21">int fetched { value.fetch_add(4) };</code>
<code class="calibre21">println("Fetched = {}", fetched);</code>
<code class="calibre21">println("Value = {}", value.load());</code></pre>
      <p class="calibre13">
       If no other threads are touching the contents of the
       <code class="calibre21">
        fetched
       </code>
       and
       <code class="calibre21">
        value
       </code>
       variables, the output is as follows:
      </p>
      <pre class="calibre26" id="c27-code-0037"><code class="calibre21">Value = 10</code>
<code class="calibre21">Fetched = 10</code>
<code class="calibre21">Value = 14</code></pre>
      <p class="calibre13" id="c27-para-0111">
       Atomic integral types support the following atomic operations:
       <code class="calibre21">
        fetch_add()
       </code>
       ,
       <code class="calibre21">
        fetch_sub()
       </code>
       ,
       <code class="calibre21">
        fetch_and()
       </code>
       ,
       <code class="calibre21">
        fetch_or()
       </code>
       ,
       <code class="calibre21">
        fetch_xor()
       </code>
       ,
       <code class="calibre21">
        ++
       </code>
       ,
       <code class="calibre21">
        --
       </code>
       ,
       <code class="calibre21">
        +=
       </code>
       ,
       <code class="calibre21">
        -=
       </code>
       ,
       <code class="calibre21">
        &amp;=
       </code>
       ,
       <code class="calibre21">
        ^=
       </code>
       , and
       <code class="calibre21">
        |=
       </code>
       . Atomic pointer types support
       <code class="calibre21">
        fetch_add()
       </code>
       ,
       <code class="calibre21">
        fetch_sub()
       </code>
       ,
       <code class="calibre21">
        ++
       </code>
       ,
       <code class="calibre21">
        --
       </code>
       ,
       <code class="calibre21">
        +=
       </code>
       , and
       <code class="calibre21">
        -=
       </code>
       . Atomic floating-point types support
       <code class="calibre21">
        fetch_add()
       </code>
       and
       <code class="calibre21">
        fetch_sub()
       </code>
       .
      </p>
      <p class="calibre13">
       <span aria-label="1004" class="calibre20" epub:type="pagebreak" id="Page_1004" role="doc-pagebreak">
       </span>
       Most of the atomic operations can accept an extra parameter specifying the memory ordering that you would like. Here is an example:
      </p>
      <pre class="calibre26" id="c27-code-0038"><code class="calibre21">T atomic&lt;T&gt;::fetch_add(T value, memory_order = memory_order_seq_cst);</code></pre>
      <p class="calibre13" id="c27-para-0113">
       You can change the default
       <code class="calibre21">
        memory_order
       </code>
       . The C++ standard provides
       <code class="calibre21">
        memory_order_relaxed
       </code>
       ,
       <code class="calibre21">
        memory_order_consume
       </code>
       ,
       <code class="calibre21">
        memory_order_acquire
       </code>
       ,
       <code class="calibre21">
        memory_order_release
       </code>
       ,
       <code class="calibre21">
        memory_order_acq_rel
       </code>
       , and
       <code class="calibre21">
        memory_order_seq_cst
       </code>
       , all of which are defined in the
       <code class="calibre21">
        std
       </code>
       namespace. However, you will rarely want to use them instead of the default, unless you're an expert in this domain. While another memory order may perform better than the default according to some metrics, if you use them in a slightly incorrect way, you will again introduce data races or other difficult-to-debug threading-related problems. If you do want to know more about memory orderings, consult one of the multithreading references in
       <a class="calibre5" href="b02.xhtml">
        Appendix B
       </a>
       .
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0027">
      </span>
      <h3 class="calibre27" id="head-3-506">
       Atomic Smart Pointers
      </h3>
      <p class="calibre13" id="c27-para-0114">
       <code class="calibre21">
        atomic&lt;std::shared_ptr&lt;T&gt;&gt;
       </code>
       is supported. The control block of a
       <code class="calibre21">
        shared_ptr
       </code>
       , which stores the reference count, among other things, has always been thread-safe, which guarantees that the pointed-to object is deleted exactly once. However, anything else from a
       <code class="calibre21">
        shared_ptr
       </code>
       is not thread-safe. Using the same
       <code class="calibre21">
        shared_ptr
       </code>
       instance concurrently from multiple threads causes data races if non-
       <code class="calibre21">
        const
       </code>
       member functions are called on that
       <code class="calibre21">
        shared_ptr
       </code>
       instance, such as calling
       <code class="calibre21">
        reset()
       </code>
       , assignment,
       <code class="calibre21">
        swap()
       </code>
       , and so on. On the other hand, when using the same
       <code class="calibre21">
        atomic&lt;shared_ptr&lt;T&gt;&gt;
       </code>
       instance from multiple threads, even calling non-
       <code class="calibre21">
        const shared_ptr
       </code>
       member functions is thread-safe. Note that calling non-
       <code class="calibre21">
        const
       </code>
       member functions on the object pointed to by the
       <code class="calibre21">
        shared_ptr
       </code>
       is still not thread-safe and requires manual synchronization.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0028">
      </span>
      <h3 class="calibre27" id="head-3-507">
       Atomic References
      </h3>
      <p class="calibre13">
       <code class="calibre21">
        std::atomic_ref
       </code>
       is basically the same as
       <code class="calibre21">
        std::atomic
       </code>
       , even with the same interface, but it works with references, while
       <code class="calibre21">
        atomic
       </code>
       always makes a copy of the value it is provided with. An
       <code class="calibre21">
        atomic_ref
       </code>
       instance itself should have a shorter lifetime than the object it references. An
       <code class="calibre21">
        atomic_ref
       </code>
       is copyable, and you can create as many
       <code class="calibre21">
        atomic_ref
       </code>
       instances as you want referring to the same object. Loads and stores done through instances of
       <code class="calibre21">
        atomic_ref
       </code>
       will be atomic and do not race with each other. Loads and stores done concurrently without going through
       <code class="calibre21">
        atomic_ref
       </code>
       can still race with those atomic accesses. The
       <code class="calibre21">
        atomic_ref&lt;T&gt;
       </code>
       class template can be used with any trivially copyable type
       <code class="calibre21">
        T
       </code>
       , just as
       <code class="calibre21">
        std::atomic
       </code>
       can. Additionally, the Standard Library provides the following:
      </p>
      <ul class="check" id="c27-list-0008">
       <li class="calibre9" id="c27-li-0030">
        Partial specializations for pointer types, supporting
        <code class="calibre21">
         fetch_add()
        </code>
        and
        <code class="calibre21">
         fetch_sub()
        </code>
       </li>
       <li class="calibre9" id="c27-li-0031">
        Full specializations for integral types, supporting
        <code class="calibre21">
         fetch_add()
        </code>
        ,
        <code class="calibre21">
         fetch_sub()
        </code>
        ,
        <code class="calibre21">
         fetch_and()
        </code>
        ,
        <code class="calibre21">
         fetch_or()
        </code>
        , and
        <code class="calibre21">
         fetch_xor()
        </code>
       </li>
       <li class="calibre9" id="c27-li-0032">
        Full specializations for floating-point types, supporting
        <code class="calibre21">
         fetch_add()
        </code>
        and
        <code class="calibre21">
         fetch_sub()
        </code>
       </li>
      </ul>
      <p class="calibre13" id="c27-para-0116">
       The following section gives an example of how to use an
       <code class="calibre21">
        atomic_ref
       </code>
       .
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0029">
      </span>
      <h3 class="calibre27" id="head-3-508">
       Using Atomic Types
      </h3>
      <p class="calibre13">
       This section explains in more detail why you should use atomic types. Suppose you have the following function called
       <code class="calibre21">
        increment()
       </code>
       that increments an integer reference parameter in a loop.
      </p>
      <pre class="calibre26" id="c27-code-0039"><span aria-label="1005" class="calibre20" epub:type="pagebreak" id="Page_1005" role="doc-pagebreak"></span><code class="calibre21">void increment(int&amp; counter)</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 100; ++i) {</code>
<code class="calibre21">        ++counter;</code>
<code class="calibre21">        this_thread::sleep_for(1ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       Now, you would like to run several threads in parallel, all executing this
       <code class="calibre21">
        increment()
       </code>
       function on a shared
       <code class="calibre21">
        counter
       </code>
       variable. By implementing this naively without atomic types or without any kind of thread synchronization, you introduce data races. The following code launches 10
       <code class="calibre21">
        increment()
       </code>
       threads, after which it waits for all threads to finish by calling
       <code class="calibre21">
        join()
       </code>
       on each thread, and then prints the result:
      </p>
      <pre class="calibre26" id="c27-code-0040"><code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    int counter { 0 };</code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">        threads.emplace:back(increment, ref(counter));</code>
<code class="calibre21">    }</code>
<code class="calibre21"> </code>
<code class="calibre21">    for (auto&amp; t : threads) { t.join(); }</code>
<code class="calibre21">    println("Result = {}", counter);</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       Because
       <code class="calibre21">
        increment()
       </code>
       increments its
       <code class="calibre21">
        counter
       </code>
       parameter 100 times, and 10 threads are launched, each of which executes
       <code class="calibre21">
        increment()
       </code>
       on the same shared
       <code class="calibre21">
        counter
       </code>
       , you might expect the final result to be 1,000. If you execute this program several times, you might get the following output but with different values:
      </p>
      <pre class="calibre26" id="c27-code-0041"><code class="calibre21">Result = 982</code>
<code class="calibre21">Result = 977</code>
<code class="calibre21">Result = 984</code></pre>
      <p class="calibre13">
       This code is clearly showing a data race:
       <code class="calibre21">
        counter
       </code>
       is written concurrently from multiple threads without any synchronization. In this example, you can use an atomic type to fix the code. The following code highlights the required changes:
      </p>
      <pre class="calibre26" id="c27-code-0042"><code class="calibre21"><b class="calibre14">void increment(atomic&lt;int&gt;&amp; counter)</b></code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 100; ++i) {</code>
<code class="calibre21">        ++counter;</code>
<code class="calibre21">        this_thread::sleep_for(1ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <b class="calibre14">atomic&lt;int&gt; counter { 0 };</b></code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">        threads.emplace:back(increment, ref(counter));</code>
<code class="calibre21">    }</code>
<code class="calibre21">    for (auto&amp; t : threads) { t.join(); } </code>
<code class="calibre21">    println("Result = {}", counter);</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       <span aria-label="1006" class="calibre20" epub:type="pagebreak" id="Page_1006" role="doc-pagebreak">
       </span>
       The only modification is changing the type of the shared
       <code class="calibre21">
        counter
       </code>
       to
       <code class="calibre21">
        std::atomic&lt;int&gt;
       </code>
       instead of
       <code class="calibre21">
        int
       </code>
       . When you run this modified version, you always get 1,000 as the result:
      </p>
      <pre class="calibre26" id="c27-code-0043"><code class="calibre21">Result = 1000</code>
<code class="calibre21">Result = 1000</code>
<code class="calibre21">Result = 1000</code></pre>
      <p class="calibre13" id="c27-para-0122">
       Without explicitly adding any synchronization mechanism to the code, it is now thread safe and data race free because the
       <code class="calibre21">
        ++counter
       </code>
       operation on an atomic type loads, increments, and stores the value in one atomic transaction, which cannot be interrupted.
      </p>
      <p class="calibre13">
       With
       <code class="calibre21">
        atomic_ref
       </code>
       , you can solve the data race as follows:
      </p>
      <pre class="calibre26" id="c27-code-0044"><code class="calibre21"><b class="calibre14">void increment(int&amp; counter)</b></code>
<code class="calibre21">{</code>
<code class="calibre21">    <b class="calibre14">atomic_ref&lt;int&gt; atomicCounter { counter };</b></code>
<code class="calibre21">    for (int i { 0 }; i &lt; 100; ++i) {</code>
<code class="calibre21">        <b class="calibre14">++atomicCounter;</b></code>
<code class="calibre21">        this_thread::sleep_for(1ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <b class="calibre14">int counter { 0 };</b></code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">        threads.emplace:back(increment, ref(counter));</code>
<code class="calibre21">    }</code>
<code class="calibre21">    for (auto&amp; t : threads) { t.join(); } </code>
<code class="calibre21">    println("Result = {}", counter);</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       However, there is a new problem with both of these modified implementations: a performance problem. You should try to minimize the amount of synchronization, either atomic or explicit synchronization, because it lowers performance. For this simple example, the best and recommended solution is to let
       <code class="calibre21">
        increment()
       </code>
       calculate its result in a local variable and only after the loop add it to the
       <code class="calibre21">
        counter
       </code>
       reference. Even then, it is still required to use an
       <code class="calibre21">
        atomic
       </code>
       or
       <code class="calibre21">
        atomic_ref
       </code>
       type, because you are still writing to
       <code class="calibre21">
        counter
       </code>
       from multiple threads.
      </p>
      <pre class="calibre26" id="c27-code-0045"><code class="calibre21">void increment(atomic&lt;int&gt;&amp; counter)</code>
<code class="calibre21">{</code>
<code class="calibre21">    <b class="calibre14">int result { 0 };</b></code>
<code class="calibre21">    for (int i { 0 }; i &lt; 100; ++i) {</code>
<code class="calibre21">        <b class="calibre14">++result;</b></code>
<code class="calibre21">        this_thread::sleep_for(1ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">    <b class="calibre14">counter += result;</b></code>
<code class="calibre21">}</code></pre>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0030">
      </span>
      <h3 class="calibre27" id="head-3-509">
       Waiting on Atomic Variables
      </h3>
      <p class="calibre13" id="c27-para-0125">
       The following wait-related member functions are available for
       <code class="calibre21">
        std::atomic
       </code>
       and
       <code class="calibre21">
        atomic_ref
       </code>
       to efficiently wait until an atomic variable is modified:
      </p>
      <p class="calibre13">
       <span aria-label="1007" class="calibre20" epub:type="pagebreak" id="Page_1007" role="doc-pagebreak">
       </span>
      </p>
      <table border="1" class="calibre31">
       <thead class="calibre32">
        <tr class="calibre33">
         <th class="left" scope="col">
          MEMBER FUNCTION
         </th>
         <th class="left" scope="col">
          DESCRIPTION
         </th>
        </tr>
       </thead>
       <tbody class="calibre34">
        <tr class="calibre33">
         <td class="bgcolor">
          <span class="calibre21">
           wait(oldValue)
          </span>
         </td>
         <td class="bgcolor">
          Blocks the thread until another thread calls
          <span class="calibre21">
           notify_one()
          </span>
          or
          <code class="calibre21">
           notify_all()
          </code>
          , and the value of the atomic variable has changed, that is, is not equal to
          <code class="calibre21">
           oldValue
          </code>
          anymore. If the current value is already unequal to
          <code class="calibre21">
           oldValue
          </code>
          , then the function doesn't block at all.
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          <span class="calibre21">
           notify_one()
          </span>
         </td>
         <td class="bgcolor">
          Wakes up one thread that is blocking on a
          <span class="calibre21">
           wait()
          </span>
          call.
         </td>
        </tr>
        <tr class="calibre33">
         <td class="bgcolor">
          <span class="calibre21">
           notify_all()
          </span>
         </td>
         <td class="bgcolor">
          Wakes up all threads blocking on a
          <span class="calibre21">
           wait()
          </span>
          call.
         </td>
        </tr>
       </tbody>
      </table>
      <p class="calibre13">
       Here is an example:
      </p>
      <pre class="calibre26" id="c27-code-0046"><code class="calibre21">atomic&lt;int&gt; value { 0 };</code>
<code class="calibre21"> </code>
<code class="calibre21">jthread job { [&amp;value] {</code>
<code class="calibre21">    println("Thread starts waiting.");</code>
<code class="calibre21">    value.wait(0);</code>
<code class="calibre21">    println("Thread wakes up, value = {}", value.load());</code>
<code class="calibre21">} };</code>
<code class="calibre21"> </code>
<code class="calibre21">this_thread::sleep_for(2s);</code>
<code class="calibre21"> </code>
<code class="calibre21">println("Main thread is going to change value to 1.");</code>
<code class="calibre21">value = 1;</code>
<code class="calibre21">value.notify_all();</code></pre>
      <p class="calibre13">
       The output is as follows:
      </p>
      <pre class="calibre26" id="c27-code-0047"><code class="calibre21">Thread starts waiting.</code>
<code class="calibre21">Main thread is going to change value to 1.</code>
<code class="calibre21">Thread wakes up, value = 1</code></pre>
     </section>
    </section>
    <section aria-labelledby="head-2-271" class="calibre2">
     <span class="calibre" id="c27-sec-0031">
     </span>
     <h2 class="calibre6" id="head-2-271">
      MUTUAL EXCLUSION
     </h2>
     <p class="calibre13" id="c27-para-0129">
      If you are writing multithreaded applications, you have to be sensitive to the sequencing of operations. If your threads read and write shared data, this can be a problem. There are many ways to avoid this problem, such as never actually sharing data between threads. However, if you can't avoid sharing data, you must provide for synchronization so that only one thread at a time can change the data.
     </p>
     <p class="calibre13" id="c27-para-0130">
      Scalars such as Booleans and integers can often be synchronized properly with atomic operations, as described earlier; however, when your data is more complex and you need to use that data from multiple threads, you can provide explicit synchronization.
     </p>
     <p class="calibre13" id="c27-para-0131">
      The Standard Library has support for mutual exclusion in the form of
      <i class="calibre18">
       mutex
      </i>
      and
      <i class="calibre18">
       lock
      </i>
      classes. These can be used to implement synchronization between threads and are discussed in the following sections.
     </p>
     <span aria-label="1008" class="calibre20" epub:type="pagebreak" id="Page_1008" role="doc-pagebreak">
     </span>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0032">
      </span>
      <h3 class="calibre27" id="head-3-510">
       Mutex Classes
      </h3>
      <p class="calibre13">
       Mutex stands for
       <i class="calibre18">
        mut
       </i>
       ual
       <i class="calibre18">
        ex
       </i>
       clusion. The basic mechanism of using a mutex is as follows:
      </p>
      <ul class="check" id="c27-list-0009">
       <li class="calibre9" id="c27-li-0033">
        A thread that wants to access (read or write) memory shared with other threads tries to lock the mutex object. If another thread is currently holding this lock, the new thread that wants to gain access blocks until the lock is released or until a timeout interval expires.
       </li>
       <li class="calibre9" id="c27-li-0034">
        Once the thread has obtained the lock, it is free to use the shared memory. Of course, this assumes that all threads that want to use the shared data participate in the mutex-locking scheme.
       </li>
       <li class="calibre9" id="c27-li-0035">
        After the thread is finished reading/writing to the shared memory, it releases its lock to give some other thread an opportunity to obtain a lock on the mutex. If two or more threads are waiting on the lock, there are no guarantees as to which thread will be granted the lock and thus allowed to proceed.
       </li>
      </ul>
      <p class="calibre13" id="c27-para-0133">
       The C++ Standard Library provides
       <i class="calibre18">
        non-timed
       </i>
       and
       <i class="calibre18">
        timed mutex
       </i>
       classes, both in a
       <i class="calibre18">
        recursive
       </i>
       and
       <i class="calibre18">
        non-recursive
       </i>
       flavor. Before we discuss all these options, let's first have a look at a concept called a
       <i class="calibre18">
        spinlock
       </i>
       .
      </p>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0033">
       </span>
       <h4 class="calibre29" id="head-4-381">
        Spinlock
       </h4>
       <p class="calibre13">
        A spinlock is a synchronization mechanism where a thread uses a busy loop (spinning) to try to acquire a lock, performs its work, and releases the lock. While spinning, the thread remains active but is not doing any useful work. A mutex, on the other hand, might block the thread if the lock cannot be acquired immediately. Blocking a thread is an expensive operation that is avoided with a spinlock. Spinlocks can be useful in situations where you know the lock is going to be held for only a short time. Spinlocks can be implemented entirely in your own code. As the following code snippet demonstrates, a spinlock can be implemented using a single atomic type:
        <code class="calibre21">
         atomic_flag
        </code>
        . The spinlock-related code is highlighted.
       </p>
       <pre class="calibre26" id="c27-code-0048"><code class="calibre21">static constexpr unsigned NumberOfThreads { 50 };</code>
<code class="calibre21">static constexpr unsigned LoopsPerThread { 100 };</code>
<code class="calibre21"> </code>
<code class="calibre21">void dowork(unsigned threadNumber, vector&lt;unsigned&gt;&amp; data, &lt;b&gt;atomic_flag&amp; spinlock)&lt;/b&gt;</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (unsigned i { 0 }; i &lt; LoopsPerThread; ++i) {</code>
<code class="calibre21">        <b class="calibre14">while (spinlock.test_and_set()) { }</b> <span class="color">// Spins until lock is acquired.</span></code>
<code class="calibre21">        <span class="color">// Safe to handle shared data…</span></code>
<code class="calibre21">        data.push_back(threadNumber);</code>
<code class="calibre21">        <b class="calibre14">spinlock.clear();</b>                   <span class="color">// Releases the acquired lock.</span></code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    vector&lt;unsigned&gt; data;</code>
<code class="calibre21">&lt;?b Start?&gt;    atomic_flag dataSpinlock;&lt;?b End?&gt;</code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    for (unsigned i { 0 }; i &lt; NumberOfThreads; ++i) {</code>
<code class="calibre21">        threads.emplace:back(dowork, i, ref(data), &lt;?b Start?&gt;ref(dataSpinlock))&lt;?b End?&gt;;</code>
<code class="calibre21">    }</code>
<span aria-label="1009" class="calibre20" epub:type="pagebreak" id="Page_1009" role="doc-pagebreak"></span><code class="calibre21">    for (auto&amp; t : threads) { t.join(); }</code>
<code class="calibre21">    println("data contains {} elements, expected {}.", data.size(),</code>
<code class="calibre21">        NumberOfThreads * LoopsPerThread);</code>
<code class="calibre21">}</code></pre>
       <p class="calibre13">
        In this code, each thread tries to acquire a lock by repeatedly calling
        <code class="calibre21">
         test_and_set()
        </code>
        on an
        <code class="calibre21">
         atomic_flag
        </code>
        until it succeeds. This is the busy loop.
       </p>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0136">
           <b class="calibre14">
            WARNING
           </b>
           <i class="calibre18">
            As spinlocks use a busy waiting loop, they should be an option only when you know for sure that threads will lock the spinlock only for brief moments of time
           </i>
           .
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
       <p class="calibre13" id="c27-para-0137">
        Let's now look at which mutex classes the Standard Library provides.
       </p>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0035">
       </span>
       <h4 class="calibre29" id="head-4-382">
        Non-timed Mutex Classes
       </h4>
       <p class="calibre13">
        The Standard Library has three non-timed mutex classes:
        <code class="calibre21">
         std::mutex
        </code>
        ,
        <code class="calibre21">
         recursive_mutex
        </code>
        , and
        <code class="calibre21">
         shared_mutex
        </code>
        . The first two classes are defined in
        <code class="calibre21">
         &lt;mutex&gt;
        </code>
        , and the last one in
        <code class="calibre21">
         &lt;shared_mutex&gt;
        </code>
        . Each mutex supports the following member functions:
       </p>
       <ul class="check" id="c27-list-0010">
        <li class="calibre9" id="c27-li-0036">
         <b class="calibre14">
          <code class="calibre21">
           lock():
          </code>
         </b>
         The calling thread tries to obtain the lock and blocks until the lock has been acquired. It blocks indefinitely. If there is a desire to limit the amount of time the thread blocks, you should use a timed mutex, discussed in the next section.
        </li>
        <li class="calibre9" id="c27-li-0037">
         <b class="calibre14">
          <code class="calibre21">
           try_lock():
          </code>
         </b>
         The calling thread tries to obtain the lock. If the lock is currently held by another thread, the call returns immediately. If the lock has been obtained,
         <code class="calibre21">
          try_lock()
         </code>
         returns
         <code class="calibre21">
          true
         </code>
         ; otherwise, it returns
         <code class="calibre21">
          false
         </code>
         .
        </li>
        <li class="calibre9" id="c27-li-0038">
         <b class="calibre14">
          <code class="calibre21">
           unlock():
          </code>
         </b>
         The calling thread releases the lock it currently holds, making it available for another thread.
        </li>
       </ul>
       <p class="calibre13" id="c27-para-0139">
        <code class="calibre21">
         std::mutex
        </code>
        is a standard mutual exclusion class with exclusive ownership semantics. There can be only one thread owning the mutex. If another thread wants to obtain ownership of this mutex, it either blocks when using
        <code class="calibre21">
         lock()
        </code>
        or fails when using
        <code class="calibre21">
         try_lock()
        </code>
        . A thread already having ownership of a
        <code class="calibre21">
         mutex
        </code>
        is not allowed to call
        <code class="calibre21">
         lock()
        </code>
        or
        <code class="calibre21">
         try_lock()
        </code>
        again on that mutex. This might lead to a deadlock!
       </p>
       <p class="calibre13" id="c27-para-0140">
        <code class="calibre21">
         std::recursive_mutex
        </code>
        behaves almost identically to
        <code class="calibre21">
         mutex
        </code>
        , except that a thread already having ownership of a recursive mutex is allowed to call
        <code class="calibre21">
         lock()
        </code>
        or
        <code class="calibre21">
         try_lock()
        </code>
        again on the same recursive mutex. The calling thread should call the
        <code class="calibre21">
         unlock()
        </code>
        member function as many times as it obtained a lock on the recursive mutex.
       </p>
       <p class="calibre13" id="c27-para-0141">
        The
        <code class="calibre21">
         shared_mutex
        </code>
        class supports the concept of
        <i class="calibre18">
         shared lock ownership
        </i>
        , also known as
        <i class="calibre18">
         readers-writer lock
        </i>
        . A thread can get either
        <i class="calibre18">
         exclusive ownership
        </i>
        or
        <i class="calibre18">
         shared ownership
        </i>
        of the lock. Exclusive ownership, also known as a
        <i class="calibre18">
         write lock
        </i>
        , can be acquired only when there are no other threads having exclusive or shared ownership. Shared ownership, also known as a
        <i class="calibre18">
         read lock
        </i>
        , can be acquired if there is no other thread having exclusive ownership, even if other threads have already acquired their own shared ownership. The
        <code class="calibre21">
         shared_mutex
        </code>
        class supports
        <code class="calibre21">
         lock()
        </code>
        ,
        <code class="calibre21">
         try_lock()
        </code>
        , and
        <code class="calibre21">
         unlock()
        </code>
        . These
        <span aria-label="1010" class="calibre20" epub:type="pagebreak" id="Page_1010" role="doc-pagebreak">
        </span>
        member functions acquire and release exclusive locks. Additionally, they have the following shared ownership-related member functions:
        <code class="calibre21">
         lock_shared()
        </code>
        ,
        <code class="calibre21">
         try_lock_shared()
        </code>
        , and
        <code class="calibre21">
         unlock_shared()
        </code>
        . These work similarly to the other set of member functions but try to acquire or release shared ownership.
       </p>
       <p class="calibre13" id="c27-para-0142">
        A thread already having a lock on a
        <code class="calibre21">
         shared_mutex
        </code>
        is not allowed to try to acquire a second lock on that mutex. This might lead to a deadlock!
       </p>
       <p class="calibre13">
        Before examples on how to use these mutex classes can be given, a couple of other topics need to be discussed first. Hence, examples are discussed in the section “
        <a class="calibre5" href="#c27-sec-0046">
         Examples Using Mutexes
        </a>
        ” later in this chapter.
       </p>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0144">
           <b class="calibre14">
            WARNING
           </b>
           <i class="calibre18">
            Do not manually call the previously discussed lock and unlock member functions on any of the mutex classes discussed in this section and the next one. Mutex locks are resources, and, like all resources, they should almost exclusively be acquired using the Resource Acquisition Is Initialization (RAII) paradigm; see
            <a class="calibre5" href="c32.xhtml">
             Chapter 32
            </a>
            , “Incorporating Design Techniques and Frameworks.” The C++ Standard Library provides a number of RAII lock classes, which are discussed in the “Locks” section later in this chapter. Using them is critical to avoid deadlocks. They automatically unlock a mutex when a lock object goes out of scope, so you don't need to remember to manually call
           </i>
           <code class="calibre21">
            unlock()
           </code>
           <i class="calibre18">
            <i class="calibre18">
             at the right time
            </i>
            .
           </i>
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0037">
       </span>
       <h4 class="calibre29" id="head-4-383">
        Timed Mutex Classes
       </h4>
       <p class="calibre13" id="c27-para-0145">
        When calling
        <code class="calibre21">
         lock()
        </code>
        on any of the previously discussed mutex classes, the call blocks until the lock can be obtained. On the other hand, calling
        <code class="calibre21">
         try_lock()
        </code>
        on those mutex classes tries to acquire a lock but returns immediately if not successful. There are also
        <i class="calibre18">
         timed mutex classes
        </i>
        that can try to obtain a lock but give up after a certain amount of time.
       </p>
       <p class="calibre13">
        The Standard Library provides three timed mutex classes:
        <code class="calibre21">
         std::timed_mutex
        </code>
        ,
        <code class="calibre21">
         recursive_timed_mutex
        </code>
        , and
        <code class="calibre21">
         shared_timed_mutex
        </code>
        . The first two classes are defined in
        <code class="calibre21">
         &lt;mutex&gt;
        </code>
        , and the last one in
        <code class="calibre21">
         &lt;shared_mutex&gt;
        </code>
        . They all support the
        <code class="calibre21">
         lock()
        </code>
        ,
        <code class="calibre21">
         try_lock()
        </code>
        , and
        <code class="calibre21">
         unlock()
        </code>
        member functions; and
        <code class="calibre21">
         shared_timed_mutex
        </code>
        also supports
        <code class="calibre21">
         lock_shared()
        </code>
        ,
        <code class="calibre21">
         try_lock_shared()
        </code>
        , and
        <code class="calibre21">
         unlock_shared()
        </code>
        . All these behave the same as described in the previous section. Additionally, they support the following member functions:
       </p>
       <ul class="check" id="c27-list-0011">
        <li class="calibre9" id="c27-li-0039">
         <b class="calibre14">
          <code class="calibre21">
           try_lock_for(rel_time):
          </code>
         </b>
         The calling thread tries to obtain the lock for a certain relative time. If the lock could not be obtained after the given timeout, the call fails and returns
         <code class="calibre21">
          false
         </code>
         . If the lock could be obtained within the timeout, the call succeeds and returns
         <code class="calibre21">
          true
         </code>
         . The timeout is specified as an
         <code class="calibre21">
          std::chrono::duration
         </code>
         ; see
         <a class="calibre5" href="c22.xhtml">
          Chapter 22
         </a>
         .
        </li>
        <li class="calibre9" id="c27-li-0040">
         <b class="calibre14">
          <code class="calibre21">
           try_lock_until(abs_time):
          </code>
         </b>
         The calling thread tries to obtain the lock until the system time equals or exceeds the specified absolute time. If the lock could be obtained before this time, the call returns
         <code class="calibre21">
          true
         </code>
         . If the system time passes the given absolute time, the function stops trying to obtain the lock and returns
         <code class="calibre21">
          false
         </code>
         . The absolute time is specified as an
         <code class="calibre21">
          std::chrono::time_point
         </code>
         ; see
         <a class="calibre5" href="c22.xhtml">
          Chapter 22
         </a>
         .
        </li>
       </ul>
       <p class="calibre13" id="c27-para-0147">
        <span aria-label="1011" class="calibre20" epub:type="pagebreak" id="Page_1011" role="doc-pagebreak">
        </span>
        A
        <code class="calibre21">
         shared_timed_mutex
        </code>
        also supports
        <code class="calibre21">
         try_lock_shared_for()
        </code>
        and
        <code class="calibre21">
         try_lock_shared_until()
        </code>
        .
       </p>
       <p class="calibre13" id="c27-para-0148">
        A thread already having ownership of a
        <code class="calibre21">
         timed_mutex
        </code>
        or a
        <code class="calibre21">
         shared_timed_mutex
        </code>
        is not allowed to acquire the lock a second time on that mutex. This might lead to a deadlock!
       </p>
       <p class="calibre13" id="c27-para-0149">
        A
        <code class="calibre21">
         recursive_timed_mutex
        </code>
        allows a thread to acquire a lock multiple times, just as with
        <code class="calibre21">
         recursive_mutex
        </code>
        .
       </p>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0038">
      </span>
      <h3 class="calibre27" id="head-3-511">
       Locks
      </h3>
      <p class="calibre13" id="c27-para-0150">
       A
       <i class="calibre18">
        lock
       </i>
       class is an RAII class that makes it easier to correctly obtain and release a lock on a mutex; the destructor of the lock class automatically releases the associated mutex. The C++ standard defines four types of locks:
       <code class="calibre21">
        std::lock_guard
       </code>
       ,
       <code class="calibre21">
        unique_lock
       </code>
       ,
       <code class="calibre21">
        shared_lock
       </code>
       , and
       <code class="calibre21">
        scoped_lock
       </code>
       .
      </p>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0039">
       </span>
       <h4 class="calibre29" id="head-4-384">
        lock_guard
       </h4>
       <p class="calibre13">
        <code class="calibre21">
         lock_guard
        </code>
        , defined in
        <code class="calibre21">
         &lt;mutex&gt;
        </code>
        , is a simple lock with two constructors:
       </p>
       <ul class="check" id="c27-list-0012">
        <li class="calibre9" id="c27-li-0041">
         <code class="calibre21">
          explicit lock_guard(mutex_type&amp; m);
         </code>
         <p class="listpara" id="c27-para-0153">
          Constructor accepting a reference to a mutex. Tries to obtain a lock on the mutex and blocks until the lock is obtained.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0042">
         <code class="calibre21">
          lock_guard(mutex_type&amp; m, adopt_lock_t);
         </code>
         <p class="listpara" id="c27-para-0155">
          Constructor accepting a reference to a mutex and a second argument equal to
          <code class="calibre21">
           std::adopt_lock
          </code>
          , which is a global constant of the tag type
          <code class="calibre21">
           std::adopt_lock_t
          </code>
          , which is provided by the Standard Library for exactly this purpose. The lock assumes that the calling thread has already called
          <code class="calibre21">
           lock()
          </code>
          on the referenced mutex. The
          <code class="calibre21">
           lock_guard
          </code>
          “adopts” the mutex and automatically releases the mutex when the
          <code class="calibre21">
           lock_guard
          </code>
          is destroyed.
         </p>
        </li>
       </ul>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0040">
       </span>
       <h4 class="calibre29" id="head-4-385">
        unique_lock
       </h4>
       <p class="calibre13">
        <code class="calibre21">
         std::unique_lock
        </code>
        , defined in
        <code class="calibre21">
         &lt;mutex&gt;
        </code>
        , is a more sophisticated lock that allows you to defer lock acquisition until later in the execution, long after the declaration. You can use the
        <code class="calibre21">
         owns_lock()
        </code>
        member function or the
        <code class="calibre21">
         unique_lock
        </code>
        's
        <code class="calibre21">
         bool
        </code>
        conversion operator to see if the lock has been acquired. An example of using this conversion operator is given later in this chapter in the section “Using Timed Locks.”
        <code class="calibre21">
         unique_lock
        </code>
        has several constructors:
       </p>
       <ul class="check" id="c27-list-0013">
        <li class="calibre9" id="c27-li-0043">
         <code class="calibre21">
          explicit unique_lock(mutex_type&amp; m);
         </code>
         <p class="listpara" id="c27-para-0158">
          Accepts a reference to a mutex. Tries to obtain a lock on the mutex and blocks until the lock is obtained.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0044">
         <code class="calibre21">
          unique_lock(mutex_type&amp; m, defer_lock_t) noexcept;
         </code>
         <p class="listpara" id="c27-para-0160">
          Accepts a reference to a mutex and an instance of
          <code class="calibre21">
           std::defer_lock_t
          </code>
          , for example
          <code class="calibre21">
           std::defer_lock
          </code>
          . The
          <code class="calibre21">
           unique_lock
          </code>
          stores the reference to the mutex, but does not immediately try to obtain a lock. A lock can be obtained later.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0045">
         <code class="calibre21">
          unique_lock(mutex_type&amp; m, try_to_lock_t);
         </code>
         <p class="listpara" id="c27-para-0162">
          Accepts a reference to a mutex and an instance of
          <code class="calibre21">
           std::try_to_lock_t
          </code>
          , for example
          <code class="calibre21">
           std::try_to_lock
          </code>
          . The lock tries to obtain a lock to the referenced mutex, but if it fails, it does not block, in which case, a lock can be obtained later.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0046">
         <span aria-label="1012" class="calibre20" epub:type="pagebreak" id="Page_1012" role="doc-pagebreak">
         </span>
         <code class="calibre21">
          unique_lock(mutex_type&amp; m, adopt_lock_t);
         </code>
         <p class="listpara" id="c27-para-0164">
          Accepts a reference to a mutex and an instance of
          <code class="calibre21">
           std::adopt_lock_t
          </code>
          , for example
          <code class="calibre21">
           std::adopt_lock
          </code>
          . The lock assumes that the calling thread has already called
          <code class="calibre21">
           lock()
          </code>
          on the referenced mutex. The lock “adopts” the mutex and automatically releases the mutex when the lock is destroyed.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0047">
         <code class="calibre21">
          unique_lock(mutex_type&amp; m, const chrono::time_point&lt;Clock, Duration&gt;&amp; abs_time);
         </code>
         <p class="listpara" id="c27-para-0166">
          Accepts a reference to a mutex and an absolute time. Tries to obtain a lock until the system time passes the given absolute time.
         </p>
        </li>
        <li class="calibre9" id="c27-li-0048">
         <code class="calibre21">
          unique_lock(mutex_type&amp; m, const chrono::duration&lt;Rep, Period&gt;&amp; rel_time);
         </code>
         <p class="listpara" id="c27-para-0168">
          Accepts a reference to a mutex and a relative time. Tries to get a lock on the mutex with the given relative timeout.
         </p>
        </li>
       </ul>
       <p class="calibre13" id="c27-para-0169">
        The
        <code class="calibre21">
         unique_lock
        </code>
        class also has the member functions
        <code class="calibre21">
         lock()
        </code>
        ,
        <code class="calibre21">
         try_lock()
        </code>
        ,
        <code class="calibre21">
         try_lock_for()
        </code>
        ,
        <code class="calibre21">
         try_lock_until()
        </code>
        , and
        <code class="calibre21">
         unlock()
        </code>
        , which behave as explained in the section “
        <a class="calibre5" href="#c27-sec-0037">
         Timed Mutex Classes
        </a>
        ,” earlier in this chapter.
       </p>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0041">
       </span>
       <h4 class="calibre29" id="head-4-386">
        shared_lock
       </h4>
       <p class="calibre13" id="c27-para-0170">
        The
        <code class="calibre21">
         shared_lock
        </code>
        class, defined in
        <code class="calibre21">
         &lt;shared_mutex&gt;
        </code>
        , has the same type of constructors and the same member functions as
        <code class="calibre21">
         unique_lock
        </code>
        . The difference is that
        <code class="calibre21">
         shared_lock
        </code>
        calls the shared ownership-related member functions on the underlying shared mutex. Thus, the member functions of
        <code class="calibre21">
         shared_lock
        </code>
        are called
        <code class="calibre21">
         lock()
        </code>
        ,
        <code class="calibre21">
         try_lock()
        </code>
        , and so on, but on the underlying shared mutex they call
        <code class="calibre21">
         lock_shared()
        </code>
        ,
        <code class="calibre21">
         try_lock_shared()
        </code>
        , and so on. This is done to give
        <code class="calibre21">
         shared_lock
        </code>
        the same interface as
        <code class="calibre21">
         unique_lock
        </code>
        , so it can be used as a drop-in replacement for
        <code class="calibre21">
         unique_lock
        </code>
        , but acquires a shared lock instead of an exclusive lock.
       </p>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0042">
       </span>
       <h4 class="calibre29" id="head-4-387">
        Acquiring Multiple Locks at Once
       </h4>
       <p class="calibre13" id="c27-para-0171">
        C++ has two generic lock functions that you can use to obtain locks on multiple mutex objects at once without the risk of creating deadlocks. Both functions are defined in the
        <code class="calibre21">
         std
        </code>
        namespace, and both are variadic function templates, as discussed in
        <a class="calibre5" href="c26.xhtml">
         Chapter 26
        </a>
        .
       </p>
       <p class="calibre13">
        The first function,
        <code class="calibre21">
         lock()
        </code>
        , locks all the given mutex objects in an unspecified order without the risk of deadlocks. If one of the mutex lock calls throws an exception,
        <code class="calibre21">
         unlock()
        </code>
        is called on all locks that have already been obtained. Its prototype is as follows:
       </p>
       <pre class="calibre26" id="c27-code-0049"><code class="calibre21">template &lt;class L1, class L2, class… Ln&gt; void lock(L1&amp;, L2&amp;, Ln&amp;…);</code></pre>
       <p class="calibre13" id="c27-para-0173">
        <code class="calibre21">
         try_lock()
        </code>
        has a similar prototype, but it tries to obtain a lock on all the given mutex objects by calling
        <code class="calibre21">
         try_lock()
        </code>
        on each of them in sequence. It returns -1 if all calls to
        <code class="calibre21">
         try_lock()
        </code>
        succeed. If any
        <code class="calibre21">
         try_lock()
        </code>
        fails,
        <code class="calibre21">
         unlock()
        </code>
        is called on all locks that have already been obtained, and the return value is the zero-based index of the mutex argument on which
        <code class="calibre21">
         try_lock()
        </code>
        failed.
       </p>
       <p class="calibre13">
        <span aria-label="1013" class="calibre20" epub:type="pagebreak" id="Page_1013" role="doc-pagebreak">
        </span>
        The following example demonstrates how to use the generic
        <code class="calibre21">
         lock()
        </code>
        function. The
        <code class="calibre21">
         process()
        </code>
        function first creates two locks, one for each mutex, and gives an instance of
        <code class="calibre21">
         std::defer_lock_t
        </code>
        as a second argument to tell
        <code class="calibre21">
         unique_lock
        </code>
        not to acquire the lock during construction. The call to
        <code class="calibre21">
         std::lock()
        </code>
        then acquires both locks without the risk of deadlocks.
       </p>
       <pre class="calibre26" id="c27-code-0050"><code class="calibre21">mutex mut1;</code>
<code class="calibre21">mutex mut2;</code>
<code class="calibre21"> </code>
<code class="calibre21">void process()</code>
<code class="calibre21">{</code>
<code class="calibre21">    unique_lock lock1 { mut1, defer_lock };</code>
<code class="calibre21">    unique_lock lock2 { mut2, defer_lock };</code>
<code class="calibre21">    lock(lock1, lock2);</code>
<code class="calibre21">    <span class="color">// Locks acquired.</span></code>
<code class="calibre21">} <span class="color">// Locks automatically released.</span></code></pre>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0043">
       </span>
       <h4 class="calibre29" id="head-4-388">
        scoped_lock
       </h4>
       <p class="calibre13">
        <code class="calibre21">
         std::scoped_lock
        </code>
        , defined in
        <code class="calibre21">
         &lt;mutex&gt;
        </code>
        , is similar to
        <code class="calibre21">
         lock_guard
        </code>
        , except that it accepts a variable number of mutexes. This greatly simplifies acquiring multiple locks. For instance, the example with the
        <code class="calibre21">
         process()
        </code>
        function from the previous section can be written using a
        <code class="calibre21">
         scoped_lock
        </code>
        as follows:
       </p>
       <pre class="calibre26" id="c27-code-0051"><code class="calibre21">mutex m1;</code>
<code class="calibre21">mutex m2;</code>
<code class="calibre21"> </code>
<code class="calibre21">void process()</code>
<code class="calibre21">{</code>
<code class="calibre21">    scoped_lock locks { m1, m2 }; <span class="color">// Uses class template argument deduction, CTAD.</span></code>
<code class="calibre21">    <span class="color">// Locks acquired.</span></code>
<code class="calibre21">} <span class="color">// Locks automatically released.</span></code></pre>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0177">
           <b class="calibre14">
            NOTE
           </b>
           <code class="calibre21">
            scoped_lock
           </code>
           <i class="calibre18">
            <i class="calibre18">
             simplifies acquiring multiple locks, because you don't need to worry about acquiring them in the right order
            </i>
            .
           </i>
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
       <p class="calibre13">
        <code class="calibre21">
         scoped_lock
        </code>
        is a variadic class template capable of locking an arbitrary number of mutexes. Suppose that you have an
        <code class="calibre21">
         std::array
        </code>
        with
        <code class="calibre21">
         mutex
        </code>
        es and a need to acquire a lock on all those mutexes at once. To make this easy, you can write a helper variadic function template in combination with using
        <code class="calibre21">
         std::index_sequence
        </code>
        and
        <code class="calibre21">
         make_index_sequence
        </code>
        , both of which are introduced in
        <a class="calibre5" href="c26.xhtml">
         Chapter 26
        </a>
        . Here's an example:
       </p>
       <pre class="calibre26" id="c27-code-0052"><code class="calibre21"><span class="color">// Helper function to create the actual scoped_lock instance.</span></code>
<code class="calibre21">template &lt;size_t N, size_t… Is&gt;</code>
<code class="calibre21">auto make_scoped_lock(array&lt;mutex, N&gt;&amp; mutexes, index_sequence&lt;Is…&gt;)</code>
<code class="calibre21">{</code>
<code class="calibre21">    return scoped_lock { mutexes[Is]… };</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<span aria-label="1014" class="calibre20" epub:type="pagebreak" id="Page_1014" role="doc-pagebreak"></span><code class="calibre21"><span class="color">// Helper function to make it easy to use.</span></code>
<code class="calibre21">template &lt;size_t N&gt;</code>
<code class="calibre21">auto make_scoped_lock(array&lt;mutex, N&gt;&amp; mutexes)</code>
<code class="calibre21">{</code>
<code class="calibre21">    return make_scoped_lock(mutexes, make_index_sequence&lt;N&gt;{});</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    array&lt;std::mutex, 4&gt; mutexes;</code>
<code class="calibre21">    auto lockAll { make_scoped_lock(mutexes) };</code>
<code class="calibre21">}</code></pre>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0045">
      </span>
      <h3 class="calibre27" id="head-3-512">
       std::call_once
      </h3>
      <p class="calibre13" id="c27-para-0179">
       You can use
       <code class="calibre21">
        std::call_once()
       </code>
       in combination with
       <code class="calibre21">
        std::once:flag
       </code>
       to make sure a certain function or member function is called exactly one time, no matter how many threads try to call
       <code class="calibre21">
        call_once()
       </code>
       with the same
       <code class="calibre21">
        once:flag
       </code>
       . Only one
       <code class="calibre21">
        call_once()
       </code>
       invocation actually calls the given function. If the given function does not throw any exceptions, then this invocation is called the
       <i class="calibre18">
        effective
       </i>
       <code class="calibre21">
        call_once()
       </code>
       invocation. If the given function does throw an exception, the exception is propagated back to the caller, and another caller is selected to execute the function. The effective invocation on a specific
       <code class="calibre21">
        once:flag
       </code>
       instance finishes before all other
       <code class="calibre21">
        call_once()
       </code>
       invocations on the same
       <code class="calibre21">
        once:flag
       </code>
       . Other threads calling
       <code class="calibre21">
        call_once()
       </code>
       on the same
       <code class="calibre21">
        once:flag
       </code>
       block until the effective call is finished.
       <a class="calibre5" href="#c27-fig-0004" id="R_c27-fig-0004">
        Figure 27.4
       </a>
       illustrates this with three threads. Thread 1 performs the effective
       <code class="calibre21">
        call_once()
       </code>
       invocation, thread 2 blocks until the effective invocation is finished, and thread 3 doesn't block because the effective invocation from thread 1 has already finished.
      </p>
      <figure class="calibre36">
       <img alt="A diagram illustrates the interaction of three threads. Thread 1, Thread 2, Thread 3 over time. Thread 1 initiates a call to underscore the operation. Thread 2 is blocked until Thread 1 completes its sequence. Thread 3 starts after Threads 1 and 2." class="center" src="images/c27f004.png"/>
       <figcaption class="calibre37">
        <p class="calibre13">
         <span class="figurelabel">
          <a class="calibre5" href="#R_c27-fig-0004" id="c27-fig-0004" role="doc-backlink">
           <b class="calibre14">
            FIGURE 27.4
           </b>
          </a>
         </span>
        </p>
       </figcaption>
      </figure>
      <p class="calibre13">
       The following example demonstrates the use of
       <code class="calibre21">
        call_once()
       </code>
       . The example launches three threads running
       <code class="calibre21">
        processingFunction()
       </code>
       that use some shared resources. These shared resources are initialized by calling
       <code class="calibre21">
        initializeSharedResources()
       </code>
       once. To accomplish this, each thread calls
       <code class="calibre21">
        call_once()
       </code>
       with a global
       <code class="calibre21">
        once:flag
       </code>
       . The result is that only one thread effectively executes
       <code class="calibre21">
        initializeSharedResources()
       </code>
       , and exactly one time. While this
       <code class="calibre21">
        call_once()
       </code>
       call is in progress, other threads block until
       <code class="calibre21">
        initializeSharedResources()
       </code>
       returns.
      </p>
      <pre class="calibre26" id="c27-code-0053"><code class="calibre21">once:flag g_onceFlag;</code>
<code class="calibre21"> </code>
<code class="calibre21">void initializeSharedResources()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// … Initialize shared resources to be used by multiple threads.</span></code>
<code class="calibre21">    println("Shared resources initialized.");</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<span aria-label="1015" class="calibre20" epub:type="pagebreak" id="Page_1015" role="doc-pagebreak"></span><code class="calibre21">void processingFunction()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Make sure the shared resources are initialized.</span></code>
<code class="calibre21">    call_once(g_onceFlag, initializeSharedResources);</code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// … Do some work, including using the shared resources</span></code>
<code class="calibre21">    println("Processing");</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Launch 3 threads.</span></code>
<code class="calibre21">    vector&lt;jthread&gt; threads { 3 };</code>
<code class="calibre21">    for (auto&amp; t : threads) {</code>
<code class="calibre21">        t = jthread { processingFunction };</code>
<code class="calibre21">    }</code>
<code class="calibre21">    <span class="color">// No need to manually call join(), as we are using jthread.</span></code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       The output of this code is as follows:
      </p>
      <pre class="calibre26" id="c27-code-0054"><code class="calibre21">Shared resources initialized.</code>
<code class="calibre21">Processing</code>
<code class="calibre21">Processing</code>
<code class="calibre21">Processing</code></pre>
      <p class="calibre13" id="c27-para-0182">
       Of course, in this example, you could call
       <code class="calibre21">
        initializeSharedResources()
       </code>
       once in the beginning of the
       <code class="calibre21">
        main()
       </code>
       function before the threads are launched; however, that wouldn't demonstrate the use of
       <code class="calibre21">
        call_once()
       </code>
       .
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0046">
      </span>
      <h3 class="calibre27" id="head-3-513">
       Examples Using Mutexes
      </h3>
      <p class="calibre13" id="c27-para-0183">
       The following sections give a couple of examples on how to use mutexes to synchronize multiple threads.
      </p>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0047">
       </span>
       <h4 class="calibre29" id="head-4-389">
        Thread-Safe Writing to Streams
       </h4>
       <p class="calibre13">
        Earlier in this chapter, in the “Threads” section, there is an example with a class called
        <code class="calibre21">
         Counter
        </code>
        . That example mentions that C++ streams, such as
        <code class="calibre21">
         cout
        </code>
        , are data-race-free by default, but that the output from multiple threads can be interleaved. Here are two solutions to solve this interleaving issue:
       </p>
       <ul class="check" id="c27-list-0014">
        <li class="calibre9" id="c27-li-0049">
         Use a
         <i class="calibre18">
          synchronized stream
         </i>
         .
        </li>
        <li class="calibre9" id="c27-li-0050">
         Use a mutex to make sure that only one thread at a time is reading/writing to the stream object.
        </li>
       </ul>
       <section class="calibre2">
        <span class="calibre" id="c27-sec-0048">
        </span>
        <h5 class="calibre35" id="head-5-165">
         Synchronized Streams
        </h5>
        <p class="calibre13" id="c27-para-0185">
         <code class="calibre21">
          &lt;syncstream&gt;
         </code>
         defines
         <code class="calibre21">
          std::basic_osyncstream
         </code>
         with predefined type aliases
         <code class="calibre21">
          osyncstream
         </code>
         and
         <code class="calibre21">
          wosyncstream
         </code>
         for
         <code class="calibre21">
          char
         </code>
         and
         <code class="calibre21">
          wchar_t
         </code>
         streams, respectively. The
         <code class="calibre21">
          O
         </code>
         in these class names stands for output. These classes guarantee that all output done through them will appear in the final output stream the moment the synchronized stream is destroyed. It guarantees that the output cannot be interleaved by other output from other threads, as long as those threads are also using their own
         <code class="calibre21">
          osyncstream
         </code>
         objects. As far as thread-safety is concerned, the relationship between
         <code class="calibre21">
          osyncstream
         </code>
         and
         <code class="calibre21">
          ostream
         </code>
         is exactly analogous to the relationship between
         <code class="calibre21">
          atomic_ref&lt;int&gt;
         </code>
         and
         <code class="calibre21">
          int
         </code>
         .
        </p>
        <p class="calibre13">
         <span aria-label="1016" class="calibre20" epub:type="pagebreak" id="Page_1016" role="doc-pagebreak">
         </span>
         The function call operator of the earlier
         <code class="calibre21">
          Counter
         </code>
         class can be implemented as follows using an
         <code class="calibre21">
          osyncstream
         </code>
         to prevent interleaved output:
        </p>
        <pre class="calibre26" id="c27-code-0055"><code class="calibre21">class Counter</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Counter(int id, int numIterations)</code>
<code class="calibre21">            : m_id { id }, m_numIterations { numIterations } { }</code>
<code class="calibre21"> </code>
<code class="calibre21">        void operator()() const</code>
<code class="calibre21">        {</code>
<code class="calibre21">            for (int i { 0 }; i &lt; m_numIterations; ++i) {</code>
<code class="calibre21">                <b class="calibre14">osyncstream syncedCout { cout };</b></code>
<code class="calibre21">                <b class="calibre14">syncedCout &lt;&lt; format("Counter {} has value {}", m_id, i);</b></code>
<code class="calibre21">                <b class="calibre14">syncedCout &lt;&lt; endl;</b></code>
<code class="calibre21">                <b class="calibre14">// Upon destruction, syncedCout atomically flushes</b></code>
<code class="calibre21">                <b class="calibre14">// its contents into cout.</b></code>
<code class="calibre21">            }</code>
<code class="calibre21">        }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_id { 0 };</code>
<code class="calibre21">        int m_numIterations { 0 };</code>
<code class="calibre21">};</code></pre>
       </section>
       <section class="calibre2">
        <span class="calibre" id="c27-sec-0049">
        </span>
        <h5 class="calibre35" id="head-5-166">
         Using Mutexes
        </h5>
        <p class="calibre13">
         If you cannot use a synchronized stream, you can use a
         <code class="calibre21">
          mutex
         </code>
         as demonstrated in the following code snippet to synchronize all accesses to
         <code class="calibre21">
          cout
         </code>
         in the
         <code class="calibre21">
          Counter
         </code>
         class. For this, a
         <code class="calibre21">
          static mutex
         </code>
         data member is added. It should be
         <code class="calibre21">
          static
         </code>
         , because all instances of the class should use the same
         <code class="calibre21">
          mutex
         </code>
         instance.
         <code class="calibre21">
          lock_guard
         </code>
         is used to obtain a lock on the
         <code class="calibre21">
          mutex
         </code>
         before writing to
         <code class="calibre21">
          cout
         </code>
         .
        </p>
        <pre class="calibre26" id="c27-code-0056"><code class="calibre21">class Counter</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Counter(int id, int numIterations)</code>
<code class="calibre21">            : m_id { id }, m_numIterations { numIterations } { }</code>
<code class="calibre21"> </code>
<code class="calibre21">        void operator()() const</code>
<code class="calibre21">        {</code>
<code class="calibre21">            for (int i { 0 }; i &lt; m_numIterations; ++i) {</code>
<code class="calibre21">                <b class="calibre14">lock_guard lock { ms_mutex };</b></code>
<code class="calibre21">                cout &lt;&lt; format("Counter {} has value {}", m_id, i) &lt;&lt; endl;</code>
<code class="calibre21">            }</code>
<code class="calibre21">        }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_id { 0 };</code>
<code class="calibre21">        int m_numIterations { 0 };</code>
<code class="calibre21">        <b class="calibre14">inline static mutex ms_mutex;</b></code>
<code class="calibre21">};</code></pre>
        <p class="calibre13">
         This code creates a
         <code class="calibre21">
          lock_guard
         </code>
         instance on each iteration of the
         <code class="calibre21">
          for
         </code>
         loop. It is recommended to limit the time a lock is held as much as possible; otherwise, you are blocking other threads for too long.
         <span aria-label="1017" class="calibre20" epub:type="pagebreak" id="Page_1017" role="doc-pagebreak">
         </span>
         For example, if the
         <code class="calibre21">
          lock_guard
         </code>
         instance was created once right before the
         <code class="calibre21">
          for
         </code>
         loop, then you would basically lose all multithreading in this code because one thread would hold a lock for the entire duration of its
         <code class="calibre21">
          for
         </code>
         loop, and all other threads would wait for this lock to be released.
        </p>
        <section class="calibre2">
         <aside class="calibre23">
          <div class="top">
           <hr class="calibre24"/>
          </div>
          <section class="feature">
           <p class="calibre25" id="c27-para-0189">
            <b class="calibre14">
             WARNING
            </b>
            <i class="calibre18">
             Try to hold locks as short as possible. This means you should avoid using slow operations while holding a lock, such as printing messages to the console, reading data from files, accessing databases, performing long calculations, doing explicit sleeps, and so on
            </i>
            .
           </p>
           <div class="top">
            <hr class="calibre24"/>
           </div>
          </section>
         </aside>
        </section>
       </section>
       <section class="calibre2">
        <span class="calibre" id="c27-sec-0051">
        </span>
        <h5 class="calibre35" id="head-5-167">
         Using Timed Mutexes
        </h5>
        <p class="calibre13">
         The following example demonstrates how to use a timed mutex. It is the same
         <code class="calibre21">
          Counter
         </code>
         class as before, but this time it uses a
         <code class="calibre21">
          timed_mutex
         </code>
         in combination with a
         <code class="calibre21">
          unique_lock
         </code>
         . A relative time of 200 milliseconds is given to the
         <code class="calibre21">
          unique_lock
         </code>
         constructor, causing it to try to obtain a lock for 200 milliseconds. If the lock cannot be obtained within this timeout interval, the constructor returns. Afterward, you can check whether the lock has been acquired. You can do this with an
         <code class="calibre21">
          if
         </code>
         statement on the
         <code class="calibre21">
          lock
         </code>
         variable, because
         <code class="calibre21">
          unique_lock
         </code>
         defines a
         <code class="calibre21">
          bool
         </code>
         conversion operator. The timeout is specified using the chrono library, discussed in
         <a class="calibre5" href="c22.xhtml">
          Chapter 22
         </a>
         .
        </p>
        <pre class="calibre26" id="c27-code-0057"><code class="calibre21">class Counter</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        explicit Counter(int id, int numIterations)</code>
<code class="calibre21">            : m_id { id }, m_numIterations { numIterations } { }</code>
<code class="calibre21"> </code>
<code class="calibre21">        void operator()() const</code>
<code class="calibre21">        {</code>
<code class="calibre21">            for (int i { 0 }; i &lt; m_numIterations; ++i) {</code>
<code class="calibre21">                <b class="calibre14">unique_lock lock { ms_timedMutex, 200ms };</b></code>
<code class="calibre21">                <b class="calibre14">if (lock) {</b></code>
<code class="calibre21">                    cout &lt;&lt; format("Counter {} has value {}", m_id, i) &lt;&lt; endl;</code>
<code class="calibre21">                <b class="calibre14">} else {</b></code>
<code class="calibre21">                    <span class="color">// Lock not acquired in 200ms, skip output.</span></code>
<code class="calibre21">                <b class="calibre14">}</b></code>
<code class="calibre21">            }</code>
<code class="calibre21">        }</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        int m_id { 0 };</code>
<code class="calibre21">        int m_numIterations { 0 };</code>
<code class="calibre21">        <b class="calibre14">inline static timed_mutex ms_timedMutex;</b></code>
<code class="calibre21">};</code></pre>
       </section>
      </section>
      <section class="calibre2">
       <span class="calibre" id="c27-sec-0052">
       </span>
       <h4 class="calibre29" id="head-4-390">
        Double-Checked Locking
       </h4>
       <p class="calibre13">
        The
        <i class="calibre18">
         double-checked locking pattern
        </i>
        is actually an anti-pattern, which you should avoid! It is shown here because you might come across it in existing code bases. The idea of the double-checked locking pattern is to try to avoid the use of mutexes. It's a half-baked attempt at trying to write more efficient code than using a mutex. It can really go wrong when you try to make it faster than demonstrated in
        <span aria-label="1018" class="calibre20" epub:type="pagebreak" id="Page_1018" role="doc-pagebreak">
        </span>
        the upcoming example, for instance, by using relaxed atomics (not further discussed), using a regular
        <code class="calibre21">
         bool
        </code>
        instead of an
        <code class="calibre21">
         atomic&lt;bool&gt;
        </code>
        , and so on. The pattern becomes sensitive to data races, and it is hard to get right. The irony is that using
        <code class="calibre21">
         call_once()
        </code>
        will usually be faster, and using a magic static (if applicable) will be even faster.
       </p>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0192">
           <b class="calibre14">
            NOTE
           </b>
           <i class="calibre18">
            Function-local
           </i>
           <code class="calibre21">
            static
           </code>
           <i class="calibre18">
            variables are called magic statics or thread-safe statics. C++ guarantees that such local
           </i>
           <code class="calibre21">
            static
           </code>
           <i class="calibre18">
            variables are initialized in a thread-safe fashion, so you don't need any manual thread synchronization. An example of using a magic static is given in
            <a class="calibre5" href="c33.xhtml">
             Chapter 33
            </a>
            , “Applying Design Patterns,” with the discussion of the singleton pattern
           </i>
           .
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0193">
           <b class="calibre14">
            WARNING
           </b>
           <i class="calibre18">
            Avoid the double-checked locking pattern! Instead, use other mechanisms such as simple locks, atomic variables,
           </i>
           <code class="calibre21">
            call_once()
           </code>
           <i class="calibre18">
            ,
            <i class="calibre18">
             magic statics, and so on
            </i>
            .
           </i>
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
       <p class="calibre13">
        Double-checked locking could, for example, be used to make sure that resources are initialized exactly once. The following example shows how you can implement this. It is called the double-checked locking pattern because it is checking the value of the
        <code class="calibre21">
         g_initialized
        </code>
        variable twice, once before acquiring the lock and once right after acquiring the lock. The first
        <code class="calibre21">
         g_initialized
        </code>
        check is used to prevent acquiring a lock when it is not needed. The second check is required to make sure that no other thread performed the initialization between the first
        <code class="calibre21">
         g_initialized
        </code>
        check and acquiring the lock.
       </p>
       <pre class="calibre26" id="c27-code-0058"><code class="calibre21">void initializeSharedResources()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// … Initialize shared resources to be used by multiple threads.</span></code>
<code class="calibre21">    println("Shared resources initialized.");</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">atomic&lt;bool&gt; g_initialized { false };</code>
<code class="calibre21">mutex g_mutex;</code>
<code class="calibre21"> </code>
<code class="calibre21">void processingFunction()</code>
<code class="calibre21">{</code>
<code class="calibre21">    if (!g_initialized) {</code>
<code class="calibre21">        unique_lock lock { g_mutex };</code>
<code class="calibre21">        if (!g_initialized) {</code>
<code class="calibre21">            initializeSharedResources();</code>
<code class="calibre21">            g_initialized = true;</code>
<code class="calibre21">        }</code>
<code class="calibre21">    }</code>
<code class="calibre21">    print("1");</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<span aria-label="1019" class="calibre20" epub:type="pagebreak" id="Page_1019" role="doc-pagebreak"></span><code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 5; ++i) {</code>
<code class="calibre21">        threads.emplace:back(processingFunction);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
       <p class="calibre13">
        The output clearly shows that only one thread initializes the shared resources:
       </p>
       <pre class="calibre26" id="c27-code-0059"><code class="calibre21">Shared resources initialized.</code>
<code class="calibre21">11111</code></pre>
       <section class="calibre2">
        <aside class="calibre23">
         <div class="top">
          <hr class="calibre24"/>
         </div>
         <section class="feature">
          <p class="calibre25" id="c27-para-0197">
           <b class="calibre14">
            NOTE
           </b>
           <i class="calibre18">
            For this example, it's recommended to use
           </i>
           <code class="calibre21">
            call_once()
           </code>
           <i class="calibre18">
            <i class="calibre18">
             as demonstrated earlier in this chapter, instead of double-checked locking!
            </i>
           </i>
          </p>
          <div class="top">
           <hr class="calibre24"/>
          </div>
         </section>
        </aside>
       </section>
      </section>
     </section>
    </section>
    <section aria-labelledby="head-2-272" class="calibre2">
     <span class="calibre" id="c27-sec-0056">
     </span>
     <h2 class="calibre6" id="head-2-272">
      CONDITION VARIABLES
     </h2>
     <p class="calibre13" id="c27-para-0198">
      Condition variables allow a thread to block until a certain condition is set by another thread or until the system time reaches a specified time. These variables allow for explicit inter-thread communication. If you are familiar with multithreaded programming using the Win32 API, you can compare condition variables with
      <i class="calibre18">
       event objects
      </i>
      in Windows.
     </p>
     <p class="calibre13">
      <code class="calibre21">
       &lt;condition_variable&gt;
      </code>
      provides two condition variables:
     </p>
     <ul class="check" id="c27-list-0015">
      <li class="calibre9" id="c27-li-0051">
       <code class="calibre21">
        std::condition_variable
       </code>
       <b class="calibre14">
        :
       </b>
       A condition variable that can wait only on a
       <code class="calibre21">
        unique_lock&lt;mutex&gt;
       </code>
       , which, according to the C++ standard, allows for maximum efficiency on certain platforms.
      </li>
      <li class="calibre9" id="c27-li-0052">
       <code class="calibre21">
        std::condition_variable_any
       </code>
       <b class="calibre14">
        :
       </b>
       A condition variable that can wait on any kind of object, including custom lock types.
      </li>
     </ul>
     <p class="calibre13">
      A
      <code class="calibre21">
       condition_variable
      </code>
      supports the following member functions:
     </p>
     <ul class="check" id="c27-list-0016">
      <li class="calibre9" id="c27-li-0053">
       <code class="calibre21">
        notify_one();
       </code>
       <p class="listpara" id="c27-para-0202">
        Wakes up one of the threads waiting on a condition variable. This is similar to an auto-reset event in Windows.
       </p>
      </li>
      <li class="calibre9" id="c27-li-0054">
       <code class="calibre21">
        notify_all();
       </code>
       <p class="listpara" id="c27-para-0204">
        Wakes up all threads waiting on a condition variable.
       </p>
      </li>
      <li class="calibre9" id="c27-li-0055">
       <code class="calibre21">
        wait(unique_lock&lt;mutex&gt;&amp; lk);
       </code>
       <p class="listpara" id="c27-para-0206">
        The thread calling
        <code class="calibre21">
         wait()
        </code>
        should already have acquired a lock on
        <code class="calibre21">
         lk
        </code>
        . The effect of calling
        <code class="calibre21">
         wait()
        </code>
        is that it atomically calls
        <code class="calibre21">
         lk.unlock()
        </code>
        and blocks the thread, waiting for a notification. When the thread is unblocked by a
        <code class="calibre21">
         notify_one()
        </code>
        or
        <code class="calibre21">
         notify_all()
        </code>
        call in another thread, the function calls
        <code class="calibre21">
         lk.lock()
        </code>
        again, possibly blocking until the lock has been acquired, and then returns.
       </p>
      </li>
      <li class="calibre9" id="c27-li-0056">
       <span aria-label="1020" class="calibre20" epub:type="pagebreak" id="Page_1020" role="doc-pagebreak">
       </span>
       <code class="calibre21">
        wait_for(unique_lock&lt;mutex&gt;&amp; lk, const chrono::duration&lt;Rep, Period&gt;&amp; rel_time);
       </code>
       <p class="listpara" id="c27-para-0208">
        Similar to
        <code class="calibre21">
         wait()
        </code>
        , except that the thread is unblocked by a
        <code class="calibre21">
         notify_one()
        </code>
        call, a
        <code class="calibre21">
         notify_all()
        </code>
        call, or when the given timeout has expired.
       </p>
      </li>
      <li class="calibre9" id="c27-li-0057">
       <code class="calibre21">
        wait_until(unique_lock&lt;mutex&gt;&amp; lk, const chrono::time_point&lt;Clock, Duration&gt;&amp; abs_time);
       </code>
       <p class="listpara" id="c27-para-0210">
        Similar to
        <code class="calibre21">
         wait()
        </code>
        , except that the thread is unblocked by a
        <code class="calibre21">
         notify_one()
        </code>
        call, a
        <code class="calibre21">
         notify_all()
        </code>
        call, or when the system time passes the given absolute time.
       </p>
      </li>
     </ul>
     <p class="calibre13">
      There are also overloads of
      <code class="calibre21">
       wait()
      </code>
      ,
      <code class="calibre21">
       wait_for()
      </code>
      , and
      <code class="calibre21">
       wait_until()
      </code>
      that accept an extra predicate parameter. For instance, the overload of
      <code class="calibre21">
       wait()
      </code>
      accepting an extra predicate is equivalent to the following:
     </p>
     <pre class="calibre26" id="c27-code-0060"><code class="calibre21">while (!predicate())</code>
<code class="calibre21">    wait(lk);</code></pre>
     <p class="calibre13" id="c27-para-0212">
      The
      <code class="calibre21">
       condition_variable_any
      </code>
      class supports the same member functions as
      <code class="calibre21">
       condition_variable
      </code>
      , except that it accepts any kind of lock class instead of only a
      <code class="calibre21">
       unique_lock&lt;mutex&gt;
      </code>
      . The used lock class must have a
      <code class="calibre21">
       lock()
      </code>
      and
      <code class="calibre21">
       unlock()
      </code>
      member function.
     </p>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0057">
      </span>
      <h3 class="calibre27" id="head-3-514">
       Spurious Wake-Ups
      </h3>
      <p class="calibre13" id="c27-para-0213">
       Threads waiting on a condition variable can wake up when another thread calls
       <code class="calibre21">
        notify_one()
       </code>
       or
       <code class="calibre21">
        notify_all()
       </code>
       , or after a relative timeout, or when the system time reaches a certain time. However, they can also wake up
       <i class="calibre18">
        spuriously
       </i>
       . This means that a thread can wake up even if no other thread has called any notify member function and no timeouts have been reached yet. Thus, when a thread waits on a condition variable and wakes up, it needs to check why it woke up. One way to check for this is by using one of the versions of
       <code class="calibre21">
        wait()
       </code>
       accepting a predicate, as demonstrated in the following section.
      </p>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0058">
      </span>
      <h3 class="calibre27" id="head-3-515">
       Using Condition Variables
      </h3>
      <p class="calibre13">
       As an example, condition variables can be used for background threads processing items from a queue. You can define a queue in which you insert items to be processed. A background thread waits until there are items in the queue. When an item is inserted into the queue, the thread wakes up, processes the item, and goes back to sleep, waiting for the next item. Suppose you have the following queue:
      </p>
      <pre class="calibre26" id="c27-code-0061"><code class="calibre21">queue&lt;string&gt; m_queue;</code></pre>
      <p class="calibre13">
       To make sure that only one thread is modifying this queue at any given time, we add a mutex:
      </p>
      <pre class="calibre26" id="c27-code-0062"><code class="calibre21">mutex m_mutex;</code></pre>
      <p class="calibre13">
       To be able to notify a background thread when an item is added, we also add a condition variable:
      </p>
      <pre class="calibre26" id="c27-code-0063"><code class="calibre21">condition_variable m_condVar;</code></pre>
      <p class="calibre13">
       <span aria-label="1021" class="calibre20" epub:type="pagebreak" id="Page_1021" role="doc-pagebreak">
       </span>
       A thread that wants to add an item to the queue first acquires a lock on the mutex, then adds the item to the queue, and notifies the background thread. Calling
       <code class="calibre21">
        notify_one()
       </code>
       or
       <code class="calibre21">
        notify_all()
       </code>
       can be done whether you currently have the lock or not; both work.
      </p>
      <pre class="calibre26" id="c27-code-0064"><code class="calibre21"><span class="color">// Lock mutex and add entry to the queue.</span></code>
<code class="calibre21">lock_guard lock { m_mutex };</code>
<code class="calibre21">m_queue.push(entry);</code>
<code class="calibre21"><span class="color">// Notify condition variable to wake up thread.</span></code>
<code class="calibre21">m_condVar.notify_all();</code></pre>
      <p class="calibre13">
       The background thread waits for notifications in an infinite loop, as follows. Note the use of
       <code class="calibre21">
        wait()
       </code>
       accepting a predicate to correctly handle spurious wake-ups. The predicate checks if there really is something in the queue. When the call to
       <code class="calibre21">
        wait()
       </code>
       returns, you are sure there is something in the queue.
      </p>
      <pre class="calibre26" id="c27-code-0065"><code class="calibre21">unique_lock lock { m_mutex };</code>
<code class="calibre21">while (true) {</code>
<code class="calibre21">    <span class="color">// Wait for a notification.</span></code>
<code class="calibre21">    m_condVar.wait(lock, [this]{ return !m_queue.empty(); });</code>
<code class="calibre21">    <span class="color">// Whenever we reach this line, the mutex is locked and the queue is non-empty.</span></code>
<code class="calibre21">    <span class="color">// Process queue item…</span></code>
<code class="calibre21">    m_queue.pop();</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13" id="c27-para-0219">
       The “Example: Multithreaded Logger Class” section toward the end of this chapter, provides a complete example on how to use condition variables to send notifications to other threads.
      </p>
      <p class="calibre13">
       The C++ standard also defines a helper function called
       <code class="calibre21">
        std::notify_all_at_thread_exit(cond, lk)
       </code>
       where
       <code class="calibre21">
        cond
       </code>
       is a condition variable and
       <code class="calibre21">
        lk
       </code>
       is a
       <code class="calibre21">
        unique_lock&lt;mutex&gt;
       </code>
       instance. A thread calling this function should already have acquired the lock
       <code class="calibre21">
        lk
       </code>
       . When the thread exits, it automatically executes the following:
      </p>
      <pre class="calibre26" id="c27-code-0066"><code class="calibre21">lk.unlock();</code>
<code class="calibre21">cond.notify_all();</code></pre>
      <section class="calibre2">
       <aside class="calibre23">
        <div class="top">
         <hr class="calibre24"/>
        </div>
        <section class="feature">
         <p class="calibre25" id="c27-para-0222">
          <b class="calibre14">
           NOTE
          </b>
          <i class="calibre18">
           The lock
          </i>
          <code class="calibre21">
           lk
          </code>
          <i class="calibre18">
           <i class="calibre18">
            stays locked until the thread exits. So, you need to make sure that this does not cause any deadlocks in your code, for example, due to wrong lock ordering
           </i>
           .
          </i>
         </p>
         <div class="top">
          <hr class="calibre24"/>
         </div>
        </section>
       </aside>
      </section>
     </section>
    </section>
    <section aria-labelledby="head-2-273" class="calibre2">
     <span class="calibre" id="c27-sec-0060">
     </span>
     <h2 class="calibre6" id="head-2-273">
      LATCHES
     </h2>
     <p class="calibre13" id="c27-para-0223">
      A
      <i class="calibre18">
       latch
      </i>
      is a single-use thread coordination point. A number of threads block at a latch point. Once a given number of threads reach the latch point, all threads are unblocked and allowed to continue execution. Basically, it's a counter that's counting down as each thread arrives at the latch point. Once the counter hits zero, the latch remains “open” indefinitely, all blocking threads are unblocked, and any threads subsequently arriving at the latch point are immediately allowed to continue.
     </p>
     <p class="calibre13" id="c27-para-0224">
      <span aria-label="1022" class="calibre20" epub:type="pagebreak" id="Page_1022" role="doc-pagebreak">
      </span>
      A latch is implemented by
      <code class="calibre21">
       std::latch
      </code>
      , defined in
      <code class="calibre21">
       &lt;latch&gt;
      </code>
      . The constructor accepts the required number of threads that need to reach the latch point. A thread arriving at the latch point can call
      <code class="calibre21">
       arrive_and_wait()
      </code>
      , which decrements the latch counter and blocks until the latch is signaled. Threads can also block on a latch point without decrementing the counter by calling
      <code class="calibre21">
       wait()
      </code>
      . The
      <code class="calibre21">
       try_wait()
      </code>
      member function can be used to check if the counter has reached zero. Finally, if needed, the counter can also be decremented without blocking by calling
      <code class="calibre21">
       count_down()
      </code>
      .
     </p>
     <p class="calibre13">
      A first example demonstrates a use case for a latch point where data is processed in parallel. The following code snippet launches a number of worker threads, each doing some of the work. Once a worker thread is finished with its work, it calls
      <code class="calibre21">
       count_down()
      </code>
      on the latch to signal that its work is done. The main thread calls
      <code class="calibre21">
       wait()
      </code>
      on the latch to wait until the latch counter reaches zero, signaling that all worker threads have finished.
     </p>
     <pre class="calibre26" id="c27-code-0067"><code class="calibre21"><span class="color">// Launch a number of threads to do some work.</span></code>
<code class="calibre21">constexpr unsigned numberOfWorkerThreads { 10 };</code>
<code class="calibre21">latch latch { numberOfWorkerThreads };</code>
<code class="calibre21">vector&lt;jthread&gt; threads;</code>
<code class="calibre21">for (unsigned i { 0 }; i &lt; numberOfWorkerThreads; ++i) {</code>
<code class="calibre21">    threads.emplace:back([&amp;latch, i] {</code>
<code class="calibre21">        <span class="color">// Do some work…</span></code>
<code class="calibre21">        print("{} ", i);</code>
<code class="calibre21">        this_thread::sleep_for(1s);</code>
<code class="calibre21">        print("{} ", i);</code>
<code class="calibre21">        <span class="color">// When work is done, decrease the latch counter.</span></code>
<code class="calibre21">        latch.count_down();</code>
<code class="calibre21">    });</code>
<code class="calibre21">}</code>
<code class="calibre21"><span class="color">// Wait for all worker threads to finish.</span></code>
<code class="calibre21">latch.wait();</code>
<code class="calibre21">println("\nAll worker threads are finished.");</code></pre>
     <p class="calibre13">
      A second example demonstrates another use case for a latch point in which some data needs to be loaded into memory (I/O bound) that is subsequently processed in parallel in multiple threads. Suppose further that the threads need to perform some CPU-bound initialization when starting up and before they can start processing data. By launching the threads first and letting them do their CPU-bound initialization, and loading the data (I/O bound) in parallel, performance is increased. The code initializes a
      <code class="calibre21">
       latch
      </code>
      object with counter 1 and launches 10 threads that all do some initialization and then block on the
      <code class="calibre21">
       latch
      </code>
      until the latch counter reaches zero. After starting the 10 threads, the code loads some data, for example from disk, that is, an I/O-bound step. Once all data has been loaded, the latch counter is decremented to 0 which unblocks all 10 waiting threads.
     </p>
     <pre class="calibre26" id="c27-code-0068"><code class="calibre21">latch startLatch { 1 };</code>
<code class="calibre21">vector&lt;jthread&gt; threads;</code>
<code class="calibre21">for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">    threads.emplace:back([&amp;startLatch] {</code>
<code class="calibre21">        <span class="color">// Do some initialization… (CPU bound)</span></code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Wait until the latch counter reaches zero.</span></code>
<code class="calibre21">        startLatch.wait();</code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Process data…</span></code>
<code class="calibre21">    });</code>
<code class="calibre21">}</code>
<code class="calibre21"><span aria-label="1023" class="calibre20" epub:type="pagebreak" id="Page_1023" role="doc-pagebreak"></span> </code>
<code class="calibre21"><span class="color">// Load data… (I/O bound)</span></code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Once all data has been loaded, decrement the latch counter</span></code>
<code class="calibre21"><span class="color">// which then reaches zero and unblocks all waiting threads.</span></code>
<code class="calibre21">startLatch.count_down();</code></pre>
    </section>
    <section aria-labelledby="head-2-274" class="calibre2">
     <span class="calibre" id="c27-sec-0061">
     </span>
     <h2 class="calibre6" id="head-2-274">
      BARRIERS
     </h2>
     <p class="calibre13" id="c27-para-0227">
      A
      <i class="calibre18">
       barrier
      </i>
      is a reusable thread coordination mechanism consisting of a sequence of phases. A number of threads block at the barrier point. Each time a given number of threads reach the barrier, a phase completion callback is executed, all blocking threads are unblocked, the thread counter is reset, and the next phase starts. During each phase, the number of expected threads for the next phase can be adjusted. Barriers are great to perform synchronization between loops. For example, suppose you have a number of threads running concurrently and performing some calculations in a loop. Suppose further that once those calculations are finished, you need to do something with the results before the threads can start a new iteration of their loop. For such a scenario, barriers are perfect. When a thread is done with its work, it blocks at the barrier. When they all arrive at the barrier, the phase completion callback processes the results of the threads and then unblocks all the threads to start their next iteration.
     </p>
     <p class="calibre13" id="c27-para-0228">
      A barrier is implemented by the class template
      <code class="calibre21">
       std::barrier
      </code>
      , defined in
      <code class="calibre21">
       &lt;barrier&gt;
      </code>
      . The most important member function of a
      <code class="calibre21">
       barrier
      </code>
      is
      <code class="calibre21">
       arrive_and_wait()
      </code>
      , which decrements the counter and then blocks the thread until the current phase is finished. Consult a Standard Library reference for a full description of other available member functions.
     </p>
     <p class="calibre13">
      The following code snippet demonstrates the use of a barrier. It's a simulation of a production environment using robots. For each iteration, all robots need to do some work. When a robot is finished, it waits until all the other robots are finished. Once all robots are done, the next iteration is prepared, and the robots are instructed to start again. The barrier-specific operations are highlighted.
     </p>
     <pre class="calibre26" id="c27-code-0069"><code class="calibre21">constexpr unsigned numberOfRobots { 2 };</code>
<code class="calibre21">constexpr unsigned numberOfIterations { 3 };</code>
<code class="calibre21">unsigned iterationCount { 1 };</code>
<code class="calibre21">vector&lt;jthread&gt; robots;</code>
<code class="calibre21"> </code>
<code class="calibre21">auto <b class="calibre14">completionCallback</b> { [&amp;] () noexcept {</code>
<code class="calibre21">    if (iterationCount == numberOfIterations) {</code>
<code class="calibre21">        println("Finished {} iterations, stopping robots.", numberOfIterations);</code>
<code class="calibre21">        for (auto&amp; robot : robots) { robot.request_stop(); }</code>
<code class="calibre21">    } else {</code>
<code class="calibre21">        ++iterationCount;</code>
<code class="calibre21">        println("All robots finished. Preparing iteration {}.", iterationCount);</code>
<code class="calibre21">        this_thread::sleep_for(1s);</code>
<code class="calibre21">        println("Iteration {} ready to start. Waking up robots.", iterationCount);</code>
<code class="calibre21">    }</code>
<code class="calibre21">} };</code>
<code class="calibre21"> </code>
<span aria-label="1024" class="calibre20" epub:type="pagebreak" id="Page_1024" role="doc-pagebreak"></span><code class="calibre21"><b class="calibre14">barrier robotSynchronization { numberOfRobots, completionCallback };</b></code>
<code class="calibre21"> </code>
<code class="calibre21">auto robotThreadFunction { [&amp;](stop_token token, string_view name) {</code>
<code class="calibre21">    println("   Thread for robot {} started.", name);</code>
<code class="calibre21">    while (!token.stop_requested()) {</code>
<code class="calibre21">        this_thread::sleep_for(1s);</code>
<code class="calibre21">        println("   {} finished.", name);</code>
<code class="calibre21">        <b class="calibre14">robotSynchronization.arrive_and_wait();</b></code>
<code class="calibre21">    }</code>
<code class="calibre21">    println("   {} shutting down.", name);</code>
<code class="calibre21">} };</code>
<code class="calibre21"> </code>
<code class="calibre21">println("Preparing first iteration. Creating {} robot threads.", numberOfRobots);</code>
<code class="calibre21"> </code>
<code class="calibre21">for (unsigned i { 0 }; i &lt; numberOfRobots; ++i) {</code>
<code class="calibre21">    robots.emplace:back(robotThreadFunction, format("Robot_{}", i));</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">for (auto&amp; robot : robots) { robot.join(); }</code>
<code class="calibre21">println("Done with all work.");</code></pre>
     <p class="calibre13">
      The output is as follows:
     </p>
     <pre class="calibre26" id="c27-code-0070"><code class="calibre21">Preparing first iteration. Creating 2 robot threads.</code>
<code class="calibre21">   Thread for robot Robot_0 started.</code>
<code class="calibre21">   Thread for robot Robot_1 started.</code>
<code class="calibre21">   Robot_1 finished.</code>
<code class="calibre21">   Robot_0 finished.</code>
<code class="calibre21">All robots finished. Preparing iteration 2.</code>
<code class="calibre21">Iteration 2 ready to start. Waking up robots.</code>
<code class="calibre21">   Robot_1 finished.</code>
<code class="calibre21">   Robot_0 finished.</code>
<code class="calibre21">All robots finished. Preparing iteration 3.</code>
<code class="calibre21">Iteration 3 ready to start. Waking up robots.</code>
<code class="calibre21">   Robot_1 finished.</code>
<code class="calibre21">   Robot_0 finished.</code>
<code class="calibre21">Finished 3 iterations, stopping robots.</code>
<code class="calibre21">   Robot_0 shutting down.</code>
<code class="calibre21">   Robot_1 shutting down.</code>
<code class="calibre21">Done with all work.</code></pre>
     <p class="calibre13" id="c27-para-0231">
      In one of the exercises at the end of this chapter, you will improve this robot simulation so that the main thread starts all the robot threads, waits for all the robots to have started, prepares the first iteration, and instructs all waiting robots to start working.
     </p>
    </section>
    <section aria-labelledby="head-2-275" class="calibre2">
     <span class="calibre" id="c27-sec-0062">
     </span>
     <h2 class="calibre6" id="head-2-275">
      SEMAPHORES
     </h2>
     <p class="calibre13" id="c27-para-0232">
      <i class="calibre18">
       Semaphores
      </i>
      are lightweight synchronization primitives that can be used as building blocks for other synchronization mechanisms such as mutexes, latches, and barriers. Basically, a semaphore consists of a counter representing a number of
      <i class="calibre18">
       slots
      </i>
      . The counter is initialized in the constructor. If you acquire a slot, the counter is decremented, while releasing a slot increments the counter. There are two semaphore classes defined in
      <code class="calibre21">
       &lt;semaphore&gt;
      </code>
      :
      <code class="calibre21">
       std::counting_semaphore
      </code>
      and
      <code class="calibre21">
       binary_semaphore
      </code>
      .
      <span aria-label="1025" class="calibre20" epub:type="pagebreak" id="Page_1025" role="doc-pagebreak">
      </span>
      The former models a non-negative resource count. The latter has only one slot; hence, the slot is either free or not free, perfectly suitable as building block for a mutex. Both provide the following member functions:
     </p>
     <table border="1" class="calibre31">
      <thead class="calibre32">
       <tr class="calibre33">
        <th class="left" scope="col">
         MEMBER FUNCTION
        </th>
        <th class="left" scope="col">
         DESCRIPTION
        </th>
       </tr>
      </thead>
      <tbody class="calibre34">
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          acquire()
         </span>
        </td>
        <td class="bgcolor">
         Decrements the counter. When the counter is zero, blocks until it is able to decrement the counter, and then does so.
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          try_acquire()
         </span>
        </td>
        <td class="bgcolor">
         Tries to decrement the counter but does not block if the counter is already zero. Returns
         <span class="calibre21">
          true
         </span>
         if the counter could be decremented,
         <code class="calibre21">
          false
         </code>
         otherwise.
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          try_acquire_for()
         </span>
        </td>
        <td class="bgcolor">
         Same as
         <span class="calibre21">
          try_acquire()
         </span>
         but tries for a given duration.
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          try_acquire_until()
         </span>
        </td>
        <td class="bgcolor">
         Same as
         <span class="calibre21">
          try_acquire()
         </span>
         but tries until the system time reaches a given time.
        </td>
       </tr>
       <tr class="calibre33">
        <td class="bgcolor">
         <span class="calibre21">
          release()
         </span>
        </td>
        <td class="bgcolor">
         Increments the counter by a given number and unblocks threads that are blocking in their
         <span class="calibre21">
          acquire()
         </span>
         call.
        </td>
       </tr>
      </tbody>
     </table>
     <p class="calibre13">
      A counting semaphore allows you to control exactly how many threads you want to allow to run concurrently. For example, the following code snippet allows a maximum of four threads to run in parallel. From the output, you clearly see that only four threads manage to acquire the semaphore concurrently.
     </p>
     <pre class="calibre26" id="c27-code-0071"><code class="calibre21"><b class="calibre14">counting_semaphore semaphore { 4 };</b></code>
<code class="calibre21">vector&lt;jthread&gt; threads;</code>
<code class="calibre21">for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">    threads.emplace:back([&amp;semaphore] {</code>
<code class="calibre21">        <b class="calibre14">semaphore.acquire();</b></code>
<code class="calibre21">        <span class="color">// … Slot acquired … (at most 4 threads concurrently)</span></code>
<code class="calibre21">        print("{}", i);</code>
<code class="calibre21">        this_thread::sleep_for(5s);</code>
<code class="calibre21">        <b class="calibre14">semaphore.release();</b></code>
<code class="calibre21">    });</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13" id="c27-para-0235">
      Another use case for semaphores is to implement a notification mechanism for threads, instead of condition variables. For example, you could initialize the counter of a semaphore to 0 in its constructor. Any thread that calls
      <code class="calibre21">
       acquire()
      </code>
      will block until some other thread calls
      <code class="calibre21">
       release()
      </code>
      on the semaphore.
     </p>
    </section>
    <section aria-labelledby="head-2-276" class="calibre2">
     <span class="calibre" id="c27-sec-0063">
     </span>
     <h2 class="calibre6" id="head-2-276">
      FUTURES
     </h2>
     <p class="calibre13" id="c27-para-0236">
      As discussed earlier in this chapter, using
      <code class="calibre21">
       std::thread
      </code>
      to launch a thread that calculates a single result does not make it easy to get the computed result back once the thread has finished executing. Another problem with
      <code class="calibre21">
       std::thread
      </code>
      is in how it handles errors like exceptions. If a thread throws an exception and this exception is not caught by the thread itself, the C++ runtime calls
      <code class="calibre21">
       std::terminate()
      </code>
      , which usually terminates the entire application.
     </p>
     <p class="calibre13" id="c27-para-0237">
      <span aria-label="1026" class="calibre20" epub:type="pagebreak" id="Page_1026" role="doc-pagebreak">
      </span>
      A
      <i class="calibre18">
       future
      </i>
      can be used to more easily get the result out of a thread and to transport exceptions from one thread to another thread, which can then handle the exception however it wants.
     </p>
     <p class="calibre13" id="c27-para-0238">
      A
      <i class="calibre18">
       promise
      </i>
      is something in which a thread stores its result. A future is used to get access to the result stored in a promise. That is, a promise is the input side for a result, a future is the output side. Once a function, running in the same thread or in another thread, has calculated the value that it wants to return, it puts this value in a promise. This value can then be retrieved through a future. A promise/future pair is an inter-thread one-shot communication channel for a result.
     </p>
     <p class="calibre13">
      C++ provides a standard future, called
      <code class="calibre21">
       std::future
      </code>
      . You can retrieve the result from an
      <code class="calibre21">
       std::future
      </code>
      as follows.
      <code class="calibre21">
       T
      </code>
      is the type of the calculated result.
     </p>
     <pre class="calibre26" id="c27-code-0072"><code class="calibre21">future&lt;T&gt; myFuture { … };   <span class="color">// Is discussed later.</span></code>
<code class="calibre21">T result { myFuture.get() };</code></pre>
     <p class="calibre13" id="c27-para-0240">
      The call to
      <code class="calibre21">
       get()
      </code>
      retrieves the result and stores it in the variable
      <code class="calibre21">
       result
      </code>
      . If calculating the result is not finished yet, the call to
      <code class="calibre21">
       get()
      </code>
      blocks until the value becomes available. You can call
      <code class="calibre21">
       get()
      </code>
      only once on a future. The behavior of calling it a second time is undefined by the standard.
     </p>
     <p class="calibre13">
      If you want to avoid blocking, you can first ask the
      <code class="calibre21">
       future
      </code>
      if there is a result available:
     </p>
     <pre class="calibre26" id="c27-code-0073"><code class="calibre21">if (myFuture.wait_for(0)) {  <span class="color">// Value is available.</span></code>
<code class="calibre21">    T result { myFuture.get() };</code>
<code class="calibre21">} else {                     <span class="color">// Value is not yet available.</span></code>
<code class="calibre21">    …</code>
<code class="calibre21">}</code></pre>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0064">
      </span>
      <h3 class="calibre27" id="head-3-516">
       std::promise and std::future
      </h3>
      <p class="calibre13" id="c27-para-0242">
       C++ provides the
       <code class="calibre21">
        std::promise
       </code>
       class as one way to implement the concept of a promise. You can call
       <code class="calibre21">
        set_value()
       </code>
       on a
       <code class="calibre21">
        promise
       </code>
       to store a result, or you can call
       <code class="calibre21">
        set_exception()
       </code>
       on it to store an exception in the
       <code class="calibre21">
        promise
       </code>
       . You can call
       <code class="calibre21">
        set_value()
       </code>
       or
       <code class="calibre21">
        set_exception()
       </code>
       only once on a specific
       <code class="calibre21">
        promise
       </code>
       . If you call it multiple times, an
       <code class="calibre21">
        std::future_error
       </code>
       exception will be thrown.
      </p>
      <p class="calibre13" id="c27-para-0243">
       Alternatively, you can use
       <code class="calibre21">
        set_value_at_thread_exit()
       </code>
       or
       <code class="calibre21">
        set_exception_at_thread_exit()
       </code>
       to set a value or an exception in a
       <code class="calibre21">
        promise
       </code>
       . Using these, the value or the exception is stored in the
       <code class="calibre21">
        promise
       </code>
       at the time the thread exits and after all thread-local storage variables have been destroyed.
      </p>
      <p class="calibre13">
       A thread A that launches another thread B to calculate something can create a
       <code class="calibre21">
        promise
       </code>
       and pass it to the launched thread. A
       <code class="calibre21">
        promise
       </code>
       cannot be copied, but it can be moved into a thread! Thread B uses that
       <code class="calibre21">
        promise
       </code>
       to store the result. Before moving the
       <code class="calibre21">
        promise
       </code>
       into thread B, thread A calls
       <code class="calibre21">
        get_future()
       </code>
       on the created
       <code class="calibre21">
        promise
       </code>
       to be able to get access to the result once B has finished. Here is a simple example:
      </p>
      <pre class="calibre26" id="c27-code-0074"><code class="calibre21">void doWork(promise&lt;int&gt; thePromise)</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// … Do some work …</span></code>
<code class="calibre21">    <span class="color">// And ultimately store the result in the promise.</span></code>
<code class="calibre21">    thePromise.set_value(42);</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<span aria-label="1027" class="calibre20" epub:type="pagebreak" id="Page_1027" role="doc-pagebreak"></span><code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Create a promise to pass to the thread.</span></code>
<code class="calibre21">    promise&lt;int&gt; myPromise;</code>
<code class="calibre21">    <span class="color">// Get the future of the promise.</span></code>
<code class="calibre21">    auto theFuture { myPromise.get_future() };</code>
<code class="calibre21">    <span class="color">// Create a thread and move the promise into it.</span></code>
<code class="calibre21">    jthread theThread { doWork, move(myPromise) };</code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Do some more work…</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Get the result.</span></code>
<code class="calibre21">    int result { theFuture.get() };</code>
<code class="calibre21">    println("Result: {}", result);</code>
<code class="calibre21">}</code></pre>
      <section class="calibre2">
       <aside class="calibre23">
        <div class="top">
         <hr class="calibre24"/>
        </div>
        <section class="feature">
         <p class="calibre25" id="c27-para-0246">
          <b class="calibre14">
           NOTE
          </b>
          <i class="calibre18">
           This code is just for demonstration purposes. It starts the calculation in a new thread and then calls
          </i>
          <code class="calibre21">
           get()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            on the
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           ,
           <i class="calibre18">
            which blocks until the result is calculated. This sounds like an expensive function call. In real-world applications, you can use
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           s
           <i class="calibre18">
            by periodically checking if there is a result available or not (using
           </i>
          </i>
          <code class="calibre21">
           wait_for()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            as discussed earlier) or by using a synchronization mechanism such as a condition variable. When the result is not yet available, you can do something else in the meantime, instead of blocking
           </i>
           .
          </i>
         </p>
         <div class="top">
          <hr class="calibre24"/>
         </div>
        </section>
       </aside>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0066">
      </span>
      <h3 class="calibre27" id="head-3-517">
       std::packaged_task
      </h3>
      <p class="calibre13" id="c27-para-0247">
       A
       <code class="calibre21">
        std::packaged_task
       </code>
       makes it easier to work with promises than explicitly using
       <code class="calibre21">
        std::promise
       </code>
       , as in the previous section. The following code demonstrates this. It creates a
       <code class="calibre21">
        packaged_task
       </code>
       to execute
       <code class="calibre21">
        calculateSum()
       </code>
       . The
       <code class="calibre21">
        future
       </code>
       is retrieved from the
       <code class="calibre21">
        packaged_task
       </code>
       by calling
       <code class="calibre21">
        get_future()
       </code>
       . A thread is launched, and the
       <code class="calibre21">
        packaged_task
       </code>
       is moved into it. A
       <code class="calibre21">
        packaged_task
       </code>
       , like a
       <code class="calibre21">
        std::promise
       </code>
       , is move-only. After the thread is launched,
       <code class="calibre21">
        get()
       </code>
       is called on the retrieved future to get the result. This blocks until the result is available.
      </p>
      <p class="calibre13">
       <code class="calibre21">
        calculateSum()
       </code>
       does not store anything explicitly in any kind of promise. A
       <code class="calibre21">
        packaged_task
       </code>
       automatically creates a promise, and automatically stores the result of the callable—
       <code class="calibre21">
        calculateSum()
       </code>
       in this case—in the promise, no matter whether that result is a value or a thrown exception.
      </p>
      <pre class="calibre26" id="c27-code-0075"><code class="calibre21">int calculateSum(int a, int b) { return a + b; }</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Create a packaged task to run calculateSum.</span></code>
<code class="calibre21">    packaged_task task { calculateSum };</code>
<code class="calibre21">    <span class="color">// Get the future for the result of the packaged task.</span></code>
<code class="calibre21">    auto theFuture { task.get_future() };</code>
<code class="calibre21">    <span class="color">// Create a thread, move the packaged task into it, and</span></code>
<code class="calibre21">    <span class="color">// execute the packaged task with the given arguments.</span></code>
<code class="calibre21">    jthread theThread { move(task), 39, 3 };</code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Do some more work…</span></code>
<code class="calibre21"> </code>
<span aria-label="1028" class="calibre20" epub:type="pagebreak" id="Page_1028" role="doc-pagebreak"></span><code class="calibre21">    <span class="color">// Get the result.</span></code>
<code class="calibre21">    int result { theFuture.get() };</code>
<code class="calibre21">    println("Result: {}", result);</code>
<code class="calibre21">}</code></pre>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0067">
      </span>
      <h3 class="calibre27" id="head-3-518">
       std::async
      </h3>
      <p class="calibre13">
       If you want to give the C++ runtime more control over whether or not a thread is created to calculate something, you can use
       <code class="calibre21">
        std::async()
       </code>
       . It accepts a callable to be executed and returns a
       <code class="calibre21">
        future
       </code>
       that you can use to retrieve the result. There are two ways in which
       <code class="calibre21">
        async()
       </code>
       can run a callable:
      </p>
      <ul class="check" id="c27-list-0017">
       <li class="calibre9" id="c27-li-0058">
        By running it on a separate thread asynchronously
       </li>
       <li class="calibre9" id="c27-li-0059">
        By running it on the calling thread synchronously at the time you call
        <code class="calibre21">
         get()
        </code>
        on the returned
        <code class="calibre21">
         future
        </code>
       </li>
      </ul>
      <p class="calibre13">
       If you call
       <code class="calibre21">
        async()
       </code>
       without additional arguments, the runtime automatically chooses one of the two mechanisms depending on factors such as the number of CPU cores in your system and the amount of concurrency already taking place. You can influence the runtime's behavior by specifying a policy argument:
      </p>
      <ul class="check" id="c27-list-0018">
       <li class="calibre9" id="c27-li-0060">
        <code class="calibre21">
         launch::async
        </code>
        <b class="calibre14">
         :
        </b>
        Forces the runtime to execute the callable asynchronously on a different thread.
       </li>
       <li class="calibre9" id="c27-li-0061">
        <code class="calibre21">
         launch::deferred
        </code>
        <b class="calibre14">
         :
        </b>
        Forces the runtime to execute the callable synchronously on the calling thread when
        <code class="calibre21">
         get()
        </code>
        is called.
       </li>
       <li class="calibre9" id="c27-li-0062">
        <code class="calibre21">
         launch::async | launch::deferred
        </code>
        <b class="calibre14">
         :
        </b>
        Lets the runtime choose (= default behavior).
       </li>
      </ul>
      <p class="calibre13">
       The following example demonstrates the use of
       <code class="calibre21">
        async()
       </code>
       :
      </p>
      <pre class="calibre26" id="c27-code-0076"><code class="calibre21">int calculateSum(int a, int b) { return a + b; }</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    auto myFuture { async(calculateSum, 39, 3) };</code>
<code class="calibre21">    <span class="color">//auto myFuture { async(launch::async, calculateSum, 39, 3) };</span></code>
<code class="calibre21">    <span class="color">//auto myFuture { async(launch::deferred, calculateSum, 39, 3) };</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Do some more work…</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Get the result.</span></code>
<code class="calibre21">    int result { myFuture.get() };</code>
<code class="calibre21">    println("Result: {}", result);</code>
<code class="calibre21">}</code></pre>
      <p class="calibre13">
       As you can see from this code snippet,
       <code class="calibre21">
        std::async()
       </code>
       is one of the easiest techniques to perform some calculations either asynchronously (on a different thread) or synchronously (on the same thread) and retrieve the result afterward.
       <span aria-label="1029" class="calibre20" epub:type="pagebreak" id="Page_1029" role="doc-pagebreak">
       </span>
      </p>
      <section class="calibre2">
       <aside class="calibre23">
        <div class="top">
         <hr class="calibre24"/>
        </div>
        <section class="feature">
         <p class="calibre25" id="c27-para-0253">
          <b class="calibre14">
           WARNING
          </b>
          <i class="calibre18">
           A
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           <i class="calibre18">
            returned by a call to
           </i>
          </i>
          <code class="calibre21">
           async()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            blocks in its destructor until the result is available. (This is not true of ordinary
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           s; only the kind returned from
          </i>
          <code class="calibre21">
           async()
          </code>
          <i class="calibre18">
           .) This means that if you call
          </i>
          <code class="calibre21">
           async()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            without capturing the returned
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           ,
           <i class="calibre18">
            the
           </i>
          </i>
          <code class="calibre21">
           async()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            call effectively becomes a blocking call! For example, the following line synchronously calls
           </i>
          </i>
          <code class="calibre21">
           calculateSum()
          </code>
          <i class="calibre18">
           :
          </i>
         </p>
         <pre class="calibre26" id="c27-code-0077"><code class="calibre21">    async(calculateSum, 39, 3);</code></pre>
         <p class="calibre25" id="c27-para-0255">
          <i class="calibre18">
           What happens with this statement is that
          </i>
          <code class="calibre21">
           async()
          </code>
          <i class="calibre18">
           <i class="calibre18">
            creates and returns a
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           . This
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           <i class="calibre18">
            is not captured, so it is a temporary. Because it is a temporary
           </i>
          </i>
          <code class="calibre21">
           future
          </code>
          <i class="calibre18">
           , its destructor is called at the end of this statement, and this destructor blocks until the result is available
          </i>
          .
         </p>
         <div class="top">
          <hr class="calibre24"/>
         </div>
        </section>
       </aside>
      </section>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0070">
      </span>
      <h3 class="calibre27" id="head-3-519">
       Exception Handling
      </h3>
      <p class="calibre13">
       A big advantage of using futures is that they can transport exceptions between threads. Calling
       <code class="calibre21">
        get()
       </code>
       on a
       <code class="calibre21">
        future
       </code>
       either returns the calculated result or rethrows any exception that has been stored in the promise linked to the
       <code class="calibre21">
        future
       </code>
       . When you use
       <code class="calibre21">
        packaged_task
       </code>
       or
       <code class="calibre21">
        async()
       </code>
       , any exception thrown from the launched callable is automatically stored in the promise. If you use
       <code class="calibre21">
        std::promise
       </code>
       directly as your promise, you can call
       <code class="calibre21">
        set_exception()
       </code>
       to store an exception in it. Here is an example using
       <code class="calibre21">
        async()
       </code>
       :
      </p>
      <pre class="calibre26" id="c27-code-0078"><code class="calibre21">int calculate()</code>
<code class="calibre21">{</code>
<code class="calibre21">    throw runtime_error { "Exception thrown from calculate()." };</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Use the launch::async policy to force asynchronous execution.</span></code>
<code class="calibre21">    auto myFuture { async(launch::async, calculate) };</code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Do some more work…</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    <span class="color">// Get the result.</span></code>
<code class="calibre21">    try {</code>
<code class="calibre21">        int result { myFuture.get() };</code>
<code class="calibre21">        println("Result: {}", result);</code>
<code class="calibre21">    } catch (const exception&amp; ex) {</code>
<code class="calibre21">        println("Caught exception: {}", ex.what());</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
     </section>
     <section class="calibre2">
      <span class="calibre" id="c27-sec-0071">
      </span>
      <h3 class="calibre27" id="head-3-520">
       std::shared_future
      </h3>
      <p class="calibre13" id="c27-para-0257">
       <code class="calibre21">
        std::future&lt;T&gt;
       </code>
       only requires
       <code class="calibre21">
        T
       </code>
       to be move-constructible. When you call
       <code class="calibre21">
        get()
       </code>
       on a
       <code class="calibre21">
        future&lt;T&gt;
       </code>
       , the result is moved out of the
       <code class="calibre21">
        future
       </code>
       and returned to you. This means you can call
       <code class="calibre21">
        get()
       </code>
       only once on a
       <code class="calibre21">
        future&lt;T&gt;
       </code>
       .
      </p>
      <p class="calibre13" id="c27-para-0258">
       <span aria-label="1030" class="calibre20" epub:type="pagebreak" id="Page_1030" role="doc-pagebreak">
       </span>
       If you want to be able to call
       <code class="calibre21">
        get()
       </code>
       multiple times, even from multiple threads, then you need to use an
       <code class="calibre21">
        std::shared_future&lt;T&gt;
       </code>
       . A
       <code class="calibre21">
        shared_future
       </code>
       can be created by using
       <code class="calibre21">
        std::future::share()
       </code>
       or by passing a
       <code class="calibre21">
        future
       </code>
       to the
       <code class="calibre21">
        shared_future
       </code>
       constructor. A
       <code class="calibre21">
        future
       </code>
       is not copyable, so you have to move it into the
       <code class="calibre21">
        shared_future
       </code>
       constructor.
      </p>
      <p class="calibre13">
       <code class="calibre21">
        shared_future
       </code>
       can be used to wake up multiple threads at once. For example, the following piece of code defines two lambda expressions to be executed asynchronously on different threads. The first thing each lambda expression does is set a value to their respective
       <code class="calibre21">
        promise
       </code>
       to signal that they have started. Then they both call
       <code class="calibre21">
        get()
       </code>
       on
       <code class="calibre21">
        signalFuture
       </code>
       , which blocks until a parameter is made available through the
       <code class="calibre21">
        future
       </code>
       , after which they continue their execution. Each lambda expression captures their respective
       <code class="calibre21">
        promise
       </code>
       by reference and captures
       <code class="calibre21">
        signalFuture
       </code>
       by value, so both lambda expressions have a copy of
       <code class="calibre21">
        signalFuture
       </code>
       . The main thread uses
       <code class="calibre21">
        async()
       </code>
       to execute both lambda expressions asynchronously on different threads, waits until both threads have started, and then sets the parameter in the
       <code class="calibre21">
        signalPromise
       </code>
       , which wakes up both threads.
      </p>
      <pre class="calibre26" id="c27-code-0079"><code class="calibre21">promise&lt;void&gt; thread1Started, thread2Started;</code>
<code class="calibre21"> </code>
<code class="calibre21">promise&lt;int&gt; signalPromise;</code>
<code class="calibre21">auto signalFuture { signalPromise.get_future().share() };</code>
<code class="calibre21"><span class="color">//shared_future&lt;int&gt; signalFuture { signalPromise.get_future() };</span></code>
<code class="calibre21"> </code>
<code class="calibre21">auto function1 { [&amp;thread1Started, signalFuture] {</code>
<code class="calibre21">    thread1Started.set_value();</code>
<code class="calibre21">    <span class="color">// Wait until parameter is set.</span></code>
<code class="calibre21">    int parameter { signalFuture.get() };</code>
<code class="calibre21">    <span class="color">// …</span></code>
<code class="calibre21">} };</code>
<code class="calibre21"> </code>
<code class="calibre21">auto function2 { [&amp;thread2Started, signalFuture] {</code>
<code class="calibre21">    thread2Started.set_value();</code>
<code class="calibre21">    <span class="color">// Wait until parameter is set.</span></code>
<code class="calibre21">    int parameter { signalFuture.get() };</code>
<code class="calibre21">    <span class="color">// …</span></code>
<code class="calibre21">} };</code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Run both lambda expressions asynchronously.</span></code>
<code class="calibre21"><span class="color">// Remember to capture the future returned by async()!</span></code>
<code class="calibre21">auto result1 { async(launch::async, function1) };</code>
<code class="calibre21">auto result2 { async(launch::async, function2) };</code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Wait until both threads have started.</span></code>
<code class="calibre21">thread1Started.get_future().wait();</code>
<code class="calibre21">thread2Started.get_future().wait();</code>
<code class="calibre21"> </code>
<code class="calibre21"><span class="color">// Both threads are now waiting for the parameter.</span></code>
<code class="calibre21"><span class="color">// Set the parameter to wake up both of them.</span></code>
<code class="calibre21">signalPromise.set_value(42);</code></pre>
     </section>
    </section>
    <section aria-labelledby="head-2-277" class="calibre2">
     <span class="calibre" id="c27-sec-0072">
     </span>
     <h2 class="calibre6" id="head-2-277">
      EXAMPLE: MULTITHREADED LOGGER CLASS
     </h2>
     <p class="calibre13" id="c27-para-0260">
      This section demonstrates how to use threads, mutexes, locks, and condition variables to write a multithreaded
      <code class="calibre21">
       Logger
      </code>
      class. The class allows log messages to be added to a queue from different
      <span aria-label="1031" class="calibre20" epub:type="pagebreak" id="Page_1031" role="doc-pagebreak">
      </span>
      threads. The
      <code class="calibre21">
       Logger
      </code>
      class itself processes this queue in a background thread that serially writes the log messages to a file. The class is designed in two iterations to show you some examples of problems you will encounter when writing multithreaded code.
     </p>
     <p class="calibre13">
      The C++ standard does not have a thread-safe queue, so it is obvious that you must protect access to the queue with some synchronization mechanism to prevent multiple threads from reading/writing to the queue at the same time. This example uses a mutex and a condition variable to provide the synchronization. Based on that, you might define the
      <code class="calibre21">
       Logger
      </code>
      class as follows:
     </p>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature">
        <p class="calibre25" id="c27-para-0262">
         <b class="calibre14">
          WARNING
         </b>
         <i class="calibre18">
          This
         </i>
         <code class="calibre21">
          Logger
         </code>
         <i class="calibre18">
          <i class="calibre18">
           class uses
          </i>
         </i>
         <code class="calibre21">
          std::thread
         </code>
         <i class="calibre18">
          <i class="calibre18">
           instead of
          </i>
         </i>
         <code class="calibre21">
          jthread
         </code>
         <i class="calibre18">
          <i class="calibre18">
           to demonstrate 1) the catastrophic results when using
          </i>
         </i>
         <code class="calibre21">
          thread
         </code>
         <i class="calibre18">
          <i class="calibre18">
           improperly and 2) how easy it is to use
          </i>
         </i>
         <code class="calibre21">
          thread
         </code>
         <i class="calibre18">
          <i class="calibre18">
           wrongly
          </i>
          .
         </i>
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <pre class="calibre26" id="c27-code-0080"><code class="calibre21">export class Logger</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        <span class="color">// Starts a background thread writing log entries to a file.</span></code>
<code class="calibre21">        Logger();</code>
<code class="calibre21">        <span class="color">// Prevent copy construction and assignment.</span></code>
<code class="calibre21">        Logger(const Logger&amp;) = delete;</code>
<code class="calibre21">        Logger&amp; operator=(const Logger&amp;) = delete;</code>
<code class="calibre21">        <span class="color">// Add log entry to the queue.</span></code>
<code class="calibre21">        void log(std::string entry);</code>
<code class="calibre21">    private:</code>
<code class="calibre21">        <span class="color">// The function running in the background thread.</span></code>
<code class="calibre21">        void processEntries();</code>
<code class="calibre21">        <span class="color">// Helper member function to process a queue of entries.</span></code>
<code class="calibre21">        void processEntriesHelper(std::queue&lt;std::string&gt;&amp; queue,</code>
<code class="calibre21">            std::ofstream&amp; ofs) const;</code>
<code class="calibre21">        <span class="color">// Mutex and condition variable to protect access to the queue.</span></code>
<code class="calibre21">        std::mutex m_mutex;</code>
<code class="calibre21">        std::condition_variable m_condVar;</code>
<code class="calibre21">        std::queue&lt;std::string&gt; m_queue;</code>
<code class="calibre21">        <span class="color">// The background thread.</span></code>
<code class="calibre21">        std::thread m_thread;</code>
<code class="calibre21">};</code></pre>
     <p class="calibre13">
      The implementation is as follows. This initial design has a couple of problems. When you try to run it, it might behave incorrect and crash. This is discussed and solved in the next design iteration of the
      <code class="calibre21">
       Logger
      </code>
      class. The
      <code class="calibre21">
       while
      </code>
      loop in the
      <code class="calibre21">
       processEntries()
      </code>
      member function is worth looking at. It processes all messages currently in the queue. While having a lock, it swaps the contents of the current queue of entries with an empty local queue on the stack. After this, it releases the lock so other threads are not blocked anymore to add new entries to the now empty current queue. Once the lock is released, all entries in the local queue are processed. This does not require the lock anymore as other threads will not touch this local queue.
     </p>
     <pre class="calibre26" id="c27-code-0081"><span aria-label="1032" class="calibre20" epub:type="pagebreak" id="Page_1032" role="doc-pagebreak"></span><code class="calibre21">Logger::Logger()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Start background thread.</span></code>
<code class="calibre21">    m_thread = thread { &amp;Logger::processEntries, this };</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">void Logger::log(string entry)</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Lock mutex and add entry to the queue.</span></code>
<code class="calibre21">    lock_guard lock { m_mutex };</code>
<code class="calibre21">    m_queue.push(move(entry));</code>
<code class="calibre21">    <span class="color">// Notify condition variable to wake up thread.</span></code>
<code class="calibre21">    m_condVar.notify_all();</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">void Logger::processEntries()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Open log file.</span></code>
<code class="calibre21">    ofstream logFile { "log.txt" };</code>
<code class="calibre21">    if (logFile.fail()) {</code>
<code class="calibre21">        println(cerr, "Failed to open logfile.");</code>
<code class="calibre21">        return;</code>
<code class="calibre21">    }</code>
<code class="calibre21"> </code>
<code class="calibre21">    unique_lock lock { m_mutex }; <span class="color">// Acquire a lock on m_mutex.</span></code>
<code class="calibre21">    while (true) { <span class="color">// Start processing loop.</span></code>
<code class="calibre21">        <span class="color">// Wait for a notification.</span></code>
<code class="calibre21">        m_condVar.wait(lock);</code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Condition variable is notified, so something might be in the queue.</span></code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// While we still have the lock, swap the contents of the current queue</span></code>
<code class="calibre21">        <span class="color">// with an empty local queue on the stack.</span></code>
<code class="calibre21">        queue&lt;string&gt; localQueue;</code>
<code class="calibre21">        localQueue.swap(m_queue);</code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Now that all entries have been moved from the current queue to the</span></code>
<code class="calibre21">        <span class="color">// local queue, we can release the lock so other threads are not blocked</span></code>
<code class="calibre21">        <span class="color">// while we process the entries.</span></code>
<code class="calibre21">        lock.unlock();</code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Process the entries in the local queue on the stack. This happens after</span></code>
<code class="calibre21">        <span class="color">// having released the lock, so other threads are not blocked anymore.</span></code>
<code class="calibre21">        processEntriesHelper(localQueue, logFile);</code>
<code class="calibre21"> </code>
<code class="calibre21">        lock.lock();</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">void Logger::processEntriesHelper(queue&lt;string&gt;&amp; queue, ofstream&amp; ofs) const</code>
<code class="calibre21">{</code>
<code class="calibre21">    while (!queue.empty()) {</code>
<code class="calibre21">        ofs &lt;&lt; queue.front() &lt;&lt; endl;</code>
<code class="calibre21">        queue.pop();</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13">
      <span aria-label="1033" class="calibre20" epub:type="pagebreak" id="Page_1033" role="doc-pagebreak">
      </span>
     </p>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature">
        <p class="calibre25" id="c27-para-0265">
         <b class="calibre14">
          WARNING
         </b>
         <i class="calibre18">
          As you can already see from this rather simple task, writing correct multithreaded code is hard! Unfortunately, at this moment, the C++ Standard Library does not provide any concurrent data structures, at least not yet
         </i>
         .
        </p>
        <p class="calibre25" id="c27-para-0266">
         <i class="calibre18">
          The
         </i>
         <code class="calibre21">
          Logger
         </code>
         <i class="calibre18">
          <i class="calibre18">
           class is just an example to show these basic building blocks. For production-quality code, I recommend using an appropriate third-party concurrent data structure, instead of writing your own. For example, the open-source boost C++ libraries
          </i>
          (
         </i>
         <code class="calibre21">
          <a class="calibre5" href="http://boost.org">
           boost.org
          </a>
         </code>
         <i class="calibre18">
          )
          <i class="calibre18">
           have an implementation of a queue that is lock-free and allows concurrent use without the need for any explicit synchronization
          </i>
          .
         </i>
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
     <p class="calibre13">
      The
      <code class="calibre21">
       Logger
      </code>
      class can be tested with the following test code. It launches a number of threads, all logging a few messages to the same
      <code class="calibre21">
       Logger
      </code>
      instance.
     </p>
     <pre class="calibre26" id="c27-code-0082"><code class="calibre21">void logSomeMessages(int id, Logger&amp; logger)</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">        logger.log(format("Log entry {} from thread {}", i, id));</code>
<code class="calibre21">        this_thread::sleep_for(50ms);</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    Logger logger;</code>
<code class="calibre21">    vector&lt;jthread&gt; threads;</code>
<code class="calibre21">    <span class="color">// Create a few threads all working with the same Logger instance.</span></code>
<code class="calibre21">    for (int i { 0 }; i &lt; 10; ++i) {</code>
<code class="calibre21">        threads.emplace:back(logSomeMessages, i, ref(logger));</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13">
      If you build and run this naive initial version, you will notice that the application is terminated abruptly. That is because the application never calls
      <code class="calibre21">
       join()
      </code>
      or
      <code class="calibre21">
       detach()
      </code>
      on the
      <code class="calibre21">
       Logger
      </code>
      background thread. Remember from earlier in this chapter that the destructor of a joinable
      <code class="calibre21">
       thread
      </code>
      object, that is, neither
      <code class="calibre21">
       join()
      </code>
      nor
      <code class="calibre21">
       detach()
      </code>
      has been called yet, calls
      <code class="calibre21">
       std::terminate()
      </code>
      to terminate all running threads and the application itself. This means that messages still in the queue are not written to the file on disk. Some runtime libraries even issue an error or generate a crash dump when the application is terminated like this. You need to add a mechanism to gracefully shut down the background thread and wait until the background thread is completely shut down before terminating the application. You can do this by adding a destructor and a Boolean data member to the class. The new definition of the class is as follows:
     </p>
     <pre class="calibre26" id="c27-code-0083"><code class="calibre21">export class Logger</code>
<code class="calibre21">{</code>
<code class="calibre21">    public:</code>
<code class="calibre21">        <span class="color">// Gracefully shut down background thread.</span></code>
<code class="calibre21">        <b class="calibre14">virtual ~Logger();</b></code>
<code class="calibre21">        <span class="color">// Other public members omitted for brevity.</span></code>
<code class="calibre21">    private:</code>
<span aria-label="1034" class="calibre20" epub:type="pagebreak" id="Page_1034" role="doc-pagebreak"></span><code class="calibre21">        <span class="color">// Boolean telling the background thread to terminate.</span></code>
<code class="calibre21">        <b class="calibre14">bool m_exit { false };</b></code>
<code class="calibre21">        <span class="color">// Other members omitted for brevity.</span></code>
<code class="calibre21">};</code></pre>
     <p class="calibre13">
      The destructor sets
      <code class="calibre21">
       m_exit
      </code>
      to
      <code class="calibre21">
       true
      </code>
      , wakes up the background thread, and then waits until the thread is shut down. The destructor acquires a lock on
      <code class="calibre21">
       m_mutex
      </code>
      before setting
      <code class="calibre21">
       m_exit
      </code>
      to
      <code class="calibre21">
       true
      </code>
      . This is to prevent a race condition and deadlock with
      <code class="calibre21">
       processEntries()
      </code>
      , which could be at the beginning of its
      <code class="calibre21">
       while
      </code>
      loop right after having checked
      <code class="calibre21">
       m_exit
      </code>
      and right before the call to
      <code class="calibre21">
       wait()
      </code>
      . If the main thread calls the
      <code class="calibre21">
       Logger
      </code>
      destructor at that very moment (assuming the destructor hadn't been written to acquire a lock on
      <code class="calibre21">
       m_mutex
      </code>
      ), then the destructor sets
      <code class="calibre21">
       m_exit
      </code>
      to
      <code class="calibre21">
       true
      </code>
      and calls
      <code class="calibre21">
       notify_all()
      </code>
      after
      <code class="calibre21">
       processEntries()
      </code>
      has checked
      <code class="calibre21">
       m_exit
      </code>
      and before
      <code class="calibre21">
       processEntries()
      </code>
      is waiting on the condition variable; thus,
      <code class="calibre21">
       processEntries()
      </code>
      will not see the new value of
      <code class="calibre21">
       m_exit
      </code>
      , and it will miss the notification. In that case, the application is deadlocked, because the destructor is waiting on the
      <code class="calibre21">
       join()
      </code>
      call and the background thread is waiting on the condition variable. The destructor can call
      <code class="calibre21">
       notify_all()
      </code>
      while still holding the lock or after having released it, but the lock must certainly be released before calling
      <code class="calibre21">
       join()
      </code>
      , which explains the extra code block using curly brackets.
     </p>
     <pre class="calibre26" id="c27-code-0084"><code class="calibre21">Logger::~Logger()</code>
<code class="calibre21">{</code>
<code class="calibre21">    {</code>
<code class="calibre21">        lock_guard lock { m_mutex };</code>
<code class="calibre21">        <span class="color">// Gracefully shut down the thread by setting m_exit to true.</span></code>
<code class="calibre21">        m_exit = true;</code>
<code class="calibre21">    }</code>
<code class="calibre21">    <span class="color">// Notify condition variable to wake up thread.</span></code>
<code class="calibre21">    m_condVar.notify_all();</code>
<code class="calibre21">    <span class="color">// Wait until thread is shut down. This should be outside the above code</span></code>
<code class="calibre21">    <span class="color">// block because the lock must be released before calling join()!</span></code>
<code class="calibre21">    m_thread.join();</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13">
      The
      <code class="calibre21">
       processEntries()
      </code>
      member function needs to check this Boolean variable and terminate the processing loop when it's
      <code class="calibre21">
       true
      </code>
      . It should also call
      <code class="calibre21">
       wait()
      </code>
      only when the queue is empty.
     </p>
     <pre class="calibre26" id="c27-code-0085"><code class="calibre21">void Logger::processEntries()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Omitted for brevity.</span></code>
<code class="calibre21"> </code>
<code class="calibre21">    unique_lock lock { m_mutex }; <span class="color">// Acquire a lock on m_mutex.</span></code>
<code class="calibre21">    while (true) { <span class="color">// Start processing loop.</span></code>
<code class="calibre21">        <b class="calibre14">if (!m_exit) {</b> <span class="color">// Only wait for notifications if we don't have to exit.</span></code>
<code class="calibre21">            <b class="calibre14">if (m_queue.empty()) {</b> <span class="color">// Only wait if the queue is empty.</span></code>
<code class="calibre21">                m_condVar.wait(lock);</code>
<code class="calibre21">            <b class="calibre14">}</b></code>
<code class="calibre21">        <b class="calibre14">} else {</b></code>
<code class="calibre21">            <span class="color">// We have to exit, process the remaining entries in the queue.</span></code>
<code class="calibre21">            <b class="calibre14">processEntriesHelper(m_queue, logFile);</b></code>
<code class="calibre21">            <b class="calibre14">break;</b></code>
<code class="calibre21">        <b class="calibre14">}</b></code>
<code class="calibre21"> </code>
<code class="calibre21">        <span class="color">// Condition variable is notified, so something might be in the queue</span></code>
<span aria-label="1035" class="calibre20" epub:type="pagebreak" id="Page_1035" role="doc-pagebreak"></span><code class="calibre21">        <span class="color">// and/or we need to shut down this thread.</span></code>
<code class="calibre21"> </code>
<code class="calibre21">        queue&lt;string&gt; localQueue;</code>
<code class="calibre21">        localQueue.swap(m_queue);</code>
<code class="calibre21">        lock.unlock();</code>
<code class="calibre21">        processEntriesHelper(localQueue, logFile);</code>
<code class="calibre21"> </code>
<code class="calibre21">        <b class="calibre14">lock.lock();</b></code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13" id="c27-para-0271">
      You cannot just check for
      <code class="calibre21">
       m_exit
      </code>
      in the condition for the outer
      <code class="calibre21">
       while
      </code>
      loop because even when
      <code class="calibre21">
       m_exit
      </code>
      is
      <code class="calibre21">
       true
      </code>
      , there might still be log entries in the queue that need to be written to the log file.
     </p>
     <p class="calibre13">
      You can add artificial delays in specific places in your multithreaded code to trigger certain behavior. Such delays should only be added for testing and must be removed from your final code! For example, to test that the race condition with the destructor is solved, you can remove any calls to
      <code class="calibre21">
       log()
      </code>
      from the main program, causing it to almost immediately call the destructor of the
      <code class="calibre21">
       Logger
      </code>
      class, and add the following delay:
     </p>
     <pre class="calibre26" id="c27-code-0086"><code class="calibre21">void Logger::processEntries()</code>
<code class="calibre21">{</code>
<code class="calibre21">    <span class="color">// Omitted for brevity.</span></code>
<code class="calibre21">    while (true) {</code>
<code class="calibre21">        if (!m_exit) { <span class="color">// Only wait for notifications if we don't have to exit.</span></code>
<code class="calibre21">            <b class="calibre14">this_thread::sleep_for(1000ms);</b></code>
<code class="calibre21">            if (m_queue.empty()) { <span class="color">// Only wait if the queue is empty.</span></code>
<code class="calibre21">                m_condVar.wait(lock);</code>
<code class="calibre21">            }</code>
<code class="calibre21">    <span class="color">// Remaining code omitted, same as before.</span></code>
<code class="calibre21">}</code></pre>
     <section class="calibre2">
      <aside class="calibre23">
       <div class="top">
        <hr class="calibre24"/>
       </div>
       <section class="feature">
        <p class="calibre25" id="c27-para-0274">
         <b class="calibre14">
          NOTE
         </b>
         <i class="calibre18">
          I recommend using
         </i>
         <code class="calibre21">
          jthread
         </code>
         <i class="calibre18">
          <i class="calibre18">
           over
          </i>
         </i>
         <code class="calibre21">
          thread
         </code>
         <i class="calibre18">
          , as it automatically joins in its destructor. With
         </i>
         <code class="calibre21">
          jthread
         </code>
         <i class="calibre18">
          , the explicit call to
         </i>
         <code class="calibre21">
          join()
         </code>
         <i class="calibre18">
          <i class="calibre18">
           in the destructor of
          </i>
         </i>
         <code class="calibre21">
          Logger
         </code>
         <i class="calibre18">
          <i class="calibre18">
           is not necessary
          </i>
          .
         </i>
        </p>
        <div class="top">
         <hr class="calibre24"/>
        </div>
       </section>
      </aside>
     </section>
    </section>
    <section aria-labelledby="head-2-278" class="calibre2">
     <span class="calibre" id="c27-sec-0076">
     </span>
     <h2 class="calibre6" id="head-2-278">
      THREAD POOLS
     </h2>
     <p class="calibre13" id="c27-para-0275">
      Instead of creating and deleting threads dynamically throughout your program's lifetime, you can create a pool of threads that can be used as needed. This technique is often used in programs that want to handle some kind of event in a thread. In most environments, the ideal number of threads is equal to the number of processing cores. If there are more threads than cores, threads will have to be suspended to allow other threads to run, and this will ultimately add overhead. Note that while the ideal number of threads is equal to the number of cores, this applies only in the case where the threads are compute bound and cannot block for any other reason, including I/O. When threads can block, it is often appropriate to run more threads than there are cores. Determining the optimal number of threads in such cases is hard and may involve throughput measurements.
     </p>
     <p class="calibre13" id="c27-para-0276">
      <span aria-label="1036" class="calibre20" epub:type="pagebreak" id="Page_1036" role="doc-pagebreak">
      </span>
      Because not all processing is identical, it is not uncommon to have threads from a thread pool receive, as part of their input, a callable that represents the computation to be done.
     </p>
     <p class="calibre13" id="c27-para-0277">
      Because threads from a thread pool are pre-existing, it is much more efficient for the operating system to schedule a thread from the pool to run than it is to create one in response to an input. Furthermore, the use of a thread pool allows you to manage the number of threads that are created, so, depending on the platform, you may have just one thread or thousands of threads.
     </p>
     <p class="calibre13" id="c27-para-0278">
      Several libraries are available that implement thread pools, including Intel Threading Building Blocks (TBB), Microsoft Parallel Patterns Library (PPL), and so on. It's recommended to use such a library for your thread pools instead of writing your own implementation. If you do want to implement a thread pool yourself, it can be done in a similar way as an object pool.
      <a class="calibre5" href="c29.xhtml">
       Chapter 29
      </a>
      , “Writing Efficient C++,” gives an example implementation of an object pool.
     </p>
    </section>
    <section aria-labelledby="head-2-279" class="calibre2">
     <span class="calibre" id="c27-sec-0077">
     </span>
     <h2 class="calibre6" id="head-2-279">
      COROUTINES
     </h2>
     <p class="calibre13">
      A coroutine is a function that can be suspended in the middle of its execution and resumed at a later point in time. Any function with one of the following keywords in its body is a coroutine:
     </p>
     <ul class="check" id="c27-list-0019">
      <li class="calibre9" id="c27-li-0063">
       <b class="calibre14">
        <code class="calibre21">
         co_await
        </code>
        :
       </b>
       Suspends the execution of a coroutine while waiting for a computation to finish. Execution is resumed when the computation is finished.
      </li>
      <li class="calibre9" id="c27-li-0064">
       <b class="calibre14">
        <code class="calibre21">
         co_return
        </code>
        :
       </b>
       Returns from a coroutine (just
       <code class="calibre21">
        return
       </code>
       is not allowed in a coroutine). The coroutine cannot be resumed after this.
      </li>
      <li class="calibre9" id="c27-li-0065">
       <b class="calibre14">
        <code class="calibre21">
         co_yield
        </code>
        :
       </b>
       Returns a value from a coroutine back to the caller and suspends the coroutine. Subsequently calling the coroutine again will continue its execution at the point where it was suspended.
      </li>
     </ul>
     <p class="calibre13" id="c27-para-0280">
      In general, there are two types of coroutines: stackful and stackless. A
      <i class="calibre18">
       stackful coroutine
      </i>
      can be suspended from anywhere deep inside a nested call. On the other hand, a
      <i class="calibre18">
       stackless coroutine
      </i>
      can only be suspended from the top stack frame. When a stackless coroutine is suspended, only the variables and temporaries with automatic storage duration in the body of the function are saved; the call stack is not saved. Hence, memory usage for stackless coroutines is minimal, allowing for millions or even billions of coroutines to be running concurrently. C++ only supports the stackless variant.
     </p>
     <p class="calibre13" id="c27-para-0281">
      To be fair, coroutines don't necessarily have anything to do with multithreading; instead, they just provide a way for a function to be suspended and resumed at a later time. Of course, if needed, coroutines can be used in a multithreaded environment just as well.
     </p>
     <p class="calibre13">
      Coroutines can be used to implement asynchronous operations using a synchronous programming style. Use cases include the following:
     </p>
     <ul class="check" id="c27-list-0020">
      <li class="calibre9" id="c27-li-0066">
       Generators
      </li>
      <li class="calibre9" id="c27-li-0067">
       Asynchronous I/O
      </li>
      <li class="calibre9" id="c27-li-0068">
       Lazy computations
      </li>
      <li class="calibre9" id="c27-li-0069">
       <span aria-label="1037" class="calibre20" epub:type="pagebreak" id="Page_1037" role="doc-pagebreak">
       </span>
       Event-driven applications
      </li>
      <li class="calibre9" id="c27-li-0070">
       State machines
      </li>
     </ul>
     <p class="calibre13" id="c27-para-0284">
      <img alt="C++23" class="calibre15" src="images/icon1.png"/>
      Unfortunately, while all the low-level language building blocks are available to write your own coroutines, there's not much in terms of high-level coroutine facilities. The C++23 Standard Library introduces one standardized high-level coroutine facility, the
      <i class="calibre18">
       generator
      </i>
      <code class="calibre21">
       std::generator
      </code>
      . A generator provides a mechanism to have a single thread switch back and forth between generating results and handling those results, without involving multiple threads.
     </p>
     <p class="calibre13">
      The following code demonstrates the use of the
      <code class="calibre21">
       std::generator
      </code>
      class template, defined in
      <code class="calibre21">
       &lt;generator&gt;
      </code>
      :
     </p>
     <pre class="calibre26" id="c27-code-0087"><code class="calibre21">generator&lt;int&gt; getSequenceGenerator(int startValue, int numberOfValues)</code>
<code class="calibre21">{</code>
<code class="calibre21">    for (int i { startValue }; i &lt; startValue + numberOfValues; ++i) {</code>
<code class="calibre21">        <span class="color">// Print the local time to standard out, see <a class="calibre5" href="c22.xhtml">Chapter 22</a>.</span></code>
<code class="calibre21">        auto currentTime { system_clock::now() };</code>
<code class="calibre21">        auto localTime { current_zone()-&gt;to_local(currentTime) };</code>
<code class="calibre21">        print("{:%H:%M:%OS}: ", localTime);</code>
<code class="calibre21">        <span class="color">// Yield a value to the caller, and suspend the coroutine.</span></code>
<code class="calibre21">        co_yield i;</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code>
<code class="calibre21"> </code>
<code class="calibre21">int main()</code>
<code class="calibre21">{</code>
<code class="calibre21">    auto gen { getSequenceGenerator(10, 5) };</code>
<code class="calibre21">    for (const auto&amp; value : gen) {</code>
<code class="calibre21">        print("{} (Press enter for next value)", value);</code>
<code class="calibre21">        cin.ignore();</code>
<code class="calibre21">    }</code>
<code class="calibre21">}</code></pre>
     <p class="calibre13">
      When you run the application, you'll get the following output:
     </p>
     <pre class="calibre26" id="c27-code-0088"><code class="calibre21">16:35:42: 10 (Press enter for next value)</code></pre>
     <p class="calibre13">
      Pressing Enter adds another line:
     </p>
     <pre class="calibre26" id="c27-code-0089"><code class="calibre21">16:35:42: 10 (Press enter for next value)</code>
<code class="calibre21">16:36:03: 11 (Press enter for next value)</code></pre>
     <p class="calibre13">
      Pressing Enter again adds yet another line:
     </p>
     <pre class="calibre26" id="c27-code-0090"><code class="calibre21">16:35:42: 10 (Press enter for next value)</code>
<code class="calibre21">16:36:03: 11 (Press enter for next value)</code>
<code class="calibre21">16:36:21: 12 (Press enter for next value)</code></pre>
     <p class="calibre13" id="c27-para-0289">
      Every time after hitting Enter, a new value is requested from the generator. This causes the coroutine to resume, which executes the next iteration of the
      <code class="calibre21">
       for
      </code>
      loop in
      <code class="calibre21">
       getSequenceGenerator()
      </code>
      printing the local time, and returning the next value. Returning a value is done with
      <code class="calibre21">
       co_yield
      </code>
      , which returns the value and then suspends the coroutine. The value itself is printed in the
      <code class="calibre21">
       main()
      </code>
      function, followed by the question to press Enter for the next value. The output clearly shows that the coroutine is suspended and resumed multiple times.
     </p>
     <p class="calibre13" id="c27-para-0290">
      <span aria-label="1038" class="calibre20" epub:type="pagebreak" id="Page_1038" role="doc-pagebreak">
      </span>
      Unfortunately, that's pretty much all there is to say about coroutines in the scope of this book. Writing coroutines yourself, such as
      <code class="calibre21">
       std::generator
      </code>
      , is complicated and way too advanced to discuss in this book. I recommend using existing coroutines, written by experts. If you need other coroutine facilities besides the
      <code class="calibre21">
       generator
      </code>
      provided by the Standard Library, there are third-party libraries available, such as cppcoro
      <a aria-describedby="c27-note-0001" class="calibre5" epub:type="noteref" href="#c27-note-0001" id="R_c27-note-0001" role="doc-noteref">
       <sup class="calibre22">
        1
       </sup>
      </a>
      and concurrencpp,
      <a aria-describedby="c27-note-0002" class="calibre5" epub:type="noteref" href="#c27-note-0002" id="R_c27-note-0002" role="doc-noteref">
       <sup class="calibre22">
        2
       </sup>
      </a>
      that provide a collection of high-level coroutines. The goal of this section was to introduce the idea so that you know it exists. Maybe a future C++ standard will introduce more high-level standardized coroutine facilities.
     </p>
    </section>
    <section aria-labelledby="head-2-280" class="calibre2">
     <span class="calibre" id="c27-sec-0078">
     </span>
     <h2 class="calibre6" id="head-2-280">
      THREADING DESIGN AND BEST PRACTICES
     </h2>
     <p class="calibre13">
      This section lists a few best practices related to multithreaded programming.
     </p>
     <ul class="check" id="c27-list-0021">
      <li class="calibre9" id="c27-li-0071">
       <b class="calibre14">
        Use parallel Standard Library algorithms:
       </b>
       The Standard Library contains a large collection of algorithms. More than 60 of them support parallel execution. Whenever possible, use such parallel algorithms instead of writing your own multithreaded code. See
       <a class="calibre5" href="c20.xhtml">
        Chapter 20
       </a>
       , “Mastering Standard Library Algorithms,” for details on how to specify parallelization options for algorithms.
      </li>
      <li class="calibre9" id="c27-li-0072">
       <b class="calibre14">
        Prefer using
        <code class="calibre21">
         jthread
        </code>
        over
        <code class="calibre21">
         thread
        </code>
        :
       </b>
       Because
       <code class="calibre21">
        jthread
       </code>
       automatically joins in its destructor, it's harder to use wrong compared to
       <code class="calibre21">
        thread
       </code>
       .
      </li>
      <li class="calibre9" id="c27-li-0073">
       <b class="calibre14">
        Before closing the application, make sure all
        <code class="calibre21">
         thread
        </code>
        objects are unjoinable:
       </b>
       If you do use
       <code class="calibre21">
        thread
       </code>
       , make sure that either
       <code class="calibre21">
        join()
       </code>
       or
       <code class="calibre21">
        detach()
       </code>
       has been called on all
       <code class="calibre21">
        thread
       </code>
       objects. Destructors of
       <code class="calibre21">
        thread
       </code>
       s that are still joinable call
       <code class="calibre21">
        std::terminate()
       </code>
       , which abruptly terminates all threads and the application itself. Also remember that if you detach a thread, it will continue running. If it still accesses any global variables of non-trivial types, then those accesses might race with the destruction of the global variables during process shutdown, causing your program to crash on exit. These kinds of bugs can be hard to debug.
      </li>
      <li class="calibre9" id="c27-li-0074">
       <b class="calibre14">
        The best synchronization is no synchronization:
       </b>
       Multithreaded programming becomes much easier if you manage to design your different threads in such a way that all threads working on shared data read only from that shared data and never write to it, or only write to parts never read by other threads. In that case, there is no need for any synchronization, and you cannot have problems like data races or deadlocks.
      </li>
      <li class="calibre9" id="c27-li-0075">
       <b class="calibre14">
        Try to use the single-thread ownership pattern:
       </b>
       This means that a block of data is owned by no more than one thread at a time. Owning the data means that no other thread is allowed to read from or write to the data. When the thread is finished with the data, the data can be passed off to another thread, which now has sole and complete responsibility/ownership of the data. No synchronization is necessary in this case.
      </li>
      <li class="calibre9" id="c27-li-0076">
       <b class="calibre14">
        Use atomic types and operations when possible:
       </b>
       Atomic types and atomic operations make it easier to write data-race-free and deadlock-free code, because they handle synchronization automatically. If atomic types and operations are not possible in your multithreaded design and you need shared data, you will have to use some synchronization mechanism, such as a mutex.
      </li>
      <li class="calibre9" id="c27-li-0077">
       <span aria-label="1039" class="calibre20" epub:type="pagebreak" id="Page_1039" role="doc-pagebreak">
       </span>
       <b class="calibre14">
        Use locks to protect mutable shared data:
       </b>
       If you need mutable shared data to which multiple threads can write and you cannot use atomic types and operations, you have to use a locking mechanism to make sure that reads and writes between different threads are synchronized.
      </li>
      <li class="calibre9" id="c27-li-0078">
       <b class="calibre14">
        Release locks as soon as possible:
       </b>
       When you need to protect your shared data with a lock, make sure that you release the lock as soon as possible. While a thread is holding a lock, it is blocking other threads waiting for the same lock, possibly hurting performance.
      </li>
      <li class="calibre9" id="c27-li-0079">
       <b class="calibre14">
        Use RAII lock objects:
       </b>
       Use the
       <code class="calibre21">
        lock_guard
       </code>
       ,
       <code class="calibre21">
        unique_lock
       </code>
       ,
       <code class="calibre21">
        shared_lock
       </code>
       , or
       <code class="calibre21">
        scoped_lock
       </code>
       RAII classes to automatically release locks at the right time.
      </li>
      <li class="calibre9" id="c27-li-0080">
       <b class="calibre14">
        Do not manually acquire multiple locks; instead use
        <code class="calibre21">
         std::lock()
        </code>
        ,
        <code class="calibre21">
         try_lock()
        </code>
        , or a
        <code class="calibre21">
         scoped_lock:
        </code>
       </b>
       If multiple threads need to acquire multiple locks, they must be acquired in the same order in all threads to prevent deadlock. You should use the generic
       <code class="calibre21">
        std::lock()
       </code>
       or
       <code class="calibre21">
        try_lock()
       </code>
       functions or the
       <code class="calibre21">
        scoped_lock
       </code>
       class to acquire multiple locks.
      </li>
      <li class="calibre9" id="c27-li-0081">
       <b class="calibre14">
        Use a multithreading-aware profiler:
       </b>
       This helps to find performance bottlenecks in your multithreaded applications and to find out if your multiple threads are indeed utilizing all available processing power in your system. An example of a multithreading-aware profiler is the profiler in Microsoft Visual Studio.
      </li>
      <li class="calibre9" id="c27-li-0082">
       <b class="calibre14">
        Understand the multithreading support features of your debugger:
       </b>
       Most debuggers have at least basic support for debugging multithreaded applications. You should be able to get a list of all running threads in your application, and you should be able to switch to any one of those threads to inspect their call stack. You can use this, for example, to inspect deadlocks, because you can see exactly what each thread is doing.
      </li>
      <li class="calibre9" id="c27-li-0083">
       <b class="calibre14">
        Use thread pools instead of creating and destroying a lot of threads dynamically:
       </b>
       Your performance decreases if you dynamically create and destroy a lot of threads. In that case, it's better to use a thread pool to reuse existing threads.
      </li>
      <li class="calibre9" id="c27-li-0084">
       <b class="calibre14">
        Use higher-level multithreading libraries:
       </b>
       The C++ standard, at this moment, only provides basic building blocks for writing multithreaded code. Using those correctly is not trivial. Where possible, use higher-level multithreading libraries such as Intel Threading Building Blocks (TBB), Microsoft Parallel Patterns Library (PPL), and so on, rather than reinventing the wheel. Multithreaded programming is error-prone. More often than not, your wheel may not be as round as you think.
      </li>
     </ul>
    </section>
    <section aria-labelledby="head-2-281" class="calibre2">
     <span class="calibre" id="c27-sec-0079">
     </span>
     <h2 class="calibre6" id="head-2-281">
      SUMMARY
     </h2>
     <p class="calibre13" id="c27-para-0292">
      This chapter gave a brief overview of multithreaded programming using the standard C++ threading support library. You learned how to launch threads using
      <code class="calibre21">
       std::thread
      </code>
      , as well as how
      <code class="calibre21">
       jthread
      </code>
      makes it safer, less error-prone, and so much easier to write cancellable threads. You learned how you can use atomic types and atomic operations to operate on shared data without having to use an explicit synchronization mechanism. In case you cannot use these atomic types and operations, you learned how to use mutexes and condition variables to ensure proper synchronization between different threads that need read/write access to shared data. You learned about the synchronization primitives: semaphores, latches, and barriers. You also saw how promises and futures represent a simple inter-thread communication channel; you can use futures to more easily get a result back from
      <span aria-label="1040" class="calibre20" epub:type="pagebreak" id="Page_1040" role="doc-pagebreak">
      </span>
      a thread. The chapter finished with a brief introduction to coroutines and a number of best practices for multithreaded application design.
     </p>
     <p class="calibre13" id="c27-para-0293">
      As mentioned in the introduction, this chapter tried to touch on all the basic multithreading building blocks provided by the Standard Library, but due to space constraints, it cannot go into all the details of multithreaded programming. There are books available that discuss nothing but multithreading. See
      <a class="calibre5" href="b02.xhtml">
       Appendix B
      </a>
      for a few references.
     </p>
    </section>
    <section aria-labelledby="head-2-282" class="calibre2">
     <span class="calibre" id="c27-sec-0080">
     </span>
     <h2 class="calibre6" id="head-2-282">
      EXERCISES
     </h2>
     <p class="calibre13" id="c27-para-0294">
      By solving the following exercises, you can practice the material discussed in this chapter. Solutions to all exercises are available with the code download on the book's website at
      <code class="calibre21">
       <a class="calibre5" href="http://www.wiley.com/go/proc++6e">
        www.wiley.com/go/proc++6e
       </a>
      </code>
      . However, if you are stuck on an exercise, first reread parts of this chapter to try to find an answer yourself before looking at the solution from the website.
     </p>
     <section class="calibre2">
      <span class="calibre" id="c27-exsec-0001">
      </span>
      <ol class="none1">
       <li class="calibre9" id="c27-ex-0001">
        <b class="calibre14">
         Exercise 27-1:
        </b>
        Write an application that beeps every three seconds indefinitely. The three-second delay must be passed as an argument to your thread function. Tip: You can make your computer beep by printing
        <code class="calibre21">
         \a
        </code>
        to the standard output.
       </li>
       <li class="calibre9" id="c27-ex-0002">
        <b class="calibre14">
         Exercise 27-2:
        </b>
        Modify your solution to Exercise 27-1 so that the application can be stopped when the user presses the enter key.
       </li>
       <li class="calibre9" id="c27-ex-0003">
        <b class="calibre14">
         Exercise 27-3:
        </b>
        Modify your solution to Exercise 27-1 so that the beeping continues until the user presses the Enter key. Once the Enter key is pressed, beeping should be paused, until the user presses the Enter key again. The user can pause and resume the beeping as many times as she wants.
       </li>
       <li class="calibre9" id="c27-ex-0004">
        <b class="calibre14">
         Exercise 27-4:
        </b>
        Write an application that can calculate a number of Fibonacci numbers concurrently. For example, your code should be able to calculate the 4
        <sup class="calibre22">
         th
        </sup>
        , 9
        <sup class="calibre22">
         th
        </sup>
        , 14
        <sup class="calibre22">
         th
        </sup>
        , and 17
        <sup class="calibre22">
         th
        </sup>
        number in the Fibonacci series in parallel. The Fibonacci series starts with 0 and 1, and any subsequent value is the sum of the two previous values, so: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, and so on. Once all results are available, output them to the standard output. Finally, calculate their sum using a constrained Standard Library algorithm.
       </li>
       <li class="calibre9" id="c27-ex-0005">
        <b class="calibre14">
         Exercise 27-5:
        </b>
        Improve the robot example from earlier in this chapter. You can find that code in the downloadable source code archive in
        <code class="calibre21">
         Ch27\05_barrier\barrier.cpp
        </code>
        . Improve it so that the main thread starts all the robot threads, waits for all the robots to have started, prepares the first iteration, and then instructs all waiting robots to start working.
       </li>
       <li class="calibre9" id="c27-ex-0006">
        <b class="calibre14">
         Exercise 27-6:
        </b>
        Use
        <code class="calibre21">
         compare_exchange_strong()
        </code>
        to implement a function
        <code class="calibre21">
         atomicMin(a, b)
        </code>
        that sets
        <code class="calibre21">
         a
        </code>
        to
        <code class="calibre21">
         min(a, b)
        </code>
        atomically, and where
        <code class="calibre21">
         a
        </code>
        is an
        <code class="calibre21">
         atomic&lt;int&gt;
        </code>
        and
        <code class="calibre21">
         b
        </code>
        an
        <code class="calibre21">
         int
        </code>
        .
       </li>
      </ol>
     </section>
    </section>
   </section>
   <section aria-labelledby="c27_2" class="calibre2" role="doc-endnotes">
    <h2 class="calibre6" id="c27_2">
     NOTES
    </h2>
    <ol class="noteslist">
     <li class="noteentry">
      <a class="calibre5" href="#R_c27-note-0001" id="c27-note-0001" role="doc-backlink">
       1
      </a>
      <code class="calibre21">
       <a class="calibre5" href="https://github.com/lewissbaker/cppcoro">
        https://github.com/lewissbaker/cppcoro
       </a>
      </code>
     </li>
     <li class="noteentry">
      <a class="calibre5" href="#R_c27-note-0002" id="c27-note-0002" role="doc-backlink">
       2
      </a>
      <code class="calibre21">
       <a class="calibre5" href="https://github.com/David-Haim/concurrencpp">
        https://github.com/David-Haim/concurrencpp
       </a>
      </code>
     </li>
    </ol>
   </section>
  </div>
 </body>
</html>
